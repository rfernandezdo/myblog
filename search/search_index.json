{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Thats me","text":""},{"location":"#quien-soy","title":"Quien soy?","text":"<p>\u00a1Hola a todos!</p> <p>Soy Rafa , y este es mi peque\u00f1o rinc\u00f3n en la web.</p> <p>Como profesional apasionado de la inform\u00e1tica, me encanta explorar nuevas tecnolog\u00edas, enfrentar nuevos desaf\u00edos y compartir mis experiencias con otros.</p> <p>Como soy bastante malo present\u00e1ndome, le he pedido a chatgpt que me ayude a hacerlo en base a los comentarios de algunos de mis compa\u00f1eros de trabajo en Linkedin, este es el resultado:</p>"},{"location":"#un-lider-y-mentor-excepcional","title":"Un L\u00edder y Mentor Excepcional","text":"<p>\u00a1Hola a todos!</p> <p>Hoy quiero compartir con ustedes mi experiencia trabajando con un profesional de increible talento, Rafael.</p> <p>Tuve la suerte de trabajar con \u00e9l en Bravent durante m\u00e1s de seis meses. Durante ese tiempo, Rafael fue no solo mi jefe directo, sino tambi\u00e9n mi mentor dentro de la empresa. No puedo decir ni una cosa mala sobre \u00e9l; es un excelente l\u00edder, uno de los pocos que he encontrado en mi vida laboral, que nunca te pide algo que \u00e9l mismo no pueda hacer.</p> <p>Rafael siempre est\u00e1 dispuesto a echar una mano si ve que est\u00e1s desbordado o perdido. Como mentor, aplica siempre el principio de \u201cno le des un pez, ens\u00e9\u00f1ale a pescar\u201d. Me ayud\u00f3 a reconducir todas las situaciones en las que me encontr\u00e9 con un callej\u00f3n sin salida, apuntando en la direcci\u00f3n en la que ten\u00eda que seguir avanzando.</p> <p>A nivel t\u00e9cnico, Rafael es excepcional. M\u00e1s all\u00e1 de su conocimiento, sorprende por su capacidad para aprender en un tiempo m\u00ednimo lo necesario para resolver cualquier tipo de problema. Trabajar con \u00e9l es tremendamente f\u00e1cil, ya que nunca tiene una mala palabra ni un mal gesto y genera un ambiente de trabajo incre\u00edblemente positivo.</p> <p>Rafael demuestra un profundo conocimiento no solo t\u00e9cnico en las \u00e1reas que le competen, sino tambi\u00e9n de planificaci\u00f3n, an\u00e1lisis y gesti\u00f3n. He tenido la gran suerte de trabajar con \u00e9l y sin duda es una de las personas que me gustar\u00eda que formara parte de cualquier equipo en el que me encuentre ahora o en el futuro.</p> <p>Rafael es un maestro en las artes inform\u00e1ticas y un verdadero profesional. En su trabajo no deja nada al azar, todo lo estudia detenidamente y suele tomar muy buenas decisiones. Adem\u00e1s, Rafael es un profesional altamente calificado. Tiene una actitud amigable y resuelve r\u00e1pidamente cualquier pregunta que tengas, explic\u00e1ndote siempre la soluci\u00f3n. Si tienes alg\u00fan problema, \u00e9l es la persona adecuada a quien pedir ayuda.</p> <p>Espero que este testimonio brinde una visi\u00f3n clara del incre\u00edble profesional y persona que es Rafael. Estoy seguro de que aquellos que tengan la oportunidad de trabajar con \u00e9l se beneficiar\u00e1n enormemente de su liderazgo, conocimientos t\u00e9cnicos y actitud positiva.</p>"},{"location":"#who-am-i","title":"Who am I?","text":"<p>Hello everyone!</p> <p>I'm Rafa, and this is my little corner on the web.</p> <p>As a passionate IT professional, I love exploring new technologies, facing new challenges, and sharing my experiences with others.</p> <p>Since I'm pretty bad at introducing myself, I've asked chatgpt to help me do it based on comments from some of my coworkers on Linkedin, this is the result:</p>"},{"location":"#an-exceptional-leader-and-mentor","title":"An Exceptional Leader and Mentor","text":"<p>Hello everyone!</p> <p>Today I want to share with you my experience working with an incredibly talented professional, Rafael.</p> <p>I was lucky enough to work with him at Bravent for over six months. During that time, Rafael was not only my direct boss, but also my mentor within the company. I can't say a single bad thing about him; He is an excellent leader, one of the few I have encountered in my working life, who never asks you for something that he cannot do himself.</p> <p>Rafael is always willing to lend a hand if he sees that you are overwhelmed or lost. As a mentor, he always applies the principle of \u201cdon't give him a fish, teach him to fish.\u201d He helped me redirect all the situations in which I found myself at a dead end, pointing in the direction in which I had to continue moving forward.</p> <p>On a technical level, Rafael is exceptional. Beyond his knowledge, he is surprised by his ability to learn in a minimum amount of time what is necessary to solve any type of problem. Working with him is tremendously easy, since he never has a bad word or a bad gesture and generates an incredibly positive work environment.</p> <p>Rafael demonstrates deep knowledge not only of technical knowledge in the areas in which he is responsible, but also of planning, analysis and management. I have had the great fortune to work with him and he is undoubtedly one of the people I would like to be part of any team I am on now or in the future.</p> <p>Rafael is a master of computer arts and a true professional. In his work he leaves nothing to chance, he studies everything carefully and he usually makes very good decisions. Furthermore, Rafael is a highly qualified professional. He has a friendly attitude and quickly resolves any questions you have, always explaining the solution. If you have a problem, he is the right person to ask for help.</p> <p>I hope this testimony provides a clear vision of the incredible professional and person that Rafael is. I am confident that those who have the opportunity to work with him will benefit greatly from his leadership, technical knowledge and positive attitude.</p>"},{"location":"contributions/","title":"Contributions","text":"<p>Better or worse, here I am adding my contributions in case one day I have to compile them to be MVP (a real pain):</p> <p>Generally, I try to contribute to the community in the following ways:</p> <ul> <li>Post/shares in Linkedin</li> <li>Post in my blog</li> <li>Some contributions to github projects azure related(see below)</li> </ul>"},{"location":"contributions/#2025","title":"2025","text":""},{"location":"contributions/#2024","title":"2024","text":"<ul> <li>Cloud Adoption Framework for Azure - Terraform module</li> <li>Update considerations for Microsoft Entra Domain Services</li> <li>Azure/Enterprise-azure-policy-as-code<ul> <li>Update ci-cd-github-actions.md </li> </ul> </li> <li>Organizer of Azure Global Seville 2024 and collaborator in Global Azure Spain 2024, Zaragoza.</li> <li>Speaker in Azure Global Seville 2024.</li> <li>Update firewall-faq.yml to add support force tunneling in Azure Firewall Basic</li> </ul>"},{"location":"contributions/#2023","title":"2023","text":"<ul> <li>Creator of Azure Certified World Community, a community by and for Azure Certified Experts.</li> <li> <p>Microsoft Azure Documentation</p> <ul> <li>Added comparative table to Containers</li> <li>Add mind maps to WAF pillars</li> </ul> </li> <li> <p>mingrammer</p> <ul> <li>Update azure icons to v12 mingrammer</li> </ul> </li> <li> <p>Cloud Adoption Framework for Azure - Terraform module</p> <ul> <li>First version of the module to support azurerm_linux_function_app</li> <li>Feature/add ddos protection plan id var non global to ddos</li> </ul> </li> <li>Microsoft Cloud Adoption Framework for Azure, run aznamingtool in podman</li> </ul>"},{"location":"contributions/#2022","title":"2022","text":"<ul> <li> <p>Cloud Adoption Framework for Azure - Terraform module</p> <ul> <li>Adding support for Digital Twins</li> <li>Submodule Eventgrid</li> <li>System Identity option added to identity in function app</li> </ul> </li> <li> <p>Global Azure Zaragoza 2022</p> <ul> <li>Enterprise Scale Zone \u2013 Empieza bien</li> <li>Enterprise Scale Zone \u2013 CAF Landing zones for Terraform</li> </ul> </li> <li> <p>Microsoft Azure Documentation</p> <ul> <li>Example added for Azure IP reserves in subnet</li> </ul> </li> <li> <p>Azure-Samples</p> <ul> <li>Update example KeyVault-Rotation-StorageAccountKey-PowerShell</li> </ul> </li> <li> <p>Azure Naming Calculator for early stage of the Cloud Adoption Framework for Azure</p> </li> </ul>"},{"location":"Azure/Security/MCSB/Asset%20Management/","title":"MCSB_v1 - Asset Management","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 Customer Security Stakeholders: AM-1 Asset Management 1.1 - Utilize an Active Discovery Tool 1.1 - Establish and Maintain Detailed Enterprise Asset Inventory CM-8: INFORMATION SYSTEM COMPONENT INVENTORY 2.4 Track asset inventory and their risks Track your asset inventory by query and discover all your cloud resources. Logically organize your assets by tagging and grouping your assets based on their service nature, location, or other characteristics. Ensure your security organization has access to a continuously updated inventory of assets. The Microsoft Defender for Cloud inventory feature and Azure Resource Graph can query for and discover all resources in your subscriptions, including Azure services, applications, and network resources. Logically organize assets according to your organization's taxonomy using tags as well as other metadata in Azure (Name, Description, and Category). How to create queries with Azure Resource Graph Explorer: Use the AWS Systems Manager Inventory feature to query for and discover all resources in your EC2 instances, including application level and operating system level details. In addition, use AWS Resource Groups - Tag Editor to browse AWS resource inventories. AWS Systems Manager Inventory: Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 1.2 - Use a Passive Asset Discovery Tool 1.5 - Use a Passive Asset Discovery Tool PM-5: INFORMATION SYSTEM INVENTORY https://docs.microsoft.com/azure/governance/resource-graph/first-query-portal https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-inventory.html 1.4 - Maintain Detailed Asset Inventory 2.1 - Establish and Maintain a Software Inventory Ensure your security organization can monitor the risks of the cloud assets by always having security insights and risks aggregated centrally Ensure that security organizations have access to a continuously updated inventory of assets on Azure. Security teams often need this inventory to evaluate their organization's potential exposure to emerging risks, and as an input for continuous security improvements. Logically organize assets according to your organization's taxonomy using tags as well as other metadata in AWS (Name, Description, and Category). Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management 1.5 - Maintain Asset Inventory Information 2.4 - Utilize Automated Software Inventory Tools Microsoft Defender for Cloud asset inventory management: AWS Resource Groups and Tags: 2.1 - Maintain Inventory of Authorized Software Ensure security organizations are granted Security Reader permissions in your Azure tenant and subscriptions so they can monitor for security risks using Microsoft Defender for Cloud. Security Reader permissions can be applied broadly to an entire tenant (Root Management Group) or scoped to management groups or specific subscriptions. https://docs.microsoft.com/azure/security-center/asset-inventory Ensure that security organizations have access to a continuously updated inventory of assets on AWS. Security teams often need this inventory to evaluate their organization's potential exposure to emerging risks, and as an input for continuous security improvements. https://docs.aws.amazon.com/ARG/latest/userguide/tag-editor.html Note: Additional permissions might be required to get visibility into workloads and services. For more information about tagging assets, see the resource naming and tagging decision guide: Note: Additional permissions might be required to get visibility into workloads and services. https://docs.microsoft.com/azure/cloud-adoption-framework/decision-guides/resource-tagging/?toc=/azure/azure-resource-manager/management/toc.json Overview of Security Reader Role: https://docs.microsoft.com/azure/role-based-access-control/built-in-roles#security-reader AM-2 Asset Management 2.7 - Utilize Application Whitelisting 2.5 - Allowlist Authorized Software CM-8: INFORMATION SYSTEM COMPONENT INVENTORY 6.3 Use only approved services Ensure that only approved cloud services can be used, by auditing and restricting which services users can provision in the environment. Use Azure Policy to audit and restrict which services users can provision in your environment. Use Azure Resource Graph to query for and discover resources within their subscriptions. You can also use Azure Monitor to create rules to trigger alerts when a non-approved service is detected. Configure and manage Azure Policy: Use AWS Config to audit and restrict which services users can provision in your environment. Use AWS Resource Groups to query for and discover resources within their accounts. You can also use CloudWatch and/or AWS Config to create rules to trigger alerts when a non-approved service is detected. AWS Resource Groups: Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management 2.8 - Implement Application Whitelisting of Libraries 2.6 - Allowlist Authorized Libraries PM-5: INFORMATION SYSTEM INVENTORY https://docs.microsoft.com/azure/governance/policy/tutorials/create-and-manage https://docs.aws.amazon.com/ARG/latest/userguide/gettingstarted.html 2.9 - Implement Application Whitelisting of Scripts 2.7 - Allowlist Authorized Scripts Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 9.2 - Ensure Only Approved Ports, Protocols, and Services Are Running 4.8 - Uninstall or Disable Unnecessary Services on Enterprise Assets and Software How to deny a specific resource type with Azure Policy: https://docs.microsoft.com/azure/governance/policy/samples/not-allowed-resource-types How to create queries with Azure Resource Graph Explorer: https://docs.microsoft.com/azure/governance/resource-graph/first-query-portal AM-3 Asset Management 1.4 - Maintain Detailed Asset Inventory 1.1 - Establish and Maintain Detailed Enterprise Asset Inventory CM-8: INFORMATION SYSTEM COMPONENT INVENTORY 2.4 Ensure security of asset lifecycle management Ensure security attributes or configurations of the assets are always updated during the asset lifecycle. Establish or update security policies/process that address asset lifecycle management processes for potentially high impact modifications. These modifications include changes to identity providers and access, data sensitivity level, network configuration, and administrative privilege assignment. Delete Azure resource group and resource: Establish or update security policies/process that address asset lifecycle management processes for potentially high impact modifications. These modifications include changes to identity providers and access, data sensitivity level, network configuration, and administrative privilege assignment. How do I check for active resources that I no longer need on my AWS account? Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 1.5 - Maintain Asset Inventory Information 2.1 - Establish and Maintain a Software Inventory CM-7: LEAST FUNCTIONALITY https://docs.microsoft.com/azure/azure-resource-manager/management/delete-resource-group https://aws.amazon.com/premiumsupport/knowledge-center/check-for-active-resources/ 2.1 - Maintain Inventory of Authorized Software Identify and remove Azure resources when they are no longer needed. Identify and remove AWS resources when they are no longer needed. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 2.4 - Track Software Inventory Information How do I terminate active resources that I no longer need on my AWS account? https://aws.amazon.com/premiumsupport/knowledge-center/terminate-resources-account-closure/ Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management AM-4 Asset Management 14.6 - Protect Information Through Access Control Lists 3.3 - Configure Data Access Control Lists AC-3: ACCESS ENFORCEMENT nan Limit access to asset management Limit users' access to asset management features, to avoid accidental or malicious modification of the assets in your cloud. Azure Resource Manager is the deployment and management service for Azure. It provides a management layer that enables you to create, update, and delete resources (assets) in Azure. Use Azure AD Conditional Access to limit users' ability to interact with Azure Resource Manager by configuring \"Block access\" for the \"Microsoft Azure Management\" App. How to configure Conditional Access to block access to Azure Resources Manager: Use AWS IAM to restrict access to a specific resource. You can specify allowed or deny actions as well as the conditions under which actions are triggered. You may specify one condition or combine methods of resource-level permissions, resource-based policies, tag-based authorization, temporary credentials, or service-linked roles to have a fine-grain control access control for your resources. AWS services that work with IAM: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management https://docs.microsoft.com/azure/role-based-access-control/conditional-access-azure-management https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_aws-services-that-work-with-iam.html Use Azure Role-based Access Control (Azure RBAC) to assign roles to identities to control their permissions and access to Azure resources. For example, a user with only the 'Reader' Azure RBAC role can view all resources, but is not allowed to make any changes. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Lock your resources to protect your infrastructure: Use Resource Locks to prevent either deletions or modifications to resources. Resource Locks may also be administered through Azure Blueprints. https://learn.microsoft.com/azure/azure-resource-manager/management/lock-resources?tabs=json Protect new resources with Azure Blueprints resource locks: https://learn.microsoft.com/azure/governance/blueprints/tutorials/protect-new-resources AM-5 Asset Management 2.7 - Utilize Application Whitelisting 2.5 - Allowlist Authorized Software CM-8: INFORMATION SYSTEM COMPONENT INVENTORY 6.3 Use only approved applications in virtual machine Ensure that only authorized software executes by creating an allow list and block the unauthorized software from executing in your environment. Use Microsoft Defender for Cloud adaptive application controls to discover and generate an application allow list. You can also use ASC adaptive application controls to ensure that only authorized software can executes, and all unauthorized software is blocked from executing on Azure Virtual Machines. How to use Microsoft Defender for Cloud adaptive application controls: Use the AWS Systems Manager Inventory feature to discover the applications installed in your EC2 instances. Use AWS Config rules to ensure that non-authorized software is blocked from executing on EC2 instances. Preventing blacklisted applications with AWS Systems Manager and AWS Config: Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 2.8 - Implement Application Whitelisting of Libraries 2.6 - Allowlist Authorized Libraries CM-7: LEAST FUNCTIONALITY https://docs.microsoft.com/azure/security-center/security-center-adaptive-application https://aws.amazon.com/blogs/mt/preventing-blacklisted-applications-with-aws-systems-manager-and-aws-config/ 2.9 - Implement Application Whitelisting of Scripts 2.7 - Allowlist Authorized Scripts CM-10: SOFTWARE USAGE RESTRICTIONS Use Azure Automation Change Tracking and Inventory to automate the collection of inventory information from your Windows and Linux VMs. Software name, version, publisher, and refresh time information are available from the Azure portal. To get the software installation date and other information, enable guest-level diagnostics and direct the Windows Event Logs to a Log Analytics workspace. You can also use a third-party solution to discover and identify unapproved software. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 9.2 - Ensure Only Approved Ports, Protocols, and Services Are Running 4.8 - Uninstall or Disable Unnecessary Services on Enterprise Assets and Software CM-11: USER-INSTALLED SOFTWARE Understand Azure Automation Change Tracking and Inventory: Depending on the type of scripts, you can use operating system-specific configurations or third-party resources to limit users' ability to execute scripts in Azure compute resources. https://docs.microsoft.com/azure/automation/change-tracking Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management You can also use a third-party solution to discover and identify unapproved software. How to control PowerShell script execution in Windows environments: https://docs.microsoft.com/powershell/module/microsoft.powershell.security/set-executionpolicy?view=powershell-6"},{"location":"Azure/Security/MCSB/Backup%20and%20Recovery/","title":"MCSB_v1 - Backup and Recovery","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 Customer Security Stakeholders: BR-1 Backup and recovery 10.1 - Ensure Regular Automated Backups 11.2 - Perform Automated Backups CP-2: CONTINGENCY PLAN nan Ensure regular automated backups Ensure backup of business-critical resources, either during resource creation or enforced through policy for existing resources. For Azure Backup supported resources (such as Azure VMs, SQL Server, HANA databases, Azure PostgreSQL Database, File Shares, Blobs or Disks), enable Azure Backup and configure the desired frequency and retention period. For Azure VM, you can use Azure Policy to have backup automatically enabled using Azure Policy. How to enable Azure Backup: For AWS Backup supported resources (such as EC2, S3, EBS or RDS), enable AWS Backup and configure the desired frequency and retention period. AWS Backup supported resources and third-party applications: Policy and standards: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-policy-standards CP-4: CONTINGENCY PLAN TESTING https://docs.microsoft.com/azure/backup/ https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html CP-9: INFORMATION SYSTEM BACKUP For resources or services not supported by Azure Backup, use the native backup capability provided by the resource or service. For example, Azure Key Vault provides a native backup capability. For resources/services not supported by AWS Backup, such as AWS KMS, enable the native backup feature as part of its resource creation. Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture Auto-Enable Backup on VM Creation using Azure Policy: Amazon S3 versioning: For resources/services that are neither supported by Azure Backup nor have a native backup capability, evaluate your backup and disaster needs, and create your own mechanism as per your business requirements. For example: https://docs.microsoft.com/azure/backup/backup-azure-auto-enable-backup For resources/services that are neither supported by AWS Backup nor have a native backup capability, evaluate your backup and disaster needs, and create your own mechanism as per your business requirements. For example: https://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint - If you use Azure Storage for data storage, enable blob versioning for your storage blobs which will allow you to preserve, retrieve, and restore every version of every object stored in your Azure Storage. - If Amazon S3 is used for data storage, enable S3 versioning for your storage backet which will allow you to preserve, retrieve, and restore every version of every object stored in your S3 bucket. - Service configuration settings can usually be exported to Azure Resource Manager templates. - Service configuration settings can usually be exported to CloudFormation templates. AWS CloudFormation best practices: Incident preparation: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.html BR-2 Backup and recovery 10.4 - Ensure Protection of Backups 11.3 - Protect Recovery Data CP-6: ALTERNATE STORAGE SITE 3.4 Protect backup and recovery data Ensure backup data and operations are protected from data exfiltration, data compromise, ransomware/malware and malicious insiders. The security controls that should be applied include user and network access control, data encryption at-rest and in-transit. Use multi-factor-authentication and Azure RBAC to secure the critical Azure Backup operations (such as delete, change retention, updates to backup config). For Azure Backup supported resources, use Azure RBAC to segregate duties and enable fine grained access, and create private endpoints within your Azure Virtual Network to securely backup and restore data from your Recovery Services vaults. Overview of security features in Azure Backup: Use AWS IAM access control to secure AWS Backup. This includes securing the AWS Backup service access and backup and restore points. Example controls include: Security in AWS Backup: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture CP-9: INFORMATION SYSTEM BACKUP https://docs.microsoft.com/azure/backup/security-overview - Use multi-factor authentication (MFA) for critical operations such as deletion of a backup/restore point. https://docs.aws.amazon.com/aws-backup/latest/devguide/security-considerations.html For Azure Backup supported resources, backup data is automatically encrypted using Azure platform-managed keys with 256-bit AES encryption. You can also choose to encrypt the backups using a customer managed key. In this case, ensure the customer-managed key in the Azure Key Vault is also in the backup scope. If you use a customer-managed key, use soft delete and purge protection in Azure Key Vault to protect keys from accidental or malicious deletion. For on-premises backups using Azure Backup, encryption-at-rest is provided using the passphrase you provide. - Use Secure Sockets Layer (SSL)/Transport Layer Security (TLS) to communicate with AWS resources. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Encryption of backup data using customer-managed keys: - Use AWS KMS in conjunction with AWS Backup to encrypt the backup data either using customer-managed CMK or an AWS-managed CMK associated with the AWS Backup service. Security Best Practices for Amazon S3: Safeguard backup data from accidental or malicious deletion, such as ransomware attacks/attempts to encrypt or tamper backup data. For Azure Backup supported resources, enable soft delete to ensure recovery of items with no data loss for up to 14 days after an unauthorized deletion, and enable multifactor authentication using a PIN generated in the Azure portal. Also enable geo-redundant storage or cross-region restoration to ensure backup data is restorable when there is a disaster in primary region. You can also enable Zone-redundant Storage (ZRS) to ensure backups are restorable during zonal failures. https://docs.microsoft.com/azure/backup/encryption-at-rest-with-cmk - Use AWS Backup Vault Lock for immutable storage of critical data. https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html Incident preparation: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation - Secure S3 buckets through access policy, disabling public access, enforcing data at-rest encryption, and versioning control. Note: If you use a resource's native backup feature or backup services other than Azure Backup, refer to the Microsoft Cloud Security Benchmark (and service baselines) to implement the above controls. Security features to help protect hybrid backups from attacks: https://docs.microsoft.com/azure/backup/backup-azure-security-feature#prevent-attacks Azure Backup - set cross region restore https://docs.microsoft.com/azure/backup/backup-create-rs-vault#set-cross-region-restore BR-3 Backup and recovery 10.4 - Ensure Protection of Backups 11.3 - Protect Recovery Data CP-9: INFORMATION SYSTEM BACKUP nan Monitor backups Ensure all business-critical protectable resources are compliant with the defined backup policy and standard. Monitor your Azure environment to ensure that all your critical resources are compliant from a backup perspective. Use Azure Policy for backup to audit and enforce such controls.  For Azure Backup supported resources, Backup Center helps you centrally govern your backup estate. Govern your backup estate using Backup Center: AWS Backup works with other AWS tools to empower you to monitor its workloads. These tools include the following: AWS Backup Monitoring: Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation https://docs.microsoft.com/azure/backup/backup-center-govern-environment - Use AWS Backup Audit Manager to monitor the backup operations to ensure the compliance. https://docs.aws.amazon.com/aws-backup/latest/devguide/monitoring.html Ensure critical backup operations (delete, change retention, updates to backup config) are monitored, audited, and have alerts in place. For Azure Backup supported resources, monitor overall backup health, get alerted to critical backup incidents, and audit triggered user actions on vaults. - Use CloudWatch and Amazon EventBridge to monitor AWS Backup processes. Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Monitor and operate backups using Backup center: - Use CloudWatch to track metrics, create alarms, and view dashboards. Monitoring AWS Backup events using EventBridge: Note: Where applicable, also use built-in policies (Azure Policy) to ensure that your Azure resources are configured for backup. https://docs.microsoft.com/azure/backup/backup-center-monitor-operate - Use EventBridge to view and monitor AWS Backup events. https://docs.aws.amazon.com/aws-backup/latest/devguide/eventbridge.html - Use Amazon Simple Notification Service (Amazon SNS) to subscribe to AWS Backup-related topics such as backup, restore, and copy events. Monitoring and reporting solutions for Azure Backup: Monitoring AWS Backup metrics with CloudWatch: https://docs.microsoft.com/azure/backup/monitoring-and-alerts-overview https://docs.aws.amazon.com/aws-backup/latest/devguide/cloudwatch.html Using Amazon SNS to track AWS Backup events: https://docs.aws.amazon.com/aws-backup/latest/devguide/sns-notifications.html Audit backups and create reports with AWS Backup Audit Manager: https://docs.aws.amazon.com/aws-backup/latest/devguide/aws-backup-audit-manager.html BR-4 Backup and recovery 10.3 - Test Data on Backup Media 11.5 - Test Data Recovery CP-4: CONTINGENCY PLAN TESTING nan Regularly test backup Periodically perform data recovery tests of your backup to verify that the backup configurations and availability of the backup data meets the recovery needs as per defined in the RTO (Recovery Time Objective) and RPO (Recovery Point Objective). Periodically perform data recovery tests of your backup to verify that the backup configurations and availability of the backup data meets the recovery needs as defined in the RTO and RPO. How to recover files from Azure Virtual Machine backup: Periodically perform data recovery tests of your backup to verify that the backup configurations and availability of the backup data meets the recovery needs as defined in the RTO and RPO. Restoring a backup: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture CP-9: INFORMATION SYSTEM BACKUP https://docs.microsoft.com/azure/backup/backup-azure-restore-files-from-vm https://docs.aws.amazon.com/aws-backup/latest/devguide/restoring-a-backup.html You may need to define your backup recovery test strategy, including the test scope, frequency and method as performing the full recovery test each time can be difficult. You may need to define your backup recovery test strategy, including the test scope, frequency and method as performing the full recovery test each time can be difficult. Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation How to restore Key Vault keys in Azure: https://docs.microsoft.com/powershell/module/azurerm.keyvault/restore-azurekeyvaultkey?view=azurermps-6.13.0 Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security"},{"location":"Azure/Security/MCSB/Data%20Protection/","title":"MCSB_v1 - Data Protection","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context: AWS Foundational Security Best Practices controls AWS Config Rule (WIP) Azure Policy CIS AWS Foundations Benchmark 1.4.0 Customer Security Stakeholders: DP-1 Data Protection 13.1 -  Maintain an Inventory of Sensitive Information 3.2 - Establish and Maintain a Data Inventory RA-2: SECURITY CATEGORIZATION A3.2 Discover, classify, and label sensitive data Establish and maintain an inventory of the sensitive data, based on the defined sensitive data scope. Use tools to discover, classify and label the in- scope sensitive data. Use tools such as Microsoft Purview, which combines the former Azure Purview and Microsoft 365 compliance solutions, and Azure SQL Data Discovery and Classification to centrally scan, classify, and label the sensitive data that reside in the Azure, on-premises, Microsoft 365, and other locations. Data classification overview: Replicate your data from various sources to a S3 storage bucket and use AWS Macie to scan, classify and label the sensitive data stored in the bucket. AWS Macie can detect sensitive data such as security credentials, financial information, PHI and PII data, or other data pattern based on the custom data identifier rules. Data Classification Process: nan nan [Preview]: Sensitive data in your SQL databases should be classified 2.3.1 Ensure that encryption is enabled for RDS Instances Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 14.5 - Utilize an Active Discovery Tool to Identify Sensitive Data 3.7 - Establish and Maintain a Data Classification Scheme SC-28: PROTECTION OF INFORMATION AT REST https://docs.microsoft.com/azure/cloud-adoption-framework/govern/policy-compliance/data-classification https://docs.aws.amazon.com/whitepapers/latest/data-classification/data-classification-process.html (Automated) 3.13 - Deploy a Data Loss Prevention Solution You may also use the Azure Purview multi-cloud scanning connector to scan, classify and label the sensitive data residing in a S3 storage bucket. Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security Labeling in the Microsoft Purview Data Map: AWS Marketplace - DLP Solution: https://docs.microsoft.com/azure/purview/create-sensitivity-label Note: You can also use third-party enterprise solutions from AWS marketplace for the purpose of data discovery classification and labeling https://aws.amazon.com/marketplace/search/results?searchTerms=DLP Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Tag sensitive information using Azure Information Protection: https://docs.microsoft.com/azure/information-protection/what-is-information-protection How to implement Azure SQL Data Discovery: https://docs.microsoft.com/azure/sql-database/sql-database-data-discovery-and-classification Microsoft Purview data sources: https://docs.microsoft.com/azure/purview/purview-connector-overview#purview-data-sources DP-2 Data Protection 13.3 - Monitor and Block Unauthorized Network Traffic 3.13 - Deploy a Data Loss Prevention Solution AC-4: INFORMATION FLOW ENFORCEMENT A3.2 Monitor anomalies and threats targeting sensitive data Monitor for anomalies around sensitive data, such as unauthorized transfer of data to locations outside of enterprise visibility and control. This typically involves monitoring for anomalous activities (large or unusual transfers) that could indicate unauthorized data exfiltration. Use Azure Information protection (AIP) to monitor the data that has been classified and labeled. Enable Azure Defender for SQL: Use AWS Macie to monitor the data that has been classified and labeled, and use GuardDuty to detect anomalous activities on some resources (S3, EC2 or Kubernetes or IAM resources). Findings and alerts can be triaged, analyzed, and tracked using EventBridge and forwarded to Microsoft Sentinel or Security Hub for incident aggregation and tracking. GuardDuty S3 finding types: nan nan Azure Defender for open-source relational databases should be enabled nan Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security 14.7 - Enforce Access Control to Data through Automated Tools SI-4: INFORMATION SYSTEM MONITORING https://docs.microsoft.com/azure/azure-sql/database/azure-defender-for-sql https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_finding-types-s3.html Azure Defender for Storage should be enabled Use Microsoft Defender for Storage, Microsoft Defender for SQL, Microsoft Defender for open-source relational databases, and Microsoft Defender for Cosmos DB to alert on anomalous transfer of information that might indicate unauthorized transfers of sensitive data information. You may also connect your AWS accounts to Microsoft Defender for Cloud for compliance checks, container security, and endpoint security capabilities. Azure Defender for SQL servers on machines should be enabled Application security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Enable Azure Defender for Storage: Amazon S3 protection in Amazon GuardDuty: Azure Defender for Azure SQL Database servers should be enabled Note: If required for compliance of data loss prevention (DLP), you can use a host-based DLP solution from Azure Marketplace or a Microsoft 365 DLP solution to enforce detective and/or preventative controls to prevent data exfiltration. https://docs.microsoft.com/azure/storage/common/storage-advanced-threat-protection?tabs=azure-security-center Note: If required for compliance of data loss prevention (DLP), you can use a host-based DLP solution from AWS Marketplace. https://docs.aws.amazon.com/guardduty/latest/ug/s3-protection.html Azure Defender for SQL should be enabled for unprotected SQL Managed Instances Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Azure Defender for SQL should be enabled for unprotected SQL Managed Instances Enable Microsoft Defender for Azure Cosmos DB: https://learn.microsoft.com/azure/defender-for-cloud/defender-for-databases-enable-cosmos-protections?tabs=azure-portal Enable Microsoft Defender for open-source relational databases and respond to alerts: https://learn.microsoft.com/azure/defender-for-cloud/defender-for-databases-usage DP-3 Data Protection 14.4 - Encrypt All Sensitive Information in Transit 3.10 - Encrypt Sensitive Data In Transit SC-8: TRANSMISSION CONFIDENTIALITY AND INTEGRITY 3.5 Encrypt sensitive data in transit Protect the data in transit against 'out of band' attacks (such as traffic capture) using encryption to ensure that attackers cannot easily read or modify the data. Enforce secure transfer in services such as Azure Storage, where a native data in transit encryption feature is built in. Double encryption for Azure data in transit: Enforce secure transfer in services such as Amazon S3, RDS and CloudFront, where a native data in transit encryption feature is built in. TLS security policies in Elastic Load Balancer: CloudFront distributions should require encryption in transit nan Kubernetes clusters should be accessible only over HTTPS 2.1.2 Ensure S3 Bucket Policy is set to deny HTTP requests (Manual) Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 3.6 https://docs.microsoft.com/azure/security/fundamentals/double-encryption#data-in-transit https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html#tls-security-policies Classic Load Balancer listeners should be configured with HTTPS or TLS termination Only secure connections to your Azure Cache for Redis should be enabled 4.1 Set the network boundary and service scope where data in transit encryption is mandatory inside and outside of the network. While this is optional for traffic on private networks, this is critical for traffic on external and public networks. Enforce HTTPS for web application workloads and services by ensuring that any clients connecting to your Azure resources use transport layer security (TLS) v1.2 or later. For remote management of VMs, use SSH (for Linux) or RDP/TLS (for Windows) instead of an unencrypted protocol. Enforce HTTPS (such as in AWS Elastic Load Balancer) for workload web application and services (either on the server side or client side, or on both) by ensuring that any clients connecting to your AWS resources use TLS v1.2 or later. Application load balancers should be configured to drop HTTP headers FTPS only should be required in your Function App Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Understand encryption in transit with Azure: AWS Transfer SFTP and FTPS: Application Load Balancer should be configured to redirect all HTTP requests to HTTPS Secure transfer to storage accounts should be enabled For remote management of Azure virtual machines, use SSH (for Linux) or RDP/TLS (for Windows) instead of an unencrypted protocol. For secure file transfer, use the SFTP/FTPS service in Azure Storage Blob, App Service apps, and Function apps, instead of using the regular FTP service. https://docs.microsoft.com/azure/security/fundamentals/encryption-overview#encryption-of-data-in-transit For remote management of EC2 instances, use SSH (for Linux) or RDP/TLS (for Windows) instead of an unencrypted protocol. For secure file transfer, use AWS Transfer SFTP or FTPS service instead of a regular FTP service. https://aws.amazon.com/aws-transfer-family/getting-started/?pg=ln&amp;cp=bn Connections to Elasticsearch domains should be encrypted using TLS 1.2 FTPS should be required in your Web App Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops S3 buckets should require requests to use Secure Socket Layer Windows web servers should be configured to use secure communication protocols Note: Data in transit encryption is enabled for all Azure traffic traveling between Azure datacenters. TLS v1.2 or later is enabled on most Azure services by default. And some services such as Azure Storage and Application Gateway can enforce TLS v1.2 or later on the server side. Information on TLS Security: Note: All network traffic between AWS data centers is transparently encrypted at the physical layer. All traffic within a VPC and between peered VPCs across regions is transparently encrypted at the network layer when using supported Amazon EC2 instance types. TLS v1.2 or later is enabled on most AWS services by default. And some services such as AWS Load Balancer can enforce TLS v1.2 or later on the server side. Function App should only be accessible over HTTPS Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security https://docs.microsoft.com/security/engineering/solving-tls1-problem Latest TLS version should be used in your API App FTPS only should be required in your API App Enforce secure transfer in Azure storage: Web Application should only be accessible over HTTPS https://docs.microsoft.com/azure/storage/common/storage-require-secure-transfer?toc=/azure/storage/blobs/toc.json#require-secure-transfer-for-a-new-storage-account API App should only be accessible over HTTPS Enforce SSL connection should be enabled for PostgreSQL database servers Enforce SSL connection should be enabled for MySQL database servers Latest TLS version should be used in your Web App Latest TLS version should be used in your Function App DP-4 Data Protection 14.8 - Encrypt Sensitive Information at Rest 3.11 - Encrypt Sensitive Data at Rest SC-28: PROTECTION OF INFORMATION AT REST 3.4 Enable data at rest encryption by default To complement access controls, data at rest should be protected against 'out of band' attacks (such as accessing underlying storage) using encryption. This helps ensure that attackers cannot easily read or modify the data. Many Azure services have data at rest encryption enabled by default at the infrastructure layer using a service-managed key. These service-managed keys are generated on the customer\u2019s behalf and automatically rotated every two years. Understand encryption at rest in Azure: https://docs.microsoft.com/azure/security/fundamentals/encryption-atrest#encryption-at-rest-in-microsoft-cloud-services Many AWS services have data at rest encryption enabled by default at the infrastructure/platform layer using an AWS-managed customer master key. These AWS-managed customer master keys are generated on the customer's behalf and rotated automatically every three years. AWS Protecting Data at Rest: API Gateway REST API cache data should be encrypted at rest nan Virtual machines should encrypt temp disks, caches, and data flows between Compute and Storage resources 2.1.1 Ensure all S3 buckets employ encryption-at-rest (Manual) Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 3.5 https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/protecting-data-at-rest.html CloudTrail should have encryption at rest enabled Transparent Data Encryption on SQL databases should be enabled 2.1.2 Ensure S3 Bucket Policy is set to deny HTTP requests (Manual) Where technically feasible and not enabled by default, you can enable data at rest encryption in the Azure services, or in your VMs at the storage level, file level, or database level. Data at rest double encryption in Azure: https://docs.microsoft.com/azure/security/fundamentals/encryption-models Where technically feasible and not enabled by default, you can enable data at rest encryption in the AWS services, or in your VMs at the storage level, file level, or database level DynamoDB Accelerator (DAX) clusters should be encrypted at rest Automation account variables should be encrypted 2.2.1 Ensure EBS volume encryption is enabled (Manual) Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Attached EBS volumes should be encrypted at rest Service Fabric clusters should have the ClusterProtectionLevel property set to EncryptAndSign 2.3.1 Ensure that encryption is enabled for RDS Instances Encryption model and key management table: EBS default encryption should be enabled (Automated) Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops https://docs.microsoft.com/azure/security/fundamentals/encryption-models Amazon EFS should be configured to encrypt file data at rest using AWS KMS Elasticsearch domains should have encryption at-rest enabled Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security Amazon Elasticsearch Service domains should encrypt data sent between nodes RDS DB instances should have encryption at rest enabled RDS cluster snapshots and database snapshots should be encrypted at rest S3 buckets should have server-side encryption enabled SNS topics should be encrypted at rest using AWS KMS AWS WAF Classic global web ACL logging should be enabled Amazon SQS queues should be encrypted at rest DynamoDB Accelerator (DAX) clusters should be encrypted at rest DP-5 Data Protection 14.8 - Encrypt Sensitive Information at Rest 3.11 - Encrypt Sensitive Data at Rest SC-12: CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT 3.4 Use customer-managed key option in data at rest encryption when required If required for regulatory compliance, define the use case and service scope where customer-managed key option is needed. Enable and implement data at rest encryption using customer-managed key in services. Azure also provides an encryption option using keys managed by yourself (customer-managed keys) for most services. Encryption model and key management table: AWS also provides an encryption option using keys managed by yourself (customer-managed customer master key stored in AWS Key Management Service) for certain services. AWS Services Integrated with AWS KMS: nan nan SQL managed instances should use customer-managed keys to encrypt data at rest nan Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture SC-28: PROTECTION OF INFORMATION AT REST 3.5 https://docs.microsoft.com/azure/security/fundamentals/encryption-models https://aws.amazon.com/kms/features/ SQL servers should use customer-managed keys to encrypt data at rest 3.6 Azure Key Vault Standard, Premium, and Managed HSM are natively integrated with many Azure Services for customer-managed key use cases. You may use Azure Key Vault to generate your key or bring your own keys. AWS Key Management Service (KMS) is natively integrated with many AWS services for customer-managed customer master key use cases. You may either use AWS Key Management Service (KMS) to generate your master keys or bring your own keys. PostgreSQL servers should use customer-managed keys to encrypt data at rest Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Services that support encryption using customer-managed key: https://docs.microsoft.com/azure/security/fundamentals/encryption-models#supporting-services AWS-managed and Customer-managed CMKs: Azure Cosmos DB accounts should use customer-managed keys to encrypt data at rest However, using the customer-managed key option requires additional operational effort to manage the key lifecycle. This may include encryption key generation, rotation, revoke, and access control, etc. However, using the customer-managed key option requires additional operational efforts to manage the key lifecycle. This may include encryption key generation, rotation, revoke, and access control, etc. https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#key-mgmt Container registries should be encrypted with a customer-managed key Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops How to configure customer managed encryption keys in Azure Storage: https://docs.microsoft.com/azure/storage/common/storage-encryption-keys-portal Cognitive Services accounts should enable data encryption with a customer-managed key Storage accounts should use customer-managed key for encryption Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security MySQL servers should use customer-managed keys to encrypt data at rest Azure Machine Learning workspaces should be encrypted with a customer-managed key DP-6 Data Protection nan nan IA-5: AUTHENTICATOR MANAGEMENT 3.6 Use a secure key management process Document and implement an enterprise cryptographic key management standard, processes, and procedures to control your key lifecycle. When there is a need to use customer-managed key in the services, use a secured key vault service for key generation, distribution, and storage. Rotate and revoke your keys based on the defined schedule and when there is a key retirement or compromise. Use Azure Key Vault to create and control your encryption keys life cycle, including key generation, distribution, and storage. Rotate and revoke your keys in Azure Key Vault and your service based on the defined schedule and when there is a key retirement or compromise. Require a certain cryptographic type and minimum key size when generating keys. Azure Key Vault overview: Use AWS Key Management Service (KMS) to create and control your encryption keys life cycle, including key generation, distribution, and storage. Rotate and revoke your keys in KMS and your service based on the defined schedule and when there is a key retirement or compromise. AWS-managed and Customer-managed CMKs: IAM users' access keys should be rotated every 90 days or less nan Key Vault keys should have an expiration date nan Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys SC-12: CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT https://docs.microsoft.com/azure/key-vault/general/overview https://docs.aws.amazon.com/whitepapers/latest/kms-best-practices/aws-managed-and-customer-managed-cmks.html Secrets Manager secrets should have automatic rotation enabled Key Vault secrets should have an expiration date SC-28: PROTECTION OF INFORMATION AT REST When there is a need to use customer-managed key (CMK) in the workload services or applications, ensure you follow the best practices: When there is a need to use customer-managed customer master key in the workload services or applications, ensure you follow the best practices: Secrets Manager secrets configured with automatic rotation should rotate successfully Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture - Use a key hierarchy to generate a separate data encryption key (DEK) with your key encryption key (KEK) in your key vault. Azure data encryption at rest--Key Hierarchy: - Use a key hierarchy to generate a separate data encryption key (DEK) with your key encryption key (KEK) in your KMS. Importing key material in AWS KMS keys: Secrets Manager secrets should be rotated within a specified number of days - Ensure keys are registered with Azure Key Vault and implemented via key IDs in each service or application. https://docs.microsoft.com/azure/security/fundamentals/encryption-atrest#key-hierarchy - Ensure keys are registered with KMS and implement via IAM policies in each service or application. https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops To maximize the key material lifetime and portability, bring your own key (BYOK) to the services (i.e., importing HSM-protected keys from your on-premises HSMs into Azure Key Vault). Follow the recommended guideline to perform the key generation and key transfer. BYOK(Bring Your Own Key) specification: To maximize the key material lifetime and portability, bring your own key (BYOK) to the services (i.e., importing HSM-protected keys from your on-premises HSMs into KMS or Cloud HSM). Follow the recommended guideline to perform the key generation and key transfer. Secure transfer of keys into to CloudHSM: Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security https://docs.microsoft.com/azure/key-vault/keys/byok-specification https://aws.amazon.com/premiumsupport/knowledge-center/cloudhsm-import-keys-openssl/ Note: Refer to the below for the FIPS 140-2 level for Azure Key Vault types and FIPS compliance/validation level. Note: AWS KMS uses shared HSM infrastructure in the backend. Use AWS KMS Custom Key Store backed by AWS CloudHSM when you need to manage your own key store and dedicated HSMs (e.g. regulatory compliance requirement for higher level of key security) to generate and store your encryption keys. - Software-protected keys in vaults (Premium &amp; Standard SKUs):  FIPS 140-2 Level 1 Creating a custom key store backed by CloudHSM: - HSM-protected keys in vaults (Premium SKU): FIPS 140-2 Level 2 Note: Refer to the below for the FIPS 140-2 level for FIPS compliance level in AWS KMS and CloudHSM https://docs.aws.amazon.com/kms/latest/developerguide/key-store-concepts.html - HSM-protected keys in Managed HSM: FIPS 140-2 Level 3 - AWS KMS default: FIPS 140-2 Level 2 validated Azure Key Vault Premium uses a shared HSM infrastructure in the backend. Azure Key Vault Managed HSM uses dedicated, confidential service endpoints with a dedicated HSM for when you need a higher level of key security. - AWS KMS using CloudHSM: FIPS 140-2 Level 3 (for certain services)  validated - AWS CloudHSM: FIPS 140-2 Level 3  validated Note: For secrets management(credentials, password, API keys etc.), use AWS Secrets Manager. DP-7 Data Protection nan nan IA-5: AUTHENTICATOR MANAGEMENT 3.6 Use a secure certificate management process Document and implement an enterprise certificate management standard, processes and procedures which includes the certificate lifecycle control, and certificate policies (if a public key infrastructure is needed). Use Azure Key Vault to create and control the certificate lifecycle, including the creation/import, rotation, revocation, storage, and purge of the certificate. Ensure the certificate generation follows the defined standard without using any insecure properties, such as insufficient key size, overly long validity period, insecure cryptography and so on. Setup automatic rotation of the certificate in Azure Key Vault and supported Azure services based on the defined schedule and when a certificate expires. If automatic rotation is not supported in the frontend application, use a manual rotation in Azure Key Vault. Get started with Key Vault certificates: Use AWS Certificate Manager (ACM) to create and control the certificate lifecycle, including creation/import, rotation, revocation, storage, and purge of the certificate. Ensure the certificate generation follows the defined standard without using any insecure properties, such as insufficient key size, overly long validity period, insecure cryptography and so on. Setup automatic rotation of the certificate in ACM and supported AWS services based on the defined schedule and when a certificate expires. If automatic rotation is not supported in the frontend application, use manual rotation in ACM. In the meantime, you should always track your certificate renewal status to ensure the certificate validity. AWS Certificate Manager - Check a certificate's renewal status: [CloudFront.7] CloudFront distributions should use custom SSL/TLS certificates nan [Preview]: Certificates should have the specified maximum validity period nan Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys SC-12: CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT https://docs.microsoft.com/azure/key-vault/certificates/certificate-scenarios https://docs.aws.amazon.com/acm/latest/userguide/check-certificate-renewal-status.html SC-17: PUBLIC KEY INFRASTRUCTURE CERTIFICATES Ensure certificates used by the critical services in your organization are inventoried, tracked, monitored, and renewed timely using automated mechanism to avoid service disruption. Avoid using a self-signed certificate and wildcard certificate in your critical services due to the limited security assurance. Instead, you can create public signed certificates in Azure Key Vault. The following Certificate Authorities (CAs) are the partnered providers that are currently integrated with Azure Key Vault. Avoid using a self-signed certificate and wildcard certificate in your critical services due to the limited security assurance. Instead, create public-signed certificates (signed by the Amazon Certificate Authority) in ACM and deploy it programmatically in services such as CloudFront, Load Balancers, API Gateway etc. You also can use ACM to establish your private certificate authority (CA) to sign the private certificates. Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture - DigiCert: Azure Key Vault offers OV TLS/SSL certificates with DigiCert. Certificate Access Control in Azure Key Vault: - GlobalSign: Azure Key Vault offers OV TLS/SSL certificates with GlobalSign. https://docs.microsoft.com/azure/key-vault/certificates/certificate-access-control Note: Use only an approved CA and ensure that known bad CA root/intermediate certificates issued by these CAs are disabled. Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Note: Use only approved CA and ensure that known bad root/intermediate certificates issued by these CAs are disabled. Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security DP-8 Data Protection nan nan IA-5: AUTHENTICATOR MANAGEMENT 3.6 Ensure security of key and certificate repository Ensure the security of the key vault service used for the cryptographic key and certificate lifecycle management. Harden your key vault service through access control, network security, logging and monitoring and backup to ensure keys and certificates are always protected using the maximum security. Secure your cryptographic keys and certificates by hardening your Azure Key Vault service through the following controls: Azure Key Vault overview: For cryptographic keys security, secure your keys by hardening your AWS Key Management Service (KMS) service through the following controls: Security best practice for AWS Key Management Service: IAM customer managed policies should not allow decryption actions on all KMS keys nan Key vaults should have purge protection enabled nan Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys SC-12: CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT - Implement access control using RBAC policies in Azure Key Vault Managed HSM at the key level to ensure the least privilege and separation of duties principles are followed. For example, ensure separation of duties are in place for users who manage encryption keys so they do not have the ability to access encrypted data, and vice versa. For Azure Key Vault Standard and Premium, create unique vaults for different applications to ensure the least privilege and separation of duties principles are followed. https://docs.microsoft.com/azure/key-vault/general/overview - Implement access control using key policies (key-level access control) in conjunction with IAM policies (identity-based access control) to ensure the least privilege and separation of duties principles are followed. For example, ensure separation of duties are in place for users who manage encryption keys so they do not have the ability to access encrypted data, and vice versa. https://docs.aws.amazon.com/kms/latest/developerguide/best-practices.html IAM principals should not have IAM inline policies that allow decryption actions on all KMS keys Azure Defender for Key Vault should be enabled SC-17: PUBLIC KEY INFRASTRUCTURE CERTIFICATES - Turn on Azure Key Vault logging to ensure critical management plane and data plane activities are logged. - Use detective controls such as CloudTrails to log and track the usage of keys in KMS and alert you on critical actions. AWS KMS keys should not be unintentionally deleted Key vaults should have soft delete enabled Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture - Secure the Azure Key Vault using Private Link and Azure Firewall to ensure minimal exposure of the service Azure Key Vault security best practices: - Never store keys in plaintext format outside of KMS. Security in AWS Certificate Manager: [Preview]: Azure Key Vault should disable public network access - Use managed identity to access keys stored in Azure Key Vault in your workload applications. https://docs.microsoft.com/azure/key-vault/general/best-practices - When keys need to be deleted, consider disabling keys in KMS instead of deleting them to avoid accidental deletion of keys and cryptographic erasure of data. https://docs.aws.amazon.com/acm/latest/userguide/security.html [Preview]: Private endpoint should be configured for Key Vault Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops - When purging data, ensure your keys are not deleted before the actual data, backups and archives are purged. - When purging data, ensure your keys are not deleted before the actual data, backups and archives are purged. Resource logs in Key Vault should be enabled - Backup your keys and certificates using Azure Key Vault. Enable soft delete and purge protection to avoid accidental deletion of keys.When keys need to be deleted, consider disabling keys instead of deleting them to avoid accidental deletion of keys and cryptographic erasure of  data. Use managed identity to access Azure Key Vault: - For bring your own key (BYOK) uses cases, generate keys in an on-premise HSM and import them to maximize the lifetime and portability of  the keys. Data Security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-data-security - For bring your own key (BYOK) use cases, generate keys in an on-premises HSM and import them to maximize the lifetime and portability of the keys. https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/tutorial-windows-vm-access-nonaad - Never store keys in plaintext format outside of the Azure Key Vault. Keys in all key vault services are not exportable by default. For certificates security, secure your certificates by hardening your AWS Certificate Manager (ACM) service through the following controls: - Use HSM-backed key types (RSA-HSM) in Azure Key Vault Premium and Azure Managed HSM for the hardware protection and the strongest FIPS levels. Overview of Microsoft Defender for Key Vault: - Implement access control using resource-level policies in conjunction with IAM policies (identity-based access control) to ensure the least privilege and separation of duties principles are followed. For example, ensure separation of duties is in place for user accounts: user accounts who generate certificates are separate from the user accounts who only require read-only access to certificates. https://learn.microsoft.com/azure/defender-for-cloud/defender-for-key-vault-introduction - Use detective controls such as CloudTrails to log and track the usage of the certificates in ACM, and alert you on critical actions. Enable Microsoft Defender for Key Vault for Azure-native, advanced threat protection for Azure Key Vault, providing an additional layer of security intelligence. - Follow the KMS security guidance to secure your private key (generated for certificate request) used for service certificate integration."},{"location":"Azure/Security/MCSB/DevOps%20Security/","title":"MCSB_v1 - DevOps Security","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Azure Implementation and additional context AWS Guidance AWS Implementation and additional context Customer Security Stakeholders: DS-1 DevOps Security nan 16.10 - Apply Secure Design Principles in Application Architectures SA-15: DEVELOPMENT PROCESS, STANDARDS, AND TOOLS 6.5 Conduct threat modeling Perform threat modeling to identify the potential threats and enumerate the mitigating controls. Ensure your threat modeling serves the following purposes: Use threat modeling tools such as the Microsoft threat modeling tool with the Azure threat model template embedded to drive your threat modeling process. Use the STRIDE model to enumerate the  threats from both internal and external and identify the controls applicable. Ensure the threat modeling process includes the threat scenarios in the DevOps process, such as malicious code injection through an insecure artifacts repository with misconfigured access control policy. Threat Modeling Overview: Use threat modeling tools such as the Microsoft threat modeling tool with the Azure threat model template embedded to drive your threat modeling process. Use the STRIDE model to enumerate the threats from both internal and external and identify the controls applicable. Ensure the threat modeling process includes the threat scenarios in the DevOps process, such as malicious code injection through an insecure artifacts repository with misconfigured access control policy. Microsoft Threat Modeling Tool: Policy and standards: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-policy-standards 16.14 - Conduct Threat Modeling 12.2 https://www.microsoft.com/securityengineering/sdl/threatmodeling https://docs.microsoft.com/en-us/azure/security/develop/threat-modeling-tool Secure your applications and services in the production run-time stage. If using a threat modeling tool is not applicable, you should, at minimum, use a questionnaire-based threat modeling process to identify the threats. If using a threat modeling tool is not applicable, you should, at minimum, use a questionnaire-based threat modeling process to identify the threats. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Secure the artifacts, underlying CI/CD pipeline and other tooling environment used for build, test, and deployment. The threat modeling at least should include the following aspects: Application threat analysis (including STRIDE + questionnaire based method): How to approach threat modeling for AWS: Define the security requirements of the application. Ensure these requirements are adequately addressed in the threat modeling. Ensure the threat modeling or analysis results are recorded and updated when there is a major security-impact change in your application or in the threat landscape. https://docs.microsoft.com/azure/architecture/framework/security/design-threat-model Ensure the threat modeling or analysis results are recorded and updated when there is a major security-impact change in your application or in the threat landscape. https://aws.amazon.com/blogs/security/how-to-approach-threat-modeling/ Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management Analyze application components, data connections and their relationship. Ensure this analysis also includes the upstream and downstream connections outside of your application scope. List the potential threats and attack vectors that your application components, data connections and upstream and downstream services may be exposed to. Azure Template - Microsoft Security Threat Model Stencil: Application threat analysis (including STRIDE + questionnaire based method): Identify the applicable security controls that can be used to mitigate the threats enumerated and identify any controls gaps (e.g., security vulnerabilities) that may require additional treatment plans. https://github.com/AzureArchitecture/threat-model-templates https://docs.microsoft.com/azure/architecture/framework/security/design-threat-model Enumerate and design the controls that can mitigate the vulnerabilities identified. DS-2 DevOps Security 18.3 - Verify That Acquired Software is Still Supported 16.4 - Establish and Manage an Inventory of Third-Party Software Components SA-12: SUPPLY CHAIN PROTECTION 6.3 Ensure software supply chain security Ensure your enterprise\u2019s SDLC (Software Development Lifecycle) or process include a set of security controls to govern the in-house and third-party software components (including both proprietary and open-source software) where your applications have dependencies. Define gating criteria to prevent vulnerable or malicious components being integrated and deployed into the environment. For the GitHub platform, ensure the software supply chain security through the following capability or tools from GitHub Advanced Security or GitHub\u2019s native feature:- Use Dependency Graph to scan, inventory and identify all your project\u2019s dependencies and related vulnerabilities through Advisory Database. GitHub Dependency Graph: If you use AWS CI/CD platforms such as CodeCommit or CodePipeline, ensure the software supply chain security using CodeGuru Reviewer to scan the source code (for Java and Python) through the CI/CD workflows. Platforms such as CodeCommit and CodePipeline also supports third-party extensions to implement similar controls to inventory, analyze and remediate the third-party software components and their vulnerabilities. GitHub Dependency Graph: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 18.4 - Only Use Up-to-Date And Trusted Third-Party Components 16.6 - Establish and Maintain a Severity Rating System and Process for Application Vulnerabilities SA-15: DEVELOPMENT PROCESS, STANDARDS, AND TOOLS 6.5 https://docs.github.com/en/code-security/supply-chain-security/understanding-your-software-supply-chain/about-the-dependency-graph https://docs.github.com/en/code-security/supply-chain-security/understanding-your-software-supply-chain/about-the-dependency-graph 18.8 - Establish a Process to Accept and Address Reports of Software Vulnerabilities 16.11 - Leverage Vetted Modules or Services for Application Security Components The software supply chain security controls should at least include the following aspects: - Use Dependabot to ensure that the vulnerable dependency is tracked and remediated, and ensure your repository automatically keeps up with the latest releases of the packages and applications it depends on. If you manage your source code through the GitHub platform, ensure the software supply chain security through the following capability or tools from GitHub Advanced Security or GitHub\u2019s native feature: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Use GitHub's native code scanning capability to scan the source code when sourcing the code externally. GitHub Dependabot: - Use Dependency Graph to scan, inventory and identify all your project\u2019s dependencies and related vulnerabilities through Advisory Database. GitHub Dependabot: Properly manage a Software Bill of Materials (SBOM) by identifying the upstream dependencies required for the service/resource development, build, integration and deployment phase. - Use Microsoft Defender for Cloud to integrate vulnerability assessment for your container image in the CI/CD workflow. https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically/about-dependabot-version-updates - Use Dependabot to ensure that the vulnerable dependency is tracked and remediated, and ensure your repository automatically keeps up with the latest releases of the packages and applications it depends on. https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically/about-dependabot-version-updates Inventory and track the in-house and third-party software components for known vulnerability when there is a fix available in the upstream. For Azure DevOps, you can use third-party extensions to implement similar controls to inventory, analyze and remediate the third-party software components and their vulnerabilities - Use GitHub's native code scanning capability to scan the source code when sourcing the code externally. Assess the vulnerabilities and malware in the software components using static and dynamic application testing for unknown vulnerabilities. Identify vulnerable container images in your CI/CD workflows: - If applicable, use Microsoft Defender for Cloud to integrate vulnerability assessment for your container image in the CI/CD workflow. DevOps in AWS: Ensure the vulnerabilities and malware are mitigated using the appropriate approach. This may include source code local or upstream fix, feature exclusion and/or applying compensating controls if the direct mitigation is not available. https://docs.microsoft.com/azure/security-center/defender-for-container-registries-cicd https://aws.amazon.com/devops/ If closed source third-party components are used in your production environment, you may have limited visibility to its security posture. You should consider additional controls such as access control, network isolation and endpoint security to minimize the impact if there is a malicious activity or vulnerability associated with the component. Azure DevOps Marketplace \u2013 supply chain security: Software Bill of Materials: https://marketplace.visualstudio.com/search?term=tag%3ASupply%20Chain%20Security&amp;target=VSTS https://www.cisa.gov/sbom DS-3 DevOps Security 18.11 - Use Standard Hardening Configuration Templates for Databases 16.7 - Use Standard Hardening Configuration Templates for Application Infrastructure CM-2: BASELINE CONFIGURATION 2.2 Secure DevOps infrastructure Ensure the DevOps infrastructure and pipeline follow security best practices across environments including your build, test, and production stages. This typically includes the security controls for following scope: As part of applying the Microsoft Cloud Security Benchmark to your DevOps infrastructure security controls, prioritize the following controls: DevSecOps controls overview \u2013 secure pipelines: As part of applying the Microsoft Cloud Security Benchmark to the security controls of your DevOps infrastructure, such as GitHub, CodeCommit, CodeArtifact, CodePipeline, CodeBuild and CodeDeploy, prioritize the following controls: AWS Well-architected Framework - security pillar: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops CM-6: CONFIGURATION SETTINGS 6.3 - Protect artifacts and the underlying environment to ensure the CI/CD pipelines don\u2019t become avenues to insert malicious code. For example, review your CI/CD pipeline to identify any misconfiguration in core areas of Azure DevOps such as Organization, Projects, Users, Pipelines (Build &amp; Release), Connections, and Build Agent to identify any misconfigurations such as open access, weak authentication, insecure connection setup and so on. For GitHub, use similar controls to secure the Organization permission levels. https://docs.microsoft.com/azure/cloud-adoption-framework/secure/devsecops-controls - Refer to this guidance and the AWS Well-architected Framework security pillar to secure your DevOps environments in AWS. https://wa.aws.amazon.com/wat.pillar.security.en.html AC-2: ACCOUNT MANAGEMENT 7.1 - Artifact repositories that store source code, built packages and images, project artifacts and business data. - Ensure your DevOps infrastructure is deployed consistently across development projects. Track compliance of your DevOps infrastructure at scale by using Microsoft Defender for Cloud (such as Compliance Dashboard, Azure Policy, Cloud Posture Management) or your own compliance monitoring tools. - Protect artifacts and the underlying supporting infrastructure to ensure the CI/CD pipelines don\u2019t become avenues to insert malicious code. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management AC-3: ACCESS ENFORCEMENT - Servers, services, and tooling that host CI/CD pipelines. - Configure identity/role permissions and entitlement policies in Azure AD, native services, and CI/CD tools in your pipeline to ensure changes to the pipelines are authorized. Secure your GitHub organization: - Ensure your DevOps infrastructure is deployed and sustained consistently across development projects. Track compliance of your DevOps infrastructure at scale by using AWS Config or your own compliance check solution. AC-6: LEAST PRIVILEGE - CI/CD pipeline configuration. - Avoid providing permanent \u201cstanding\u201d privileged access to the human accounts such as developers or testers by using features such as Azure managed identifies and just-in-time access. https://docs.github.com/en/code-security/getting-started/securing-your-organization - Use CodeArtifact to securely store and share software packages used for application development. You can use CodeArtifact with popular build tools and package managers such as Maven, Gradle, npm, yarn, pip, and twine. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint - Remove keys, credentials, and secrets from code and scripts used in CI/CD workflow jobs and keep them in a key store or Azure Key Vault. - Configure identity/role permissions and permission policies in AWS IAM, native services, and CI/CD tools in your pipeline to ensure changes to the pipelines are authorized. - If you run self-hosted build/deployment agents, follow Microsoft Cloud Security Benchmark controls including network security, posture and vulnerability management, and endpoint security to secure your environment. Azure DevOps pipeline \u2013 Microsoft hosted agent security considerations: - Remove keys, credentials, and secrets from code and scripts used in CI/CD workflow jobs and keep them in key store or AWS KMS Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture https://docs.microsoft.com/azure/devops/pipelines/agents/hosted?view=azure-devops&amp;tabs=yaml#security - If you run self-hosted build/deployment agents, follow Microsoft Cloud Security Benchmark controls including network security, posture and vulnerability management, and endpoint security to secure your environment. Use AWS Inspector for vulnerability scanning for vulnerabilities in EC2 or containerized environment as the build environment. Note: Refer to the Logging and Threat Detection, DS-7, and the Posture and Vulnerability Management sections to use services such as Azure Monitor and Microsoft Sentinel to enable governance, compliance, operational auditing, and risk auditing for your DevOps infrastructure. Note: Refer to the Logging and Threat Detection, DS-7, and the and Posture and Vulnerability Management sections to use services such as AWS CloudTrail, CloudWatch and Microsoft Sentinel to enable governance, compliance, operational auditing, and risk auditing for your DevOps infrastructure. DS-4 DevOps Security 18.7 - Apply Static and Dynamic Code Analysis Tools 16.12 - Implement Code-Level Security Checks SA-11: DEVELOPER TESTING AND EVALUATION 6.3 Integrate static application security testing into DevOps pipeline Ensure static application security testing (SAST) fuzzy testing, interactive testing, mobile application testing, are part of the gating controls in the CI/CD workflow. The gating can be set based on the testing results to prevent vulnerable packages from committing into the repository, building into the packages, or deploying into the production. Integrate SAST into your pipeline (e.g., in your infrastructure as code template) so the source code can be scanned automatically in your CI/CD workflow. Azure DevOps Pipeline or GitHub can integrate the  below tools and third-party SAST tools into the workflow. GitHub CodeQL: Integrate SAST into your pipeline so the source code can be scanned automatically in your CI/CD workflow. Building end-to-end AWS DevSecOps CI/CD pipeline with open source SCA, SAST and DAST tools: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 6.5 - GitHub CodeQL for source code analysis. https://codeql.github.com/docs/ https://aws.amazon.com/blogs/devops/building-end-to-end-aws-devsecops-ci-cd-pipeline-with-open-source-sca-sast-and-dast-tools/ - Microsoft BinSkim Binary Analyzer for Windows and *nix binary analysis. If using AWS CodeCommit, use AWS CodeGuru Reviewer for Python and Java source code analysis. AWS Codepipeline can also support integration of third-part SAST tools into the code deployment pipeline. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Azure DevOps Credential Scanner (Microsoft Security DevOps extension) and GitHub native secret scanning for credential scan in the source code. BinSkim Binary Analyzer: https://github.com/microsoft/binskim If using GitHub, the below tools and third-party SAST tools can be integrated into the workflow. - GitHub CodeQL for source code analysis. Azure DevOps Credential Scan: - Microsoft BinSkim Binary Analyzer for Windows and *nix binary analysis. https://secdevtools.azurewebsites.net/helpcredscan.html - GitHub native secret scanning for credential scan in the source code. - AWS CodeGuru Reviewer for Python and Java source code analysis. GitHub secret scanning: https://docs.github.com/en/code-security/secret-security/about-secret-scanning DS-5 DevOps Security 18.7 - Apply Static and Dynamic Code Analysis Tools 16.12 - Implement Code-Level Security Checks SA-11: DEVELOPER TESTING AND EVALUATION 6.3 Integrate dynamic application security testing into DevOps pipeline Ensure dynamic application security testing (DAST) are part of the gating controls in the CI/CD workflow. The gating can be set based on the testing results to prevent vulnerability from building into the packages or deploying into the production. Integrate DAST into your pipeline so the runtime application can be tested automatically in your CI/CD workflow set in Azure DevOps or GitHub. The automated penetration testing (with manual assisted validation) should also be part of the DAST. DAST tools in Azure DevOps marketplace: Integrate DAST into your pipeline so the runtime application can be tested automatically in your CI/CD workflow set in AWS CodePipeline or GitHub. The automated penetration testing (with manual assisted validation) should also be part of the DAST. Building end-to-end AWS DevSecOps CI/CD pipeline with open source SCA, SAST and DAST tools: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 6.5 https://marketplace.visualstudio.com/search?term=DAST&amp;target=AzureDevOps&amp;category=All%20categories https://aws.amazon.com/blogs/devops/building-end-to-end-aws-devsecops-ci-cd-pipeline-with-open-source-sca-sast-and-dast-tools/ Azure DevOps Pipeline or GitHub supports the integration of third-party DAST tools into the CI/CD workflow. AWS CodePipeline or GitHub supports integration of third-party DAST tools into the CI/CD workflow. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management DS-6 DevOps Security 5.2 - Deploy System Configuration Management Tools 7.5 - Perform Automated Vulnerability Scans of Internal Enterprise Assets CM-2: BASELINE CONFIGURATION 6.1 Enforce security of workload throughout DevOps lifecycle Ensure the workload is secured throughout the entire lifecycle in development, testing, and deployment stage. Use Microsoft Cloud Security Benchmark to evaluate the controls (such as network security, identity management, privileged access and so on) that can be set as guardrails by default or shift left prior to the deployment stage. In particular, ensure the following controls are in place in your DevOps process: Guidance for Azure VMs: Shared Image Gallery overview: Use Amazon Elastic Container Registry to share and control access to your images by different users and roles within your organization. And Use AWS IAM to ensure that only authorized users can access your custom images. AWS ECR image scanning: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 5.3 - Securely Store Master Images 7.6 - Perform Automated Vulnerability Scans of Externally-Exposed Enterprise Assets CM-6: CONFIGURATION SETTINGS 6.2 - Automate the deployment by using Azure or third-party tooling in the CI/CD workflow, infrastructure management (infrastructure as code), and testing to reduce human error and attack surface. - Use Azure Shared Image Gallery to share and control access to your images by different users, service principals, or AD groups within your organization. Use Azure role-based access control (Azure RBAC) to ensure that only authorized users can access your custom images. https://docs.microsoft.com/azure/virtual-machines/windows/shared-image-galleries https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html 5.4 - Deploy System Configuration Management Tools 7.7 - Remediate Detected Vulnerabilities AC-2: ACCOUNT MANAGEMENT 6.3 - Ensure VMs, container images and other artifacts are secure from malicious manipulation. - Define the secure configuration baselines for the VMs to eliminate unnecessary credentials, permissions, and packages. Deploy and enforce configuration baselines through custom images, Azure Resource Manager templates, and/or Azure Policy guest configuration. Define the secure configuration baselines for the EC2 AMI images to eliminate unnecessary credentials, permissions, and packages. Deploy and enforce configurations baselines through custom AMI images, CloudFormation templates, and/or AWS Config Rules. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 5.5 - Implement Automated Configuration Monitoring Systems 16.1 - Establish and Maintain a Secure Application Development Process AC-3: ACCESS ENFORCEMENT - Scan the workload artifacts (in other words, container images, dependencies, SAST and DAST scans) prior to the deployment in the CI/CD workflow How to implement Microsoft Defender for Cloud vulnerability assessment recommendations: https://docs.microsoft.com/azure/security-center/security-center-vulnerability-assessment-recommendations AWS Inspector: 18.1 - Establish Secure Coding Practices 16.7 - Use Standard Hardening Configuration Templates for Application Infrastructure AC-6: LEAST PRIVILEGE - Deploy vulnerability assessment and threat detection capability into the production environment and continuously use these capabilities in the run-time. Guidance for Azure container services: Use AWS Inspector for vulnerability scanning of VM's and Containerized environments, securing them from malicious manipulation. https://docs.aws.amazon.com/inspector/latest/user/getting_started_tutorial.html Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture - Use Azure Container Registry (ACR) to create your private container registry where granular access can be restricted through Azure RBAC, so only authorized services and accounts can access the containers in the private registry. Security considerations for Azure Container: - Use Defender for Containers for vulnerability assessment of the images in your private Azure Container Registry. In addition, you can use Microsoft Defender for Cloud to integrate the container image scans as part of your CI/CD workflows. https://docs.microsoft.com/azure/container-instances/container-instances-image-security For AWS serverless services, use AWS CodePipeline in conjunction with AWS AppConfig to adopt similar controls to ensure security controls \"shift left\" to the stage prior to deployment. AWS AppConfig: https://docs.aws.amazon.com/appconfig/latest/userguide/getting-started-with-appconfig.html For Azure serverless services, adopt similar controls to ensure security controls \"shift-left\" to the stage prior to deployment. Azure Defender for container registries: https://docs.microsoft.com/azure/security-center/defender-for-container-registries-introduction DS-7 DevOps Security 6.2 - Activate audit logging 8.2 Collect Audit Logs AU-3: CONTENT OF AUDIT RECORDS 10.1 Enable logging and monitoring in DevOps Ensure your logging and monitoring scope includes non-production environments and CI/CD workflow elements used in DevOps (and any other development processes). The vulnerabilities and threats targeting these environments can introduce significant risks to your production environment if they are not monitored properly. The events from the CI/CD build, test and deployment workflow should also be monitored to identify any deviations in the CI/CD workflow jobs. Enable and configure the audit logging capabilities in non-production and CI/CD tooling environments (such as Azure DevOps and GitHub) used throughout the DevOps process. Azure DevOps - audit streaming: Enable and configure AWS CloudTrail for audit logging capabilities in non-production and CI/CD tooling environments (such as AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy, AWS CodeStar) used throughout the DevOps process. Connect Microsoft Sentinel to Amazon Web Services to ingest AWS service log data: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center 6.3 - Enable Detailed Logging 8.5 Collect Detailed Audit Logs AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING 10.2 https://docs.microsoft.com/azure/devops/organizations/audit/auditing-streaming?view=azure-devops https://docs.microsoft.com/en-us/azure/sentinel/connect-aws?tabs=s3 6.5 - Central Log Management 8.9 Centralize Audit Logs AU-12: AUDIT GENERATION 10.3 Follow Microsoft Cloud Security Benchmark \u2013 Logging and Threat Detection as the guideline to implement your logging and monitoring controls for workload. The events generated from Azure DevOps and the GitHub CI/CD workflow, including the build, test and deployment jobs, should also be monitored to identify any anomalous results. The events generated from the AWS CI/CD environments (such as AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy, AWS CodeStar) and the GitHub CI/CD workflow, including the build, test and deployment jobs, should also be monitored to identify any anomalous results. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 6.6 - Deploy SIEM or Log Analytic tool 8.11 Conduct Audit Log Reviews SI-4: INFORMATION SYSTEM MONITORING 10.6 GitHub logging: GitHub Logging: 6.7 - Regularly Review Logs Ingest the above logs and events into Microsoft Sentinel or other SIEM tools through a logging stream or API to ensure the security incidents are properly monitored and triaged for handling. https://docs.github.com/en/organizations/keeping-your-organization-secure/reviewing-the-audit-log-for-your-organization Ingest the above logs and events into AWS CloudWatch, Microsoft Sentinel or other SIEM tools through a logging stream or API to ensure the security incidents are properly monitored and triaged for handling. https://docs.github.com/en/organizations/keeping-your-organization-secure/reviewing-the-audit-log-for-your-organization Incident preparation: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation 6.8 - Regularly Tune SIEM"},{"location":"Azure/Security/MCSB/Endpoint%20Security/","title":"MCSB_v1 - Endpoint Security","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 Customer Security Stakeholders: ES-1 Endpoint security 9.4 - Apply Host-Based Firewalls or Port Filtering 13.7 - Deploy a Host-Based Intrusion Prevention Solution SC-3: SECURITY FUNCTION ISOLATION 11.5 Use Endpoint Detection and Response (EDR) Enable Endpoint Detection and Response (EDR) capabilities for VMs and integrate with SIEM and security operations processes. Microsoft Defender for servers (with Microsoft Defender for Endpoint integrated) provides EDR capability to prevent, detect, investigate, and respond to advanced threats. Microsoft Defender for servers introduction: Onboard your AWS account into Microsoft Defender for Cloud and deploy Microsoft Defender for servers (with Microsoft Defender for Endpoint integrated) on your EC2 instances to provide EDR capabilities to prevent, detect, investigate, and respond to advanced threats. Protect your endpoints with Defender for Cloud's integrated EDR solution: Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security SI-2: FLAW REMEDIATION https://docs.microsoft.com/azure/security-center/defender-for-servers-introduction https://docs.microsoft.com/en-us/azure/defender-for-cloud/integration-defender-for-endpoint?tabs=windows SI-3: MALICIOUS CODE PROTECTION Use Microsoft Defender for Cloud to deploy Microsoft Defender for servers on your endpoints and integrate the alerts to your SIEM solution such as Microsoft Sentinel. Alternatively, use Amazon GuardDuty integrated threat intelligence capability to monitor and protect your EC2 instances. Amazon GuardDuty can detect anomalous activities such as activity indicating an instance compromise, such as cryptocurrency mining, malware using domain generation algorithms (DGAs), outbound denial of service activity, unusually high volume of network traffic, unusual network protocols, outbound instance communication with a known malicious IP, temporary Amazon EC2 credentials use by an external IP address, and data exfiltration using DNS. Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence SI-16 MEMORY PROTECTION Microsoft Defender for Endpoint overview: https://docs.microsoft.com/microsoft-365/security/defender-endpoint/microsoft-defender-endpoint?view=o365-worldwide Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Microsoft Defender for Cloud feature coverage for machines: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management https://docs.microsoft.com/azure/security-center/security-center-services?tabs=features-windows Connector for Defender for servers integration into SIEM: https://docs.microsoft.com/azure/security-center/security-center-wdatp?WT.mc_id=Portal-Microsoft_Azure_Security_CloudNativeCompute&amp;tabs=windows ES-2 Endpoint security 8.1 - Utilize Centrally Managed Anti-malware Software 10.1 - Deploy and Maintain Anti-Malware Software SC-3: SECURITY FUNCTION ISOLATION 5.1 Use modern anti-malware software Use anti-malware solutions (also known as endpoint protection) capable of real-time protection and periodic scanning. Microsoft Defender for Cloud can automatically identify the use of a number of popular anti-malware solutions for your virtual machines and on-premises machines with Azure Arc configured and report the endpoint protection running status and make recommendations. Supported endpoint protection solutions: Onboard your AWS account into Microsoft Defender for Cloud to allow Microsoft Defender for Cloud to automatically identify the use some popular anti-malware solutions for EC2 instances with Azure Arc configured and report the endpoint protection running status and make recommendations. https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_finding-types-ec2.html Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security SI-2: FLAW REMEDIATION https://docs.microsoft.com/azure/security-center/security-center-services?tabs=features-windows#supported-endpoint-protection-solutions- SI-3: MALICIOUS CODE PROTECTION Microsoft Defender Antivirus is the default anti-malware solution for Windows server 2016 and above. For Windows server 2012 R2, use Microsoft Antimalware extension to enable SCEP (System Center Endpoint Protection).   For Linux VMs, use Microsoft Defender for Endpoint on Linux for the endpoint protection feature. Deploy Microsoft Defender Antivirus which is the default anti-malware solution for Windows server 2016 and above. For EC2 instances running Windows server 2012 R2, use Microsoft Antimalware extension to enable SCEP (System Center Endpoint Protection). For EC2 instances running Linux, use Microsoft Defender for Endpoint on Linux for the endpoint protection feature. Microsoft Defender supported endpoint protection solutions: Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence SI-16 MEMORY PROTECTION How to configure Microsoft Antimalware for Cloud Services and virtual machines: https://docs.microsoft.com/en-us/azure/defender-for-cloud/supported-machines-endpoint-solutions-clouds-servers?tabs=features-windows#supported-endpoint-protection-solutions- For both Windows and Linux, you can use Microsoft Defender for Cloud to discover and assess the health status of the anti-malware solution. https://docs.microsoft.com/azure/security/fundamentals/antimalware For both Windows and Linux, you can use Microsoft Defender for Cloud to discover and assess the health status of the anti-malware solution. Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Endpoint protection recommendations in Microsoft Defender for Clouds: Note: You can also use Microsoft Defender for Cloud's Defender for Storage to detect malware uploaded to Azure Storage accounts. Note: Microsoft Defender Cloud also supports certain third-party endpoint protection products for the discovery and health status assessment. https://docs.microsoft.com/en-us/azure/defender-for-cloud/endpoint-protection-recommendations-technical Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management ES-3 Endpoint security 8.2 - Ensure Anti-Malware Software and Signatures are Updated 10.2 - Configure Automatic Anti-Malware Signature Updates SI-2: FLAW REMEDIATION 5.2 Ensure anti-malware software and signatures are updated Ensure anti-malware signatures are updated rapidly and consistently for the anti-malware solution. Follow recommendations in Microsoft Defender for Cloud to keep all endpoints up to date with the latest signatures. Microsoft Antimalware (for Windows) and Microsoft Defender for Endpoint (for Linux) will automatically install the latest signatures and engine updates by default. How to deploy Microsoft Antimalware for Cloud Services and virtual machine: With your AWS account onboarded into Microsoft Defender for Cloud, follow recommendations in Microsoft Defender for Cloud to keep all endpoints up to date with the latest signatures. Microsoft Antimalware (for Windows) and Microsoft Defender for Endpoint (for Linux) will automatically install the latest signatures and engine updates by default. Connect your AWS accounts to Microsoft Defender for Cloud: Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security SI-3: MALICIOUS CODE PROTECTION 5.3 https://docs.microsoft.com/azure/security/fundamentals/antimalware https://docs.microsoft.com/en-us/azure/defender-for-cloud/quickstart-onboard-aws?pivots=env-settings For third-party solutions, ensure the signatures are updated in the third-party anti-malware solution. For third-party solutions, ensure the signatures are updated in the third-party anti-malware solution. Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence Endpoint protection assessment and recommendations in Microsoft Defender for Cloud: https://docs.microsoft.com/azure/security-center/security-center-endpoint-protection Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management"},{"location":"Azure/Security/MCSB/Governance%20and%20Strategy/","title":"MCSB_v1 - Governance and Strategy","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle General Guidance Implementation and additional context Customer Security Stakeholders: GS-1 Governance and Strategy 17.2 - Deliver Training to Fill the Skills Gap 14.9 - Conduct Role-Specific Security Awareness and Skills Training PL-9: CENTRAL MANAGEMENT 12.4 Align organization roles, responsibilities and accountabilities N/A Ensure that you define and communicate a clear strategy for roles and responsibilities in your security organization. Prioritize providing clear accountability for security decisions, educating everyone on the shared responsibility model, and educate technical teams on technology to secure the cloud. Azure Security Best Practice 1 \u2013 People: Educate Teams on Cloud Security Journey: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions PM-10: SECURITY AUTHORIZATION PROCESS https://docs.microsoft.com/azure/cloud-adoption-framework/security/security-top-10#1-people-educate-teams-about-the-cloud-security-journey PM-13: INFORMATION SECURITY WORKFORCE AT-1: SECURITY AWARENESS AND TRAINING POLICY AND PROCEDURES Azure Security Best Practice 2 - People: Educate Teams on Cloud Security Technology: AT-3: ROLE-BASED SECURITY TRAINING https://docs.microsoft.com/azure/cloud-adoption-framework/security/security-top-10#2-people-educate-teams-on-cloud-security-technology Azure Security Best Practice 3 - Process: Assign Accountability for Cloud Security Decisions: https://docs.microsoft.com/azure/cloud-adoption-framework/security/security-top-10#4-process-update-incident-response-ir-processes-for-cloud GS-2 Governance and Strategy 2.10 - Physically or Logically Segregate High Risk Applications 3.12 - Segment Data Processing and Storage Based on Sensitivity AC-4: INFORMATION FLOW ENFORCEMENT 1.2 Define and implement enterprise segmentation/separation of duties strategy N/A Establish an enterprise-wide strategy to segment access to assets using a combination of identity, network, application, subscription, management group, and other controls. Security in the Microsoft Cloud Adoption Framework for Azure - Segmentation: Separate to protect All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 14.1 - Segment the Network Based on Sensitivity SC-7: BOUNDARY PROTECTION 6.4 https://docs.microsoft.com/azure/cloud-adoption-framework/secure/access-control#segmentation-separate-to-protect SC-2: APPLICATION PARTITIONING Carefully balance the need for security separation with the need to enable daily operation of the systems that need to communicate with each other and access data. Security in the Microsoft Cloud Adoption Framework for Azure - Architecture: establish a single unified security strategy: Ensure that the segmentation strategy is implemented consistently in the workload, including network security, identity and access models, and application permission/access models, and human process controls. https://docs.microsoft.com/azure/cloud-adoption-framework/secure/security-top-10#11-architecture-establish-a-single-unified-security-strategy GS-3 Governance and Strategy 14.1 - Segment the Network Based on Sensitivity 3.1 - Establish and Maintain a Data Management Process AC-4: INFORMATION FLOW ENFORCEMENT 3.1 Define and implement data protection strategy N/A Establish an enterprise-wide strategy for data protection in your cloud environment: Azure Security Benchmark - Data Protection: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 3.7 - Establish and Maintain a Data Classification Scheme SI-4: INFORMATION SYSTEM MONITORING 3.2 - Define and apply the data classification and protection standard in accordance with the enterprise data management standard and regulatory compliance to dictate the security controls required for each level of the data classification. https://docs.microsoft.com/security/benchmark/azure/security-controls-v3-data-protection 3.12 - Segment Data Processing and Storage Based on Sensitivity SC-8: TRANSMISSION CONFIDENTIALITY AND INTEGRITY 3.3 - Set up your cloud resource management hierarchy aligned to the enterprise segmentation strategy. The enterprise segmentation strategy should also be informed by the location of sensitive or business critical data and systems. SC-12: CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT 3.4 - Define and apply the applicable zero-trust principles in your cloud environment to avoid implementing trust based on network location within a perimeter. Instead, use device and user trust claims to gate access to data and resources. Cloud Adoption Framework - Azure data security and encryption best practices: SC-17: PUBLIC KEY INFRASTRUCTURE CERTIFICATES 3.5 - Track and minimize the sensitive data footprint (storage, transmission, and processing) across the enterprise to reduce the attack surface and data protection cost. Consider techniques such as one-way hashing, truncation, and tokenization in the workload where possible, to avoid storing and transmitting sensitive data in its original form. https://docs.microsoft.com/azure/security/fundamentals/data-encryption-best-practices SC-28: PROTECTION OF INFORMATION AT REST 3.6 - Ensure you have a full lifecycle control strategy to provide security assurance of the data and access keys. RA-2: SECURITY CATEGORIZATION 3.7 Azure Security Fundamentals - Azure Data security, encryption, and storage: 4.1 https://docs.microsoft.com/azure/security/fundamentals/encryption-overview A3.2 GS-4 Governance and Strategy 12.1 - Maintain an Inventory of Network Boundaries 12.2 - Establish and Maintain a Secure Network Infrastructure AC-4: INFORMATION FLOW ENFORCEMENT 1.1 Define and implement network security strategy N/A Establish a cloud network security strategy as part of your organization\u2019s overall security strategy for access control. This strategy should include documented guidance, policy, and standards for the following elements: Azure Security Best Practice 11 - Architecture. Single unified security strategy: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 12.4 - Establish and Maintain Architecture Diagram(s) AC-17: REMOTE ACCESS 1.2 - Design a centralized/decentralized network management and security responsibility model to deploy and maintain network resources. https://docs.microsoft.com/azure/cloud-adoption-framework/security/security-top-10#11-architecture-establish-a-single-unified-security-strategy CA-3: SYSTEM INTERCONNECTIONS 1.3 - A virtual network segmentation model aligned with the enterprise segmentation strategy. CM-1: CONFIGURATION MANAGEMENT POLICY AND PROCEDURES 1.5 - An Internet edge and ingress and egress strategy. Azure Security Benchmark - Network Security: CM-2: BASELINE CONFIGURATION 4.1 - A hybrid cloud and on-premises interconnectivity strategy. https://docs.microsoft.com/security/benchmark/azure/security-controls-v3-network-security CM-6: CONFIGURATION SETTINGS 6.6 - A network monitoring and logging strategy. CM-7: LEAST FUNCTIONALITY 11.4 - An up-to-date network security artifacts (such as network diagrams, reference network architecture). Azure network security overview: SC-1: SYSTEM AND COMMUNICATIONS PROTECTION POLICY AND PROCEDURES A2.1 https://docs.microsoft.com/azure/security/fundamentals/network-overview SC-2: APPLICATION PARTITIONING A2.2 SC-5: DENIAL OF SERVICE PROTECTION A2.3 Enterprise network architecture strategy: SC-7: BOUNDARY PROTECTION A3.2 https://docs.microsoft.com/azure/cloud-adoption-framework/ready/enterprise-scale/architecture SC-20: SECURE NAME / ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) SC-21: SECURE NAME / ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER) SI-4: INFORMATION SYSTEM MONITORING GS-5 Governance and Strategy 5.1 - Establish Secure Configurations 4.1 - Establish and Maintain a Secure Configuration Process CA-1: SECURITY ASSESSMENT AND AUTHORIZATION POLICY AND PROCEDURES 1.1 Define and implement security posture management strategy N/A Establish a policy, procedure and standard to ensure the security configuration management and vulnerability management are in place in your cloud security mandate. Azure Security Benchmark - Posture and vulnerability management: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 4.2 - Establish and Maintain a Secure Configuration Process for Network Infrastructure CA-8: PENETRATION TESTING 1.2 https://docs.microsoft.com/security/benchmark/azure/security-controls-v3-posture-vulnerability-management CM-1: CONFIGURATION MANAGEMENT POLICY AND PROCEDURES 2.2 The security configuration management in cloud should include the following areas: CM-2: BASELINE CONFIGURATION 6.1 - Define the secure configuration baselines for different resource types in the cloud, such as the web portal/console, management and control plane, and resources running in the IaaS, PaaS and SaaS services. Azure Security Best Practice 9 - Establish security posture management: CM-6: CONFIGURATION SETTINGS 6.2 - Ensure the security baselines address the risks in different control areas such as network security, identity management, privileged access, data protection and so on. https://docs.microsoft.com/azure/cloud-adoption-framework/secure/security-top-10#5-process-establish-security-posture-management RA-1: RISK ASSESSMENT POLICY AND PROCEDURES 6.5 - Use tools to continuously measure, audit, and enforce the configuration to prevent configuration deviating from the baseline. RA-3: RISK ASSESSMENT 6.6 - Develop a cadence to stay updated with security features, for instance, subscribe to the service updates. RA-5: VULNERABILITY SCANNING 11.2 - Utilize a security health or compliance check mechanism (such as Secure Score, Compliance Dashboard in Microsoft Defender for Cloud) to regularly review security configuration posture and remediate the gaps identified. SI-1: SYSTEM AND INFORMATION INTEGRITY POLICY AND PROCEDURES 11.3 SI-2: FLAW REMEDIATION 11.5 The vulnerability management in the cloud should include the following security aspects: SI-5: SECURITY ALERTS, ADVISORIES, AND DIRECTIVES - Regularly assess and remediate vulnerabilities in all cloud resource types, such as cloud native services, operating systems, and application components. - Use a risk-based approach to prioritize assessment and remediation. - Subscribe to the relevant CSPM's security advisory notices and blogs to receive the latest security updates. - Ensure the vulnerability assessment and remediation (such as schedule, scope, and techniques) meet the regularly compliance requirements for your organization. GS-6 Governance and Strategy 4.5 - Use Multifactor Authentication For All Administrative Access 5.6 - Centralize Account Management AC-1: ACCESS CONTROL POLICY AND PROCEDURES 7.1 Define and implement identity and privileged access strategy N/A Establish a cloud identity and privileged access approach as part of your organization\u2019s overall security access control strategy. This strategy should include documented guidance, policy, and standards for the following aspects: Azure Security Benchmark - Identity management: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 16.2 - Configure Centralized Point of Authentication 6.5 - Require MFA for Administrative Access AC-2: ACCOUNT MANAGEMENT 7.2 - Centralized identity and authentication system (such as Azure AD) and its interconnectivity with other internal and external identity systems https://docs.microsoft.com//security/benchmark/azure/security-controls-v3-identity-management 6.7 - Centralize Access Control AC-3: ACCESS ENFORCEMENT 7.3 - Privileged identity and access governance (such as access request, review and approval) AC-4: INFORMATION FLOW ENFORCEMENT 8.1 - Privileged accounts in emergency (break-glass) situation Azure Security Benchmark - Privileged access: AC-5: SEPARATION OF DUTIES 8.2 - Strong authentication (passwordless authentication and multifactor authentication) methods in different use cases and conditions https://docs.microsoft.com/security/benchmark/azure/security-controls-v3-privileged-access AC-6: LEAST PRIVILEGE 8.3 - Secure access by administrative operations through web portal/console, command-line and API. IA-1: IDENTIFICATION AND AUTHENTICATION POLICY AND PROCEDURES 8.4 Azure Security Best Practice 11 - Architecture. Single unified security strategy: IA-2: IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) 8.5 For exception cases, where an enterprise system isn\u2019t used, ensure adequate security controls are in place for identity, authentication and access management, and governed. These exceptions should be approved and periodically reviewed by the enterprise team. These exceptions are typically in cases such as: https://docs.microsoft.com/azure/cloud-adoption-framework/security/security-top-10#11-architecture-establish-a-single-unified-security-strategy IA-4: IDENTIFIER MANAGEMENT 8.6 - Use of a non-enterprise designated identity and authentication system, such as cloud-based third-party systems (may introduce unknown risks) IA-5: AUTHENTICATOR MANAGEMENT 8.7 - Privileged users authenticated locally and/or use non-strong authentication methods Azure identity management security overview: IA-8: IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) 8.8 https://docs.microsoft.com/azure/security/fundamentals/identity-management-overview IA-9: SERVICE IDENTIFICATION AND AUTHENTICATION A3.4 SI-4: INFORMATION SYSTEM MONITORING GS-7 Governance and Strategy 6.2 -Activate audit logging 8.1 - Establish and Maintain an Audit Log Management Process AU-1: AUDIT AND ACCOUNTABILITY POLICY AND PROCEDURES 10.1 Define and implement logging, threat detection and incident response strategy N/A Establish a logging, threat detection and incident response strategy to rapidly detect and remediate threats and meet compliance requirements. Security operations (SecOps / SOC) team should prioritize high quality alerts and seamless experiences so that they can focus on threats rather than log integration and manual steps. Azure Security Benchmark - Logging and threat detection: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 6.3 - Enable Detailed Logging 13.1 - Centralize Security Event Alerting IR-1: INCIDENT RESPONSE POLICY AND PROCEDURES 10.2 This strategy should include documented policy, procedure and standards for the following aspects: https://docs.microsoft.com/azure/security/benchmarks/security-benchmark-v3-logging-threat-detection 6.6 - Deploy SIEM or Log Analytic tool 17.2 - Establish and Maintain Contact Information for Reporting Security Incidents IR-2: INCIDENT RESPONSE TRAINING 10.3 - The security operations (SecOps) organization's role and responsibilities 6.7 - Regularly Review Logs 17.4 - Establish and Maintain an Incident Response Process IR-10: INTEGRATED INFORMATION SECURITY ANALYSIS TEAM 10.4 - A well-defined and regularly tested incident response plan and handling process aligning with NIST SP 800-61 (Computer Security Incident Handling Guide) or other industry frameworks. Azure Security Benchmark - Incident response: 19.1 - Document Incident Response Procedures 17.7 - Conduct Routine Incident Response Exercises SI-1: SYSTEM AND INFORMATION INTEGRITY POLICY AND PROCEDURES 10.5 - Communication and notification plan with your customers, suppliers, and public parties of interest. https://docs.microsoft.com/azure/security/benchmarks/security-benchmark-v3-incident-response 19.5 - Maintain Contact Information For Reporting Security Incidents SI-5: SECURITY ALERTS, ADVISORIES, AND DIRECTIVES 10.6 - Simulate both expected and unexpected security events within your cloud environment to understand the effectiveness of your preparation. Iterate on the outcome of your simulation to improve the scale of your response posture, reduce time to value, and further reduce risk. 19.7 - Conduct Periodic Incident Scenario Sessions for Personnel 10.7 - Preference of using extended detection and response (XDR) capabilities such as Azure Defender capabilities to detect threats in the various areas. Azure Security Best Practice 4 - Process. Update Incident Response Processes for Cloud: 10.8 - Use of cloud native capability (e.g., as Microsoft Defender for Cloud) and third-party platforms for incident handling, such as logging and threat detection, forensics, and attack remediation and eradication. https://aka.ms/AzSec4 10.9 - Prepare the necessary runbooks, both manual and automated, to ensure reliable and consistent responses. 12.10 - Define key scenarios (such as threat detection, incident response, and compliance) and set up log capture and retention to meet the scenario requirements. Azure Adoption Framework, logging, and reporting decision guide: A3.5 - Centralized visibility of and correlation information about threats, using SIEM, native cloud threat detection capability, and other sources. https://docs.microsoft.com/azure/cloud-adoption-framework/decision-guides/logging-and-reporting/ - Post-incident activities, such as lessons learned and evidence retention. Azure enterprise scale, management, and monitoring: https://docs.microsoft.com/azure/cloud-adoption-framework/ready/enterprise-scale/management-and-monitoring NIST SP 800-61 Computer Security Incident Handling Guide: https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r2.pdf GS-8 Governance and Strategy 10.1 - Ensure Regular Automated Backups 11.1 - Establish and Maintain a Data Recovery Process CP-1: CONTINGENCY PLANNING POLICY AND PROCEDURES 3.4 Define and implement backup and recovery strategy N/A Establish a backup and recovery strategy for your organization. This strategy should include documented guidance, policy, and standards in the following aspects: Azure Security Benchmark - Backup and recovery: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions CP-9: INFORMATION SYSTEM BACKUP - Recovery time objective (RTO) and recovery point objective (RPO) definitions in accordance with your business resiliency objectives, and regulatory compliance requirements. https://docs.microsoft.com/azure/security/benchmarks/security-benchmark-v3-backup-recovery CP-10: INFORMATION SYSTEM RECOVERY AND RECONSTITUTION - Redundancy design (including backup, restore and replication) in your applications and infrastructure for both in cloud and on-premises. Consider regional, region-pairs, cross-regional recovery and off-site storage location as part of your strategy. - Protection of backup from unauthorized access and tempering using controls such as data access control, encryption and network security. Azure Well-Architecture Framework - Backup and disaster recover for Azure applications: https://docs.microsoft.com/azure/architecture/framework/resiliency/backup-and-recovery - Use of backup and recovery to mitigate the risks from emerging threats, such as ransomware attack. And also secure the backup and recovery data itself from these attacks. - Monitoring the backup and recovery data and operations for audit and alerting purposes. Azure Adoption Framework-business continuity and disaster recovery: https://docs.microsoft.com/azure/cloud-adoption-framework/ready/enterprise-scale/business-continuity-and-disaster-recovery Backup and restore plan to protect against ransomware: https://docs.microsoft.com/azure/security/fundamentals/backup-plan-to-protect-against-ransomware GS-9 Governance and Strategy 8.1 - Utilize Centrally Managed Anti-malware Software 4.4 - Implement and Manage a Firewall on Servers SI-2: FLAW REMEDIATION 5.1 Define and implement endpoint security strategy N/A Establish a cloud endpoint security strategy which includes the following aspects: Azure Security Benchmark - Endpoint security: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 9.4 - Apply Host-Based Firewalls or Port-Filtering 10.1 - Deploy and Maintain Anti-Malware Software SI-3: MALICIOUS CODE PROTECTION 5.2 - Deploy the endpoint detection and response and antimalware capability into your endpoint and integrate with the threat detection and SIEM solution and security operations process. https://docs.microsoft.com/azure/security/benchmarks/security-benchmark-v3-endpoint-security SC-3: SECURITY FUNCTION ISOLATION 5.3 - Follow Microsoft Cloud Security Benchmark to ensure endpoint related security settings in other respective areas (such as network security, posture vulnerability management, identity and privileged access, and logging and threat detections) are also in place to provide a defense-in-depth protection for your endpoint. 5.4 - Prioritize the endpoint security in your production environment but ensure the non-production environments (such as test and build environment used in the DevOps process) are also secured and monitored, as these environment can also be used to introduce the malware and vulnerabilities into the production. Best practices for endpoint security on Azure: 11.5 https://docs.microsoft.com/azure/architecture/framework/security/design-network-endpoints GS-10 Governance and Strategy 5.1 - Establish Secure Configurations 4.1 - Establish and Maintain a Secure Configuration Process SA-12: SUPPLY CHAIN PROTECTION 2.2 Define and implement DevOps security strategy N/A Mandate the security controls as part of the organization\u2019s DevOps engineering and operation standard. Define the security objectives, control requirements, and tooling specifications in accordance with enterprise and cloud security standards in your organization. Azure Security Benchmark - DevOps security: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions 18.1 - Establish Secure Coding Practices 4.2 - Establish and Maintain a Secure Configuration Process for Network Infrastructure SA-15: DEVELOPMENT PROCESS, STANDARDS, AND TOOLS 6.1 https://docs.microsoft.com/azure/security/benchmarks/security-benchmark-v3-devops-security 18.8 - Establish a Process to Accept and Address Reports of Software Vulnerabilities 16.1 - Establish and Maintain a Secure Application Development\u00a0Process CM-1: CONFIGURATION MANAGEMENT POLICY AND PROCEDURES 6.2 Encourage the use of DevOps as an essential operating model in your organization for its benefits in rapidly identifying and remediating vulnerabilities using different type of automations (such as infrastructure as code provision, and automated SAST and DAST scan) throughout the CI/CD workflow. This \u2018shift left\u2019 approach also increases visibility and ability to enforce consistent security checks in your deployment pipeline, effectively deploying security guardrails into the environment ahead of time to avoid last minute security surprises when deploying a workload into production. 16.2 - Establish and Maintain a Process to Accept and Address Software Vulnerabilities CM-2: BASELINE CONFIGURATION 6.3 Secure DevOps: CM-6: CONFIGURATION SETTINGS 6.5 When shifting security controls left into the pre-deployment phases, implement security guardrails to ensure the controls are deployed and enforced throughout your DevOps process. This technology could include resource deployment templates (such as Azure ARM template) to define guardrails in the IaC (infrastructure as code), resource provisioning and audit to restrict which services or configurations can be provisioned into the environment. https://www.microsoft.com/securityengineering/devsecops AC-2: ACCOUNT MANAGEMENT 7.1 AC-3: ACCESS ENFORCEMENT 10.1 For the run-time security controls of your workload, follow the Microsoft Cloud Security Benchmark to design and implement effective the controls, such as identity and privileged access, network security, endpoint security, and data protection inside your workload applications and services. Cloud Adoption Framework - DevSecOps controls: AC-6: LEAST PRIVILEGE 10.2 https://docs.microsoft.com/azure/cloud-adoption-framework/secure/devsecops-controls SA-11: DEVELOPER TESTING AND EVALUATION 10.3 AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING 10.6 AU-12: AUDIT GENERATION 12.2 SI-4: INFORMATION SYSTEM MONITORING GS-11 Governance and Strategy nan nan nan nan Define and implement multi-cloud security strategy N/A Ensure a multi-cloud strategy is defined in your cloud and security governance, risk management, and operation process which should include the following aspects: Azure hybrid and multicloud: All stakeholders: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security#security-functions - Multi-cloud adoption: For organizations that operate multi-cloud infrastructure and Educate your organization to ensure teams understand the feature difference between the cloud platforms and technology stack. Build, deploy, and/or migrate solutions that are portable. Allow for ease of movement between cloud platforms with minimum vendor lock-in while utilizing cloud native features adequately for the optimal result from the cloud adoption. https://docs.microsoft.com/en-us/hybrid/ - Cloud and security operations: Streamline security operations to support the solutions across each cloud, through a central set of governance and management processes which share common operations processes, regardless of where the solution is deployed and operated. - Tooling and technology stack: Choose the appropriate tooling that supports multi-cloud environment to help with establishing unified and centralized management platforms which may include all the security domains discussed in this security benchmark. Azure hybrid and multicloud documentation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/hybrid/scenario-overview AWS to Azure services comparison: https://docs.microsoft.com/en-us/azure/architecture/aws-professional/services Azure for AWS professionals: https://docs.microsoft.com/en-us/azure/architecture/aws-professional/"},{"location":"Azure/Security/MCSB/Identity%20Management/","title":"MCSB_v1 - Identity Management","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context: Customer Security Stakeholders: IM-1 Identity Management 16.1 - Maintain an Inventory of 6.7 - Centralize Access Control AC-2: ACCOUNT MANAGEMENT 7.2 Use centralized identity and authentication system Use a centralized identity and authentication system to govern your organization's identities and authentications for cloud and non-cloud resources. Azure Active Directory (Azure AD) is Azure's identity and authentication management service. You should standardize on Azure AD to govern your organization's identity and authentication in: Tenancy in Azure AD: AWS IAM (Identity and Access Management) is AWS' default identity and authentication management service. Use AWS IAM to govern your AWS identity and access management.  Alternatively, through AWS and Azure Sigle Sign-On (SSO), you can also use Azure AD to manage the identity and access control of AWS to avoid managing duplicate accounts separately in two cloud platforms. AWS IAM: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys Authentication Systems 12.5 - Centralize Network Authentication, Authorization, and Auditing (AAA) AC-3: ACCESS ENFORCEMENT 8.3 - Microsoft cloud resources, such as Azure Storage, Azure Virtual Machines (Linux and Windows), Azure Key Vault, PaaS, and SaaS applications. https://docs.microsoft.com/azure/active-directory/develop/single-and-multi-tenant-apps https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html 16.2 - Configure Centralized IA-2: IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) - Your organization's resources, such as applications on Azure, third-party applications running on your corporate network resources, and third-party SaaS applications. AWS supports Single Sign-On which allows you to bridge your corporate's third party identities (such as Windows Active Directory,  or other identity stores) with the AWS identities to avoid creating duplicate accounts to access AWS resources. Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture Point of Authentication IA-8: IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) - Your enterprise identities in Active Directory by synchronization to Azure AD to ensure a consistent and centrally managed identity strategy. How to create and configure an Azure AD instance: AWS Single Sign-On: https://docs.microsoft.com/azure/active-directory/fundamentals/active-directory-access-create-new-tenant https://docs.aws.amazon.com/singlesignon/index.html Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops For the Azure services that apply, avoid use of local authentication methods and instead use Azure Active Directory to centralize your service authentications. Define Azure AD tenants: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management Note: As soon as it is technically feasible, you should migrate on-premises Active Directory-based applications to Azure AD. This could be an Azure AD Enterprise Directory, Business to Business configuration, or Business to consumer configuration. https://azure.microsoft.com/resources/securing-azure-environments-with-azure-active-directory/ Use external identity providers for an application: https://docs.microsoft.com/azure/active-directory/b2b/identity-providers IM-2 Identity Management 4.3 - Ensure the Use of Dedicated Administrative Accounts 5.4 - Restrict Administrator Privileges to Dedicated Administrator Accounts AC-2: ACCOUNT MANAGEMENT 8.2 Protect identity and authentication systems Secure your identity and authentication system as a high priority in your organization's cloud security practice. Common security controls include: Use the Azure AD security baseline and the Azure AD Identity Secure Score to evaluate your Azure AD identity security posture, and remediate security and configuration gaps. What is the identity secure score in Azure AD: https://docs.microsoft.com/azure/active-directory/fundamentals/identity-secure-score Use the following security best practices to secure your AWS IAM: Security Best Practice in IAM: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys 4.5 - Use Multi-Factor Authentication for All Administrative Access 6.5 - Require MFA for Administrative Access AC-3: ACCESS ENFORCEMENT 8.3 - Restrict privileged roles and accounts The Azure AD Identity Secure Score evaluates Azure AD for the following configurations: - Set up AWS account root user access keys for emergency access as described in PA-5 (Set up emergency access) https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html IA-2: IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) - Require strong authentication for all privileged access - Use limited administrative roles Best Practices for Securing Active Directory: - Follow least privilege principles for access assignments Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture IA-8: IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) - Monitor and audit high risk activities - Turn on user risk policy https://docs.microsoft.com/windows-server/identity/ad-ds/plan/security-best-practices/best-practices-for-securing-active-directory - Leverage IAM groups to apply policies instead of individual user(s). IAM Access Advisor: SI-4: INFORMATION SYSTEM MONITORING - Designate more than one global admin - Follow strong authentication guidance in IM-6 (Use strong authentication controls) for all users https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor.html Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops - Enable policy to block legacy authentication What is Identity Protection? - Use AWS Organizations SCP (Service Control Policy) and permission boundaries - Ensure all users can complete multi-factor authentication for secure access https://learn.microsoft.com/en-us/azure/active-directory/identity-protection/overview-identity-protection - Use IAM Access Advisor to audit service access IAM Credential Report: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Require MFA for administrative roles - Use IAM credential report to track user accounts and credential status https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html - Enable self-service password reset What is Microsoft Defender for Identity? - Do not expire passwords https://learn.microsoft.com/en-us/defender-for-identity/what-is Note: Follow published best practices if you have other identity and authentication systems, e.g., follow the Azure AD security baseline if you use Azure AD to manage AWS identity and access. - Turn on sign-in risk policy - Do not allow users to grant consent to unmanaged applications Use Azure AD Identity Protection to detect, investigate, and remediate identity-based risks. To similarly protect your on-premises Active Directory domain, use Defender for Identity. Note: Follow published best practices for all other identity components, including your on-premises Active Directory and any third party capabilities, and the infrastructure (such as operating systems, networks, databases) that host them. IM-3 Identity Management nan nan AC-2: ACCOUNT MANAGEMENT N/A Manage application identities securely and automatically Use managed application identities instead of creating human accounts for applications to access resources and execute code. Managed application identities provide benefits such as reducing the exposure of credentials. Automate the rotation of credentials to ensure the security of the identities. Use Azure managed identities, which can authenticate to Azure services and resources that support Azure AD authentication. Managed identity credentials are fully managed, rotated, and protected by the platform, avoiding hard-coded credentials in source code or configuration files. Azure managed identities: Use AWS IAM roles instead of creating user accounts for resources that support this feature. IAM roles are managed by the platform at the backend and the credentials are temporary and rotated automatically. This avoids creating long-term access keys or a username/password for applications and hard-coded credentials in source code or configuration files. AWS IAM Roles: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys AC-3: ACCESS ENFORCEMENT https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/overview https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html IA-4: IDENTIFIER MANAGEMENT For services that don't support managed identities, use Azure AD to create a service principal with restricted permissions at the resource level. It is recommended to configure service principals with certificate credentials and fall back to client secrets for authentication. You may use service-linked roles which are attached with pre-defined permission policies for access between  AWS services instead of customizing your own role permissions for the IAM roles. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops IA-5: AUTHENTICATOR MANAGEMENT Services that support managed identities for Azure resources: Providing access to an AWS service: IA-9: SERVICE IDENTIFICATION AND AUTHENTICATION https://docs.microsoft.com/azure/active-directory/managed-identities-azure-resources/services-support-managed-identities Note: For services that don't support IAM roles, use access keys but follow the security best practice such as IM-8: Restrict the exposure of credential and secrets to secure your keys. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html Azure service principal: https://docs.microsoft.com/powershell/azure/create-azure-service-principal-azureps Create a service principal with certificates: https://docs.microsoft.com/azure/active-directory/develop/howto-authenticate-service-principal-powershell IM-4 Identity Management nan nan IA-9: SERVICE IDENTITIFICATION AND AUTHENTICATION nan Authenticate server and services Authenticate remote servers and services from your client side to ensure you are connecting to trusted server and services. The most common server authentication protocol is Transport Layer Security (TLS), where the client-side (often a browser or client device) verifies the server by verifying the server\u2019s certificate was issued by a trusted certificate authority. Many Azure services support TLS authentication by default. For services that don't support this by default or support TLS disabling, ensure it is always enabled to support the server/service authentication. Your client application should also be designed to verify server/service identity (by verifying the server\u2019s certificate issued by a trusted certificate authority) in the handshake stage. Enforce Transport Layer Security (TLS) for a storage account: Many AWS services support TLS authentication by default. For services that don't support this by default or support  TLS disabling, ensure it is always enabled to support the server/service authentication. Your client application should also be designed to verify server/service identity (by verifying the server\u2019s certificate issued by a trusted certificate authority) in the handshake stage. AWS Certificate Manager certificate pinning. Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys https://docs.microsoft.com/azure/storage/common/transport-layer-security-configure-minimum-version?tabs=portal#use-azure-policy-to-enforce-the-minimum-tls-version https://docs.aws.amazon.com/acm/latest/userguide/acm-bestpractices.html#best-practices-pinning Note: Mutual authentication can be used when both the server and the client authenticate one-another. Note: Services such as API Management and API Gateway support TLS mutual authentication. Note: Services such as API Gateway support TLS mutual authentication. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops SSL certificate for backend authentication: https://docs.aws.amazon.com/apigateway/latest/developerguide/getting-started-client-side-ssl-authentication.html IM-5 Identity Management 16.2 - Configure Centralized Point of Authentication 12.5 - Centralize Network Authentication, Authorization, and Auditing (AAA) IA-4: IDENTIFIER MANAGEMENT nan Use single sign-on (SSO) for application access Use single sign-on (SSO) to simplify the user experience for authenticating to resources including applications and data across cloud services and on-premises environments. Use Azure AD for workload application workload access (customer facing)  through Azure AD single sign-on (SSO), reducing the need for duplicate accounts. Azure AD provides identity and access management to Azure resources (in the management plane including CLI, PowerShell, portal), cloud applications, and on-premises applications. Understand application SSO with Azure AD: Use AWS Cognito to manage access to  your customer facing workload application through single sign-on (SSO) to allow customers to bridge their third-party identities from different identity providers. AWS Single Sign-On: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture IA-2: IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) https://docs.microsoft.com/azure/active-directory/manage-apps/what-is-single-sign-on https://docs.aws.amazon.com/singlesignon/ IA-8: IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) Azure AD also supports SSO for enterprise identities such as corporate user identities, as well as external user identities from trusted third-party and public users. For SSO access to the AWS native resources (including AWS console access or service management and data plane level access), use AWS Sigle Sign-On to reduce the need for duplicate accounts. Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys AWS Cognito Single Sign-On Adding SAML identity providers: AWS SSO also allows you to bridge corporate identities (such as identities from Azure Active Directory) with  AWS identities, as well as external user identities from trusted third-party and public users. https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-saml-idp.html Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops IM-6 Identity Management 4.2 - Change Default Passwords 6.3 - Require MFA for Externally-Exposed Applications AC-2: ACCOUNT MANAGEMENT 7.2 Use strong authentication controls Enforce strong authentication controls (strong passwordless authentication or multi-factor authentication) with your centralized identity and authentication management system for all access to resources. Authentication based on password credentials alone is considered legacy, as it is insecure and does not stand up to popular attack methods. Azure AD supports strong authentication controls through passwordless methods and multi-factor authentication (MFA). How to enable MFA in Azure: AWS IAM supports strong authentication controls through multi-factor authentication (MFA). MFA can be enforced on all users, select users, or at the per-user level based on defined conditions. Using multi-factor authentication (MFA) in AWS: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 4.5 - Use Multifactor Authentication For All Administrative Access 6.4 - Require MFA for Administrative Access AC-3: ACCESS ENFORCEMENT 8.2 - Passwordless authentication: Use passwordless authentication as your default authentication method. There are three options available in passwordless authentication: Windows Hello for Business, Microsoft Authenticator app phone sign-in, and FIDO2 security keys. In addition, customers can use on-premises authentication methods such as smart cards. https://docs.microsoft.com/azure/active-directory/authentication/howto-mfa-getstarted https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa.html 12.11 - Require All Remote Logins to Use Multi-Factor Authentication IA-2: IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) 8.3 When deploying strong authentication, configure administrators and privileged users first, to ensure the highest level of the strong authentication method, quickly followed by rolling out the appropriate strong authentication policy to all users. - Multi-factor authentication: Azure MFA can be enforced on all users, select users, or at the per-user level based on sign-in conditions and risk factors. Enable Azure MFA and follow Microsoft Defender for Cloud identity and access management recommendations for your MFA setup. If you use corporate accounts from a third-party directory (such as Windows Active Directory) with AWS identities, follow the respective security guidance to enforce strong authentication.  Refer to the Azure Guidance for this control if you use Azure AD to manage AWS access. Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys 16.3 - Require Multi-Factor Authentication IA-5: AUTHENTICATOR MANAGEMENT 8.4 Introduction to passwordless authentication options for Azure Active Directory: IAM supported MFA form factors: IA-8: IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) Note: If legacy password-based authentication is required for legacy applications and scenarios, ensure password security best practices such as complexity requirements, are followed. If legacy password-based authentication is still used for Azure AD authentication, be aware that cloud-only accounts (user accounts created directly in Azure) have a default baseline password policy. And hybrid accounts (user accounts that come from on-premises Active Directory) follow the on-premises password policies. https://docs.microsoft.com/azure/active-directory/authentication/concept-authentication-passwordless Note: For third-party applications and AWS services that may have default IDs and passwords, you should disable or change them during initial service setup. https://aws.amazon.com/iam/features/mfa/ Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops For third-party applications and services that may have default IDs and passwords, you should disable or change them during initial service setup. Azure AD default password policy: https://docs.microsoft.com/azure/active-directory/authentication/concept-sspr-policy#password-policies-that-only-apply-to-cloud-user-accounts Eliminate bad passwords using Azure AD Password Protection: https://docs.microsoft.com/azure/active-directory/authentication/concept-password-ban-bad Block legacy authentication: https://docs.microsoft.com/azure/active-directory/conditional-access/block-legacy-authentication IM-7 Identity Management 12.11 - Require All Remote Logins to Use Multi-Factor Authentication 3.3 - Configure Data Access Control Lists AC-2: ACCOUNT MANAGEMENT 7.2 Restrict resource access based on  conditions Explicitly validate trusted signals to allow or deny user access to resources, as part of a zero-trust access model. Signals to validate should include strong authentication of user account, behavioral analytics of user account, device trustworthiness, user or group membership, locations and so on. Use Azure AD conditional access for more granular access controls based on user-defined conditions, such as requiring user logins from certain IP ranges (or devices) to use MFA. Azure AD Conditional Access allows you to enforce access controls on your organization\u2019s apps based on certain conditions. Azure Conditional Access overview: Create IAM policy and define conditions for more granular access controls based on user-defined conditions, such as requiring user logins from certain IP ranges (or devices) to use multi-factor authentication. Condition settings may include single or multiple conditions as well as logic. Policies and permissions in IAM: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys 12.12 - Manage All Devices Remotely Logging Into Internal Network 6.4 - Require MFA for Administrative Access AC-3: ACCESS ENFORCEMENT https://docs.microsoft.com/azure/active-directory/conditional-access/overview https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html 14.6 - Protect Information Through Access Control Lists 13.5 - Manage Access Control for Remote Assets AC-6: LEAST PRIVILEGE Define the applicable conditions and criteria for Azure AD conditional access in the workload. Consider the following common use cases: Policies can be defined from six different dimensions: identity-based policies, resource-based policies, permissions boundaries, AWS Organizations service control policy (SCP) , Access Control Lists(ACL), and session policies. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 16.3 - Require Multi-Factor Authentication - Requiring multi-factor authentication for users with administrative roles Common Conditional Access policies: Conditions key table: - Requiring multi-factor authentication for Azure management tasks https://docs.microsoft.com/azure/active-directory/conditional-access/concept-conditional-access-policy-common https://docs.aws.amazon.com/service-authorization/latest/reference/reference_policies_actions-resources-contextkeys.html#context_keys_table Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Blocking sign-ins for users attempting to use legacy authentication protocols - Requiring trusted locations for Azure AD Multi-Factor Authentication registration Conditional Access insights and reporting: Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence - Blocking or granting access from specific locations https://docs.microsoft.com/azure/active-directory/conditional-access/howto-conditional-access-insights-reporting - Blocking risky sign-in behaviors - Requiring organization-managed devices for specific applications Configure authentication session management with Conditional Access: https://docs.microsoft.com/azure/active-directory/conditional-access/howto-conditional-access-session-lifetime Note: Granular authentication session management controls can also be implemented through Azure AD conditional access policies such as sign-in frequency and persistent browser session. IM-8 Identity Management 18.1 - Establish Secure Coding Practices 16.9 - Train Developers in Application Security Concepts and Secure Coding IA-5: AUTHENTICATOR MANAGEMENT 3.5 Restrict the exposure of credential and secrets Ensure that application developers securely handle credentials and secrets: When using a managed identity is not an option, ensure that secrets and credentials are stored in secure locations such as Azure Key Vault, instead of embedding them into the code and configuration files. How to setup Credential Scanner: When using an IAM role for application access is not an option, ensure that secrets and credentials are stored in secure locations such as AWS Secret Manager or Systems Manager Parameter Store, instead of embedding them into the code and configuration files. AWS IAM roles in EC2: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 18.6 - Ensure Software Development Personnel Are Trained in Secure Coding 16.12 - Implement Code-Level Security Checks 6.3 - Avoid embedding the credentials and secrets into the code and configuration files https://secdevtools.azurewebsites.net/helpcredscan.html https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html 18.7 - Apply Static and Dynamic Code Analysis Tools 8.2 - Use key vault or a secure key store service to store the credentials and secrets If you use Azure DevOps and GitHub for your code management platform: Use CodeGuru Reviewer for static code analysis which can detect the secrets hard-coded in your source code. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Scan for credentials in source code. - Implement Azure DevOps Credential Scanner to identify credentials within the code. GitHub secret scanning: AWS Secrets Manager integrated services: - For GitHub, use the native secret scanning feature to identify credentials or other forms of secrets within the code. https://docs.github.com/github/administering-a-repository/about-secret-scanning If you use the Azure DevOps and GitHub for your code management platform: https://docs.aws.amazon.com/secretsmanager/latest/userguide/integrating.html Note: This is often governed and enforced through a secure software development lifecycle (SDLC) and DevOps security process - Implement Azure DevOps Credential Scanner to identify credentials within the code. Clients such as Azure Functions, Azure Apps services, and VMs can use managed identities to access Azure Key Vault securely. See Data Protection controls related to the use of Azure Key Vault for secrets management. - For GitHub, use the native secret scanning feature to identify credentials or other forms of secrets within the code. CodeGuru Reviewer Secrets Detection: https://docs.aws.amazon.com/codeguru/latest/reviewer-ug/recommendations.html Note: Azure Key Vault provides automatic rotation for supported services. For secrets which cannot be automatically rotated, ensure they are manually rotated periodically and purged when no longer in use. Note: Secrets Manager provides automatic secrets rotation for supported services. For secrets which cannot be automatically rotated, ensure they are manually rotated periodically and purged when no longer in use. IM-9 Identity Management 12.10 Decrypt Network Traffic at Proxy 6.7 - Centralize Access Control AC-2: ACCOUNT MANAGEMENT nan Secure user access to  existing applications In a hybrid environment, where you have on-premises applications or non-native cloud applications using legacy authentication, consider solutions such as cloud access security broker (CASB), application proxy, single sign-on (SSO)  to govern the access to these applications for the following benefits: Protect your on-premises and non-native cloud applications using legacy authentication by connecting them to: Azure AD Application Proxy: Follow Azure's guidance to protect your on-premises and non-native cloud applications using legacy authentication by connecting them to: AWS Marketplace Application Proxy solutions: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 16.2 Configure Centralized Point of Authentication 12.5 - Centralize Network Authentication, Authorization, and Auditing (AAA) AC-3: ACCESS ENFORCEMENT - Enforce a centralized strong authentication - Azure AD Application Proxy and configure header-based authentication to allow single sign-on (SSO) access to the applications for remote users  while explicitly validating the trustworthiness of both remote users and devices with Azure AD Conditional Access. If required, use a third-party Software-Defined Perimeter (SDP) solution which can offer similar functionality. https://docs.microsoft.com/azure/active-directory/manage-apps/application-proxy#what-is-application-proxy - Azure AD Application Proxy and configure header-based authentication to allow single sign-on (SSO) access to the applications for remote users while explicitly validating the trustworthiness of both remote users and devices with Azure AD Conditional Access. If required, use a third-party Software-Defined Perimeter (SDP) solution which can offer similar functionality. https://aws.amazon.com/marketplace/search/results?searchTerms=Application+proxy SC-11: TRUSTED PATH - Monitor and control risky end-user activities - Microsoft Defender for Cloud Apps which serves as a cloud access security broker (CASB) service to monitor and block user access to unapproved third-party SaaS applications. - Microsoft Defender for Cloud Apps which serves as a cloud access security broker (CASB) service to monitor and block user access to unapproved third-party SaaS applications. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture - Monitor and remediate risky legacy applications activities - Your existing third-party application delivery controllers and networks. Microsoft Cloud App Security best practices: - Your existing third-party application delivery controllers and networks. AWS Marketplace CASB solutions: - Detect and prevent sensitive data transmission https://docs.microsoft.com/cloud-app-security/best-practices https://aws.amazon.com/marketplace/search/results?searchTerms=CASB Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Note: VPNs are commonly used to access legacy applications and often only have basic access control and limited session monitoring. Note: VPNs are commonly used to access legacy applications and often only have basic access control and limited session monitoring. Azure AD secure hybrid access: https://docs.microsoft.com/azure/active-directory/manage-apps/secure-hybrid-access"},{"location":"Azure/Security/MCSB/Incident%20Response/","title":"MCSB_v1 - Incident Response","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 Customer Security Stakeholders: IR-1 Incident Response 19.1 - Document Incident Response Procedures 17.4 - Establish and Maintain an Incident Response Process IR-4: INCIDENT HANDLING 10.8 Preparation - update incident response plan and handling process Ensure your organization follows industry best practice to develop processes and plans to respond to security incidents on the cloud platforms. Be mindful about the shared responsibility model and the variances across IaaS, PaaS, and SaaS services. This will have a direct impact to how you collaborate with your cloud provider in incident response and handling activities, such as incident notification and triage, evidence collection, investigation, eradication, and recovery. Update your organization's incident response process to include the handling of incidents in the Azure platform. Based on the Azure services used and your application nature, customize the incident response plan and playbook to ensure they can be used to respond to the incident in the cloud environment. Implement security across the enterprise environment: Update your organization's incident response process to include the handling of incidents. Ensure a unified multi-cloud incident response plan is in place by updating your organization's incident response process to include the handling of incidents in the AWS platform. Based on the AWS services used and your application nature, follow the AWS Security Incident Response Guide to customize the incident response plan and playbook to ensure they can be used to respond to the incident in the cloud environment. AWS Security Incident Response Guide:  https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/welcome.html Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center 19.7 - Conduct Periodic Incident Scenario Sessions for Personnel 17.7 - Conduct Routine Incident Response Exercises IR-8: INCIDENT RESPONSE PLAN https://docs.microsoft.com/azure/cloud-adoption-framework/secure/security-top-10#4-process-update-incident-response-processes-for-cloud Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation Regularly test the incident response plan and handling process to ensure they're up to date. Incident response reference guide: https://docs.microsoft.com/microsoft-365/downloads/IR-Reference-Guide.pdf Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence NIST SP800-61 Computer Security Incident Handling Guide https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r2.pdf Incident response overview: https://docs.microsoft.com/en-us/security/compass/incident-response-overview IR-2 Incident Response 19.2 - Assign Job Titles and Duties for Incident Response 17.1 - Designate Personnel to Manage Incident Handling IR-4: INCIDENT HANDLING 12.1 Preparation - setup incident contact information Ensure the security alerts and incident notification from the cloud service provider's platform and your environments can be received by correct contact in your incident response organization. Set up security incident contact information in Microsoft Defender for Cloud. This contact information is used by Microsoft to contact you if the Microsoft Security Response Center (MSRC) discovers that your data has been accessed by an unlawful or unauthorized party. You also have options to customize incident alerts and notification in different Azure services based on your incident response needs. How to set the Microsoft Defender for Cloud security contact: Set up security incident contact information in AWS Systems Manager Incident Manager (the incident management center for AWS). This contact information is used for incident management communication between you and AWS through the different channels (i.e., Email, SMS, or Voice). You can define a contact's engagement plan and escalation plan to describe how and when the  Incident Manager engages the contact and to escalate if the contact(s) does not response to an incident. Incident Manager Contact: https://docs.aws.amazon.com/incident-manager/latest/userguide/contacts.html Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center 19.3 - Designate Management Personnel to Support Incident Handling 17.3 - Establish and Maintain an Enterprise Process for Reporting Incidents IR-8: INCIDENT RESPONSE PLAN https://docs.microsoft.com/azure/security-center/security-center-provide-security-contact-details 19.4 - Devise Organization-wide Standards for Reporting Incidents 17.6 - Define Mechanisms for Communicating During Incident Response IR-5: INCIDENT MONITORING Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation 19.5 - Maintain Contact Information For Reporting Security Incidents IR-6: INCIDENT REPORTING IR-3 Incident Response 19.8 - Create Incident Scoring and Prioritization Schema 17.9 - Establish and Maintain Security Incident Thresholds IR-4: INCIDENT HANDLING 10.8 Detection and analysis - create incidents based on high-quality alerts Ensure you have a process to create high-quality alerts and measure the quality of alerts. This allows you to learn lessons from past incidents and prioritize alerts for analysts, so they don't waste time on false positives. Microsoft Defender for Cloud provides high-quality alerts across many Azure assets. You can use the Microsoft Defender for Cloud data connector to stream the alerts to Microsoft Sentinel. Microsoft Sentinel lets you create advanced alert rules to generate incidents automatically for an investigation. How to configure export: Use security tools like SecurityHub or GuardDuty and other third-party tools to send alerts to Amazon CloudWatch or Amazon EventBridge so incidents can be automatically created in Incident Manager based on the defined criteria and rule sets.  You can also manually create incidents in the Incident Manager for further incident handling and tracking. Incident creation in Incident Manager: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center IR-5: INCIDENT MONITORING https://docs.microsoft.com/azure/security-center/continuous-export https://docs.aws.amazon.com/incident-manager/latest/userguide/incident-creation.html IR-7 INCIDENT RESPONSE ASSISTANCE High-quality alerts can be built based on experience from past incidents, validated community sources, and tools designed to generate and clean up alerts by fusing and correlating diverse signal sources. Export your Microsoft Defender for Cloud alerts and recommendations using the export feature to help identify risks to Azure resources. Export alerts and recommendations either manually or in an ongoing, continuous fashion. If you use Microsoft Defender for Cloud to monitor your AWS accounts, you can also use Microsoft Sentinel to monitor and alert the incidents identified by Microsoft Defender for Cloud on AWS resources. Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation How to stream alerts into Microsoft Sentinel: How Defender for Cloud Apps helps protect your Amazon Web Services (AWS) environment: https://docs.microsoft.com/azure/sentinel/connect-azure-security-center https://docs.microsoft.com/en-us/defender-cloud-apps/protect-aws Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence IR-4 Incident Response nan nan IR-4: INCIDENT HANDLING 12.1 Detection and analysis - investigate an incident Ensure the security operation team can query and use diverse data sources as they investigate potential incidents, to build a full view of what happened. Diverse logs should be collected to track the activities of a potential attacker across the kill chain to avoid blind spots. You should also ensure insights and learnings are captured for other analysts and for future historical reference. Ensure your security operations team can query and use diverse data sources that are collected from the in-scope services and systems. In addition, it sources can also include: Snapshot a Windows machine's disk: The data sources for investigation are the centralized logging sources that collect from the in-scope services and running systems, but can also include: Traffic Mirroring: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center - Identity and access log data: Use Azure AD logs and workload (such as operating systems or application level) access logs for correlating identity and access events. https://docs.microsoft.com/azure/virtual-machines/windows/snapshot-copy-managed-disk - Identity and access log data: Use IAM logs and workload (such as operating systems or application level) access logs for correlating identity and access events. https://docs.aws.amazon.com/vpc/latest/mirroring/traffic-mirroring-how-it-works.html Use the cloud native SIEM and incident management solution if your organization does not have an existing solution to aggregate security logs and alerts information. Correlate incident data based on the data sourced from different sources to facility the incident investigations. - Network data: Use network security groups' flow logs, Azure Network Watcher, and Azure Monitor to capture network flow logs and other analytics information. - Network data: Use VPC Flow Logs, VPC Traffic Mirrors, and Azure CloudTrail and CloudWatch to capture network flow logs and other analytics information. Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation - Incident related activity data of from snapshots of the impacted systems, which can be obtained through: Snapshot a Linux machine's disk: - Snapshots of running systems, which can be obtained through: Creating EBS volume backups with AMIs and EBS snapshots: a) The azure virtual machine's snapshots capability, to create a snapshot of the running system's disk. https://docs.microsoft.com/azure/virtual-machines/linux/snapshot-copy-managed-disk a) Snapshot capability in Amazon EC2(EBS) to create a snapshot of the running system's disk. https://docs.aws.amazon.com/prescriptive-guidance/latest/backup-recovery/ec2-backup.html Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence b) The operating system's native memory dump capability, to create a snapshot of the running system's memory. b) The operating system's native memory dump capability, to create a snapshot of the running system's memory. c) The snapshot feature of the other supported Azure services or your software's own capability, to create snapshots of the running systems. Microsoft Azure Support diagnostic information and memory dump collection: c) The snapshot feature of the AWS services or your software's own capability, to create snapshots of the running systems. https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/use-immutable-storage.html https://azure.microsoft.com/support/legal/support-diagnostic-information-collection/ Microsoft Sentinel provides extensive data analytics across virtually any log source and a case management portal to manage the full lifecycle of incidents. Intelligence information during an investigation can be associated with an incident for tracking and reporting purposes. If you aggregate your SIEM related data into Microsoft Sentinel, it provides extensive data analytics across virtually any log source and a case management portal to manage the full lifecycle of incidents. Intelligence information during an investigation can be associated with an incident for tracking and reporting purposes. Investigate incidents with Azure Sentinel: Note: When incident related data is captured for investigation, ensure there is adequate security in place to protect the data from unauthorized alteration, such as disabling logging or removing logs, which can be performed by the attackers during an in-flight data breach activity. https://docs.microsoft.com/azure/sentinel/tutorial-investigate-cases Note: When incident related data is captured for investigation, ensure there is adequate security in place to protect the data from unauthorized alteration, such as disabling logging or removing logs, which can be performed by the attackers during an in-flight data breach activity. IR-5 Incident Response 19.8 - Create Incident Scoring and Prioritization Schema 17.4 - Establish and Maintain an Incident Response Process IR-4: INCIDENT HANDLING 12.1 Detection and analysis - prioritize incidents Provide context to security operations teams to help them determine which incidents ought to first be focused on, based on alert severity and asset sensitivity defined in your organization\u2019s incident response plan. Microsoft Defender for Cloud assigns a severity to each alert to help you prioritize which alerts should be investigated first. The severity is based on how confident Microsoft Defender for Cloud is in the finding or the analytics used to issue the alert, as well as the confidence level that there was malicious intent behind the activity that led to the alert. Security alerts in Microsoft Defender for Cloud: For each incident created in the Incident Manager, assign an impact level based on your organization's defined criteria, such as a measure of the severity of the incident and criticality level of the assets impacted. Define your naming convention best practice: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center 17.9 - Establish and Maintain Security Incident Thresholds https://docs.microsoft.com/azure/security-center/security-center-alerts-overview https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming Additionally, mark resources using tags and create a naming system to identify and categorize your cloud resources, especially those processing sensitive data. It is your responsibility to prioritize the remediation of alerts based on the criticality of the resources and environment where the incident occurred. Similarly, Microsoft Sentinel creates alerts and incidents with an assigned severity and other details based on analytics rules. Use analytic rule templates and customize the rules according to your organization's needs to support incident prioritization. Use automation rules in Microsoft Sentinel to manage and orchestrate threat response in order to maximize your security operation's team efficiency and effectiveness, including tagging incidents to classify them. Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation Use tags to organize your Azure resources: https://docs.microsoft.com/azure/azure-resource-manager/resource-group-using-tags Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence Create incidents from Microsoft security alerts: https://learn.microsoft.com/azure/sentinel/create-incidents-from-alerts IR-6 Incident Response nan nan IR-4: INCIDENT HANDLING 12.1 Containment, eradication and recovery - automate the incident handling Automate the manual, repetitive tasks to speed up response time and reduce the burden on analysts. Manual tasks take longer to execute, slowing each incident and reducing how many incidents an analyst can handle. Manual tasks also increase analyst fatigue, which increases the risk of human error that causes delays and degrades the ability of analysts to focus effectively on complex tasks. Use workflow automation features in Microsoft Defender for Cloud and Microsoft Sentinel to automatically trigger actions or run a playbooks to respond to incoming security alerts. Playbooks take actions, such as sending notifications, disabling accounts, and isolating problematic networks. Configure workflow automation in Security Center: If you use Microsoft Sentinel to centrally manage your incident, you can also create  automated actions or run a playbooks to respond to incoming security alerts. AWS Systems Manager - runbooks and automation: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center IR-5: INCIDENT MONITORING https://docs.microsoft.com/azure/security-center/workflow-automation https://docs.aws.amazon.com/incident-manager/latest/userguide/runbooks.html IR-6: INCIDENT REPORTING Alternatively, use automation features in AWS System Manager to automatically trigger actions defined in the incident response plan, including notifying the contacts and/or running a runbook to respond to alerts, such as disabling accounts, and isolating problematic networks. Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation Set up automated threat responses in Microsoft Defender for Cloud: https://docs.microsoft.com/azure/security-center/tutorial-security-incident#triage-security-alerts Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence Set up automated threat responses in Microsoft Sentinel: https://docs.microsoft.com/azure/sentinel/tutorial-respond-threats-playbook IR-7 Incident Response nan 17.8 - Conduct Post-Incident Reviews IR-4 INCIDENT HANDLING 12.1 Post-incident activity - conduct lesson learned and retain evidence Conduct lessons learned in your organization periodically and/or after major incidents, to improve your future capability in incident response and handling. Use the outcome from the lessons learned activity to update your incident response plan, playbook (such as a Microsoft Sentinel playbook) and reincorporate findings into your environments (such as logging and threat detection to address any gaps in logging) to improve your future capability in detecting, responding, and handling of incidents in Azure. Incident response process - Post-incident cleanup: Create incident analysis for a closed incident in Incident Manager using the standard incident analysis template or your own custom template. Use the outcome from the lessons learned activity to update your incident response plan, playbook (such as the AWS Systems Manager runbook and Microsoft Sentinel playbook) and reincorporate findings into your environments (such as logging and threat detection to address any gaps in logging) to improve your future capability in detecting, responding, and handling of the incidents in AWS. Post-incident analysis: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center https://docs.microsoft.com/security/compass/incident-response-process#2-post-incident-cleanup https://docs.aws.amazon.com/incident-manager/latest/userguide/analysis.html Based on the nature of the incident, retain the evidence related to the incident for the period defined in the incident handling standard for further analysis or legal actions. Keep the evidence collected during the \"Detection and analysis - investigate an incident step\" such as system logs, network traffic dumps and running system snapshots in storage such as an Azure Storage account for immutable retention. Keep the evidence collected during the \"Detection and analysis - investigate an incident step\" such as system logs, network traffic dumps and running system snapshot in storage such as an Amazon S3 bucket or Azure Storage account for immutable retention. Incident preparation: https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-incident-preparation Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence"},{"location":"Azure/Security/MCSB/Logging%20and%20Threat%20Detection/","title":"MCSB_v1 - Logging and Threat Detection","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 AWS Config Rule (WIP) Customer Security Stakeholders: LT-1 Logging and threat detection 6.7 - Regularly Review Logs 8.11 - Conduct Audit Log Reviews AU-3: CONTENT OF AUDIT RECORDS Enable threat detection capabilities To support threat detection scenarios, monitor all known resource types for known and expected threats and anomalies. Configure your alert filtering and analytics rules to extract high-quality alerts from log data, agents, or other data sources to reduce false positives. Use the threat detection capability of Microsoft Defender for Cloud for the respective Azure services. Introduction to Microsoft Defender for Cloud: Use Amazon GuardDuty for threat detection which analyzes and processes the following data sources: VPC Flow Logs, AWS CloudTrail management event logs, CloudTrail S3 data event logs, EKS audit logs, and DNS logs. GuardDuty is capable of reporting on security issues such as privilege escalation, exposed credential usage , or communication with malicious IP addresses, or domains. Amazon GuardDuty: nan Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING https://learn.microsoft.com/azure/defender-for-cloud/defender-for-cloud-introduction https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html AU-12: AUDIT GENERATION For threat detection not included in Microsoft Defender services, refer to Microsoft Cloud Security Benchmark service baselines for the respective services to enable the threat detection or security alert capabilities within the service. Ingest alerts and log data from Microsoft Defender for Cloud, Microsoft 365 Defender, and log data from other resources into your Azure Monitor or Microsoft Sentinel instances to build analytics rules, which hunt detect threats and create alerts that match specific criteria across your environment. Configure AWS Config to check rules in SecurityHub for compliance monitoring such as configuration drift, and create findings when needed. Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center SI-4: INFORMATION SYSTEM MONITORING Microsoft Defender for Cloud security alerts reference guide: Amazon GuardDuty data sources: For Operational Technology (OT) environments that include computers that control or monitor Industrial Control System (ICS) or Supervisory Control and Data Acquisition (SCADA) resources, use Microsoft Defender for IoT to inventory assets and detect threats and vulnerabilities. https://docs.microsoft.com/azure/security-center/alerts-reference For threat detection not included in GuardDuty and SecurityHub, enable threat detection or security alert capabilities within the supported AWS services. Extract the alerts to your CloudTrail, CloudWatch, or Microsoft Sentinel to build analytics rules, which hunt threats that match specific criteria across your environment. https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.html Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management For services that do not have a native threat detection capability, consider collecting the data plane logs and analyze the threats through Microsoft Sentinel. Create custom analytics rules to detect threats: You can also use Microsoft Defender for Cloud to monitor certain services in AWS such as EC2 instances. Connect your AWS accounts to Microsoft Defender for Cloud: Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops https://docs.microsoft.com/azure/sentinel/tutorial-detect-threats-custom https://docs.microsoft.com/en-us/azure/defender-for-cloud/quickstart-onboard-aws?pivots=env-settings For Operational Technology (OT) environments that include computers that control or monitor Industrial Control System (ICS) or Supervisory Control and Data Acquisition (SCADA) resources, use Microsoft Defender for IoT to inventory assets and detect threats and vulnerabilities. Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence Threat indicators for cyber threat intelligence in Microsoft Sentinel: How Defender for Cloud Apps helps protect your Amazon Web Services (AWS) environment https://docs.microsoft.com/azure/architecture/example-scenario/data/sentinel-threat-intelligence https://docs.microsoft.com/en-us/defender-cloud-apps/protect-aws Security recommendations for AWS resources - a reference guide: https://docs.microsoft.com/en-us/azure/defender-for-cloud/recommendations-reference-aws LT-2 Logging and threat detection 4.9 - Log and Alert on Unsuccessful Administrative Account Login 8.11 - Conduct Audit Log Reviews AU-3: CONTENT OF AUDIT RECORDS 10.6 Enable threat detection for  identity and access management Detect threats for identities and access management by monitoring the user and application sign-in and access anomalies. Behavioral patterns such as excessive number of failed login attempts, and deprecated accounts in the subscription, should be alerted. Azure AD provides the following logs that can be viewed in Azure AD reporting or integrated with Azure Monitor, Microsoft Sentinel or other SIEM/monitoring tools for more sophisticated monitoring and analytics use cases: Audit activity reports in Azure AD: AWS IAM provides the following reporting the logs and reports for console user activities through IAM Access Advisor and IAM credential report: IAM credential reports: nan Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 6.7 - Regularly Review Logs AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING 10.8 - Sign-ins: The sign-ins report provides information about the usage of managed applications and user sign-in activities. https://docs.microsoft.com/azure/active-directory/reports-monitoring/concept-audit-logs - Every successful sign-in and unsuccessful login attempts. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html 16.13 - Alert on Account Login Behavior Deviation AU-12: AUDIT GENERATION A3.5 - Audit logs: Provides traceability through logs for all changes done by various features within Azure AD. Examples of audit logs include changes made to any resources within Azure AD like adding or removing users, apps, groups, roles and policies. - Multi-factor authentication (MFA) status for each user. Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center SI-4: INFORMATION SYSTEM MONITORING - Risky sign-ins: A risky sign-in is an indicator for a sign-in attempt that might have been performed by someone who is not the legitimate owner of a user account. Enable Azure Identity Protection: - Dormant IAM user GuardDuty data source: - Users flagged for risk: A risky user is an indicator for a user account that might have been compromised. https://docs.microsoft.com/azure/active-directory/identity-protection/overview-identity-protection https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.html Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management For API level access monitoring and threat detection, use Amazon GuadDuty to identify the findings related to the IAM. Examples of these findings include: Azure AD also provides an Identity Protection module to detect and remediate risks related to user accounts and sign-in behaviors. Examples of risks include leaked credentials, sign-in from anonymous or malware linked IP addresses, password spray. The policies in Azure AD Identity Protection allow you to enforce risk-based MFA authentication in conjunction with Azure Conditional Access on user accounts. Threat protection in Microsoft Defender for Cloud: - An API used to gain access to an AWS environment and was invoked in an anomalous way, or was used to evade defensive measures GuardDuty IAM finding types: Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops https://docs.microsoft.com/azure/security-center/threat-protection - An API used to: https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_finding-types-iam.html In addition, Microsoft Defender for Cloud can be configured to alert on deprecated accounts in the subscription and suspicious activities such as an excessive number of failed authentication attempts. In addition to the basic security hygiene monitoring, Microsoft Defender for Cloud's Threat Protection module can also collect more in-depth security alerts from individual Azure compute resources (such as virtual machines, containers, app service), data resources (such as SQL DB and storage), and Azure service layers. This capability allows you to see account anomalies inside the individual resources. a) discover resources was invoked in an anomalous way Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence Overview of Microsoft Defender for Identity: b) collect data from an AWS environment was invoked in an anomalous way. Note: If you are connecting your on-premises Active Directory for synchronization, use the Microsoft Defender for Identity solution to consume your on-premises Active Directory signals to identify, detect, and investigate advanced threats, compromised identities, and malicious insider actions directed at your organization. https://learn.microsoft.com/defender-for-identity/what-is b) tamper with data or processes in an AWS environment was invoked in an anomalous way. c) gain unauthorized access to an AWS environment was invoked in an anomalous way. d) maintain unauthorized access to an AWS environment was invoked in an anomalous way. e) obtain high-level permissions to an AWS environment was invoked in an anomalous way. f) be invoked from a known malicious IP address. g) be invoked using root credentials. - AWS CloudTrail logging was disabled. - Account password policy was weakened. - Multiple worldwide successful console logins were observed. - Credentials that were created exclusively for an EC2 instance through an Instance launch role are being used from another account within AWS. - Credentials that were created exclusively for an EC2 instance through an Instance launch role are being used from an external IP address. - An API was invoked from a known malicious IP address. - An API was invoked from an IP address on a custom threat list. - An API was invoked from a Tor exit node IP address. LT-3 Logging and threat detection 6.2 - Activate Audit Logging 8.2 - Collect Audit Logs AU-3: CONTENT OF AUDIT RECORDS 10.1 Enable logging for security investigation Enable logging for your cloud resources to meet the requirements for security incident investigations and security response and compliance purposes. Enable logging capability for resources at the different tiers, such as logs for Azure resources, operating systems and applications inside in your VMs and other log types. Understand logging and different log types in Azure: Use AWS CloudTrail logging for management events (control plane operations) and data events (data plane operations) and monitor these trails with CloudWatch for automated actions. Enabling logging from certain AWS services: nan Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 6.3 - Enable Detailed Logging 8.5 - Collect Detailed Audit Logs AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING 10.2 https://docs.microsoft.com/azure/azure-monitor/platform/platform-logs-overview https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html 8.8 - Enable Command-Line Audit Logging 8.12 - Collect Service Provider Logs AU-12: AUDIT GENERATION 10.3 Be mindful about different types of logs for security, audit, and other operational logs at the management/control plane and data plane tiers. There are three types of the logs available at the Azure platform: The Amazon CloudWatch Logs service allows you to collect and store logs from your resources, applications, and services in near real time. There are three main categories of logs: Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center SI-4: INFORMATION SYSTEM MONITORING - Azure resource log: Logging of operations that are performed within an Azure resource (the data plane). For example, getting a secret from a key vault or making a request to a database. The content of resource logs varies by the Azure service and resource type. Understand Microsoft Defender for Cloud data collection: - Vended logs: Logs natively published by AWS services on your behalf. Currently, Amazon VPC Flow Logs and Amazon Route 53 logs are the two supported types. These two logs are enabled by default. https://docs.aws.amazon.com/whitepapers/latest/introduction-aws-security/monitoring-and-logging.html - Azure activity log: Logging of operations on each Azure resource at the subscription layer, from the outside (the management plane). You can use the Activity Log to determine what, who, and when for any write operations (PUT, POST, DELETE) taken on the resources in your subscription. There is a single Activity log for each Azure subscription. https://docs.microsoft.com/azure/security-center/security-center-enable-data-collection - Logs published by AWS services: Logs from more than 30 AWS services publish to CloudWatch. They include Amazon API Gateway, AWS Lambda, AWS CloudTrail, and many others. These logs can be enabled directly in the services and CloudWatch. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Azure Active Directory logs: Logs of the history of sign-in activity and audit trail of changes made in the Azure Active Directory for a particular tenant. - Custom logs: Logs from your own application and on-premises resources. You may need to collect these logs by installing CloudWatch Agent in your operating systems and forward them to CloudWatch. https://aws.amazon.com/cloudwatch/features/ Enable and configure antimalware monitoring: Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops You can also use Microsoft Defender for Cloud and Azure Policy to enable resource logs and log data collecting on Azure resources. https://docs.microsoft.com/azure/security/fundamentals/antimalware#enable-and-configure-antimalware-monitoring-using-powershell-cmdlets While many services publish logs only to CloudWatch Logs, some AWS services can publish logs directly to AmazonS3 or Amazon Kinesis Data Firehose where you can use different logging storage and retention policies. Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence Operating systems and application logs inside in your compute resources: https://docs.microsoft.com/azure/azure-monitor/agents/data-sources#operating-system-guest LT-4 Logging and threat detection 6.2 - Activate Audit Logging 8.2 - Collect Audit Logs AU-3: CONTENT OF AUDIT RECORDS 10.8 Enable network logging for security investigation Enable logging for your network services to support network-related incident investigations, threat hunting, and security alert generation. The network logs may include logs from network services such as IP filtering, network and application firewall, DNS, flow monitoring and so on. Enable and collect network security group (NSG) resource logs, NSG flow logs, Azure Firewall logs, and Web Application Firewall (WAF) logs, and logs from virtual machines via the network traffic data collection agent for security analysis to support incident investigations, and security alert generation. You can send the flow logs to an Azure Monitor Log Analytics workspace and then use Traffic Analytics to provide insights. How to enable network security group flow logs: Enable and collect network logs such as VPC Flow Logs, WAF Logs, and Route53 Resolver query logs for security analysis to support incident investigations, and security alert generation. The logs can be exported to CloudWatch for monitoring or an S3 storage bucket for ingesting into the Microsoft Sentinel solution for centralized analytics. https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html nan Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center 6.3 - Enable Detailed Logging 8.5 - Collect Detailed Audit Logs AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING https://docs.microsoft.com/azure/network-watcher/network-watcher-nsg-flow-logging-portal 7.6 - Log All URL Requests 8.6 - Collect DNS Query Audit Logs AU-12: AUDIT GENERATION Collect DNS query logs to assist in correlating other network data. Infrastructure and endpoint security 8.7 - Enable DNS Query Logging 8.7 - Collect URL Request Audit Logs SI-4: INFORMATION SYSTEM MONITORING Azure Firewall logs and metrics: 12.8 - Deploy NetFlow Collection on Networking Boundary Devices 13.6 - Collect Network Traffic Flow Logs https://docs.microsoft.com/azure/firewall/logs-and-metrics Application security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Azure networking monitoring solutions in Azure Monitor: Threat intelligence: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-threat-intelligence https://docs.microsoft.com/azure/azure-monitor/insights/azure-networking-analytics Gather insights about your DNS infrastructure with the DNS Analytics solution: https://docs.microsoft.com/azure/azure-monitor/insights/dns-analytics LT-5 Logging and threat detection 6.5 - Central Log Management 8.9 - Centralize Audit Logs AU-3: CONTENT OF AUDIT RECORDS nan Centralize security log management and analysis Centralize logging storage and analysis to enable correlation across log data. For each log source, ensure that you have assigned a data owner, access guidance, storage location, what tools are used to process and access the data, and data retention requirements. Ensure that you are integrating Azure activity logs into a centralized Log Analytics workspace. Use Azure Monitor to query and perform analytics and create alert rules using the logs aggregated from Azure services, endpoint devices, network resources, and other security systems. How to collect platform logs and metrics with Azure Monitor: Ensure that you are integrating your AWS logs  into a centralized resource for storage and analysis. Use CloudWatch to query and perform analytics, and to create alert rules using the logs aggregated from AWS services, services, endpoint devices, network resources, and other security systems. Connect Microsoft Sentinel to Amazon Web Services to ingest AWS service log data: nan Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 6.6 - Deploy SIEM or Log Analytic tool 8.11 - Conduct Audit Log Reviews AU-6: AUDIT REVIEW, ANALYSIS, AND REPORTING https://docs.microsoft.com/azure/azure-monitor/platform/diagnostic-settings https://docs.microsoft.com/en-us/azure/sentinel/connect-aws?tabs=s3 6.7 - Regularly Review Logs 13.1 - Centralize Security Event Alerting AU-12: AUDIT GENERATION Use Cloud native SIEM if you don't have an existing SIEM solution for CSPs. or aggregate logs/alerts into your existing SIEM. In addition, enable and onboard data to Microsoft Sentinel which provides security information event management (SIEM) and security orchestration automated response (SOAR) capabilities. In addition, you can aggregate the logs in a S3 storage bucket and onboard the log data to Microsoft Sentinel which provides security information event management (SIEM) and security orchestration automated response (SOAR) capabilities. Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 8.6 - Centralize Anti-Malware Logging SI-4: INFORMATION SYSTEM MONITORING How to onboard Azure Sentinel: https://docs.microsoft.com/azure/sentinel/quickstart-onboard Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint LT-6 Logging and threat detection 6.4 - Ensure Adequate Storage for Logs 8.3 - Ensure Adequate Audit Log Storage AU-11: AUDIT RECORD RETENTION 10.5 Configure log storage retention Plan your log retention strategy according to your compliance, regulation, and business requirements. Configure the log retention policy at the individual logging services to ensure the logs are archived appropriately. Logs such as Azure Activity Logs are retained for 90 days and then deleted. You should create a diagnostic setting and route the logs to another location (such as Azure Monitor Log Analytics workspace, Event Hubs or Azure Storage) based on your needs. This strategy also applies to other resource logs and resources managed by yourself such as logs in the operating systems and applications inside VMs. Change the data retention period in Log Analytics: By default, logs are kept indefinitely and never expire in CloudWatch. You can adjust the retention policy for each log group, keeping the indefinite retention, or choosing a retention period between 10 years and one day. Altering CloudWatch log retention: nan Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 8.10 - Retain Audit Logs 10.7 https://docs.microsoft.com/azure/azure-monitor/platform/manage-cost-storage#change-the-data-retention-period https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html You have the log retention option as below: Use Amazon S3 for log archival from CloudWatch and apply object lifecycle management and archival policy to the bucket. You can use Azure Storage for central log archival by transferring the files from Amazon S3 to Azure Storage. Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops - Use Azure Monitor Log Analytics workspace for a log retention period of up to 1 year or per your response team requirements. How to configure retention policy for Azure Storage account logs: Copy data from Amazon S3 to Azure Storage by using AzCopy: - Use Azure Storage, Data Explorer or Data Lake for long-term and archival storage for greater than 1 year and to meet your security compliance requirements. https://docs.microsoft.com/azure/storage/common/storage-monitor-storage-account#configure-logging https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-s3 Security operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center - Use Azure Event Hubs to forward logs to an external resource outside of Azure. Microsoft Defender for Cloud alerts and recommendations export: https://docs.microsoft.com/azure/security-center/continuous-export Security compliance management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Note: Microsoft Sentinel uses Log Analytics workspace as its backend for log storage. You should consider a long-term storage strategy if you plan to retain SIEM logs for longer time. LT-7 Logging and threat detection 6.1 - Utilize Three Synchronized Time Sources 8.4 - Standardize Time Synchronization AU-8: TIME STAMPS 10.4 Use approved time synchronization sources Use approved time synchronization sources for your logging time stamp which include date, time and time zone information. Microsoft maintains time sources for most Azure PaaS and SaaS services. For your compute resources operating systems, use a Microsoft default NTP server for time synchronization unless you have a specific requirement. If you need to stand up your own network time protocol (NTP) server, ensure you secure the UDP service port 123. How to configure time synchronization for Azure Windows compute resources: AWS maintains time sources for most AWS services. For resources or services where the operating system time setting is configured, use AWS default Amazon Time Sync Service for time synchronization unless you have a specific requirement. If you need to stand up your own network time protocol (NTP) server, ensure you secure the UDP service port 123. Set the time for a Linux instance: nan Policy and standards: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-policy-standards https://docs.microsoft.com/azure/virtual-machines/windows/time-sync https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html All logs generated by resources within Azure provide time stamps with the time zone specified by default. All logs generated by resources within AWS provide time stamps with the time zone specified by default. Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops How to configure time synchronization for Azure Linux compute resources: Set the time for a Windows instance: https://docs.microsoft.com/azure/virtual-machines/linux/time-sync https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/windows-set-time.html Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint How to disable inbound UDP for Azure services: https://support.microsoft.com/help/4558520/how-to-disable-inbound-udp-for-azure-services"},{"location":"Azure/Security/MCSB/Network%20Security/","title":"MCSB_v1 - Network Security","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context: Customer Security Stakeholders: NS-1 Network Security 9.2 - Ensure Only Approved Ports, Protocols and Services Are Running 3.12 - Segment Data Processing and Storage Based on Sensitivity AC-4: INFORMATION FLOW ENFORCEMENT 1.1 Establish network segmentation boundaries Ensure that your virtual network deployment aligns to your enterprise segmentation strategy defined in the GS-2 security control. Any workload that could incur higher risk for the organization should be in isolated virtual networks. Create a virtual network (VNet) as a fundamental segmentation approach in your Azure network, so resources such as VMs can be deployed into the VNet within a network boundary. To further segment the network, you can create subnets inside VNet for smaller sub-networks. Azure Virtual Network concepts and best practices: Create a Virtual Private Cloud (VPC) as a fundamental segmentation approach in your AWS network, so resources such as EC2 instances can be deployed into the VPC within a network boundary. To further segment the network, you can create subnets inside VPC for smaller sub-networks. Control traffic to EC2 instances with security groups: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 9.4 - Apply Host-Based Firewalls or Port Filtering 13.4 - Perform Traffic Filtering Between Network Segments SC-2: APPLICATION PARTITIONING 1.2 Examples of high-risk workload include: https://docs.microsoft.com/azure/virtual-network/concepts-and-best-practices https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html 12.3 - Deny Communications with Known Malicious IP Addresses 4.4 - Implement and Manage a Firewall on Severs SC-7: BOUNDARY PROTECTION 1.3 - An application storing or processing highly sensitive data. Use network security groups (NSG) as a network layer control to restrict or monitor traffic by port, protocol, source IP address, or destination IP address. Refer to NS-7 Simplify network security configuration to use Adaptive Network Hardening to recommend NSG hardening rules based on threat intelligence and traffic analysis result. For EC2 instances, use Security Groups, as a stateful firewall to restrict traffic by port, protocol, source IP address, or destination IP address. At the VPC subnet level, use Network Access Control List (NACL) as a stateless firewall to have explicit rules for ingress and egress traffic to the subnet. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 12.4 - Deny Communication over Unauthorized Ports - An external network-facing application accessible by the public or users outside of your organization. Add, change, or delete a virtual network subnet: Compare security groups and network ACLs: 14.1 - Segment the Network Based on Sensitivity - An application using insecure architecture or containing vulnerabilities that cannot be easily remediated. You can also use application security groups (ASGs) to simplify complex configuration. Instead of defining policy based on explicit IP addresses in network security groups, ASGs enable you to configure network security as a natural extension of an application's structure, allowing you to group virtual machines and define network security policies based on those groups. https://docs.microsoft.com/azure/virtual-network/virtual-network-manage-subnet Note: To control VPC traffic, Internet and NAT Gateway should be configured to ensure the traffic from/to the internet are restricted. https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html#VPC_Security_Comparison Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 14.2 - Enable Firewall Filtering Between VLANs To enhance your enterprise segmentation strategy, restrict or monitor traffic between internal resources using network controls. For specific, well-defined applications (such as a 3-tier app), this can be a highly secure \"deny by default, permit by exception\" approach by restricting the ports, protocols, source, and destination IPs of the network traffic. If you have many applications and endpoints interacting with each other, blocking traffic may not scale well, and you may only be able to monitor traffic. How to create a network security group with security rules: Internet Gateway: https://docs.microsoft.com/azure/virtual-network/tutorial-filter-network-traffic https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html Understand and use application security groups: NAT Gateway: https://docs.microsoft.com/azure/virtual-network/network-security-groups-overview#application-security-groups https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html NS-2 Network Security 14.1 - Segment the Network Based on Sensitivity 3.12 - Segment Data Processing and Storage Based on Sensitivity AC-4: INFORMATION FLOW ENFORCEMENT 1.1 Secure cloud native services with network controls Secure cloud services by establishing a private access point for the resources. You should also disable or restrict access from public network when possible. Deploy private endpoints for all Azure resources that support the Private Link feature, to establish a private access point for the resources. Using Private Link will keep the private connection from routing through the public network. Understand Azure Private Link: Deploy VPC PrivateLink for all AWS resources that support the PrivateLink feature, to allow private connection to the supported AWS services or services hosted by other AWS accounts (VPC endpoint services). Using PrivateLink will keep the private connection from routing through the public network. AWS PrivateLink: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 4.4 - Implement and Manage a Firewall on Servers SC-2: APPLICATION PARTITIONING 1.2 https://docs.microsoft.com/azure/private-link/private-link-overview https://docs.aws.amazon.com/vpc/latest/privatelink/endpoint-service.html SC-7: BOUNDARY PROTECTION 1.3 Note: Certain Azure services may also allow private communication through the service endpoint feature, though it is recommended to use Azure Private Link for secure and private access to services hosted on Azure platform. For certain services, you can choose to deploy the service instance into your own VPC to isolate the traffic. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management Integrate Azure services with virtual networks for network isolation: Blocking public access to your Amazon S3 storage: For certain services, you can choose to deploy VNet integration for the service where you can restrict/isolate the VNET to establish a private access point for the service. https://learn.microsoft.com/en-us/azure/virtual-network/vnet-integration-for-azure-services You also have the option to configure the service native ACL rules to block access from the public network. For example, Amazon S3 allows you to block public access at the bucket or account level. https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-control-block-public-access.html Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops You also have the option to configure the service native network ACL rules or simply disable public network access to block access from the public network. When assigning IPs to your service resources in your VPC, unless there is a strong use case, you should avoid assigning public IPs/subnet directly to your resources and instead use private IPs/subnet. For Azure VMs, unless there is a strong use case, you should avoid assigning public IPs/subnet directly to the VM interface and instead use gateway or load balancer services as the front-end for access by the public network. NS-3 Network Security 9.2 - Ensure Only Approved Ports, Protocols and Services Are Running 4.4 - Implement and Manage a Firewall on Servers AC-4: INFORMATION FLOW ENFORCEMENT 1.1 Deploy firewall at the edge of enterprise network Deploy a firewall to perform advanced filtering on network traffic to and from external networks. You can also use firewalls between internal segments to support a segmentation strategy. If required, use custom routes for your subnet to override the system route when you need to force the network traffic to go through a network appliance for security control purpose. Use Azure Firewall to provide fully stateful application layer traffic restriction (such as URL filtering) and/or central management over a large number of enterprise segments or spokes (in a hub/spoke topology). How to deploy Azure Firewall: Use AWS Network Firewall to provide fully stateful application layer traffic restriction (such as URL filtering) and/or central management over a large number of enterprise segments or spokes (in a hub/spoke topology). AWS Network Firewall: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 9.4 - Apply Host-Based Firewalls or Port Filtering 4.8 - Uninstall or Disable Unnecessary Services on Enterprise Assets and Software SC-7: BOUNDARY PROTECTION 1.2 https://docs.microsoft.com/azure/firewall/tutorial-firewall-deploy-portal https://docs.aws.amazon.com/network-firewall/latest/developerguide/what-is-aws-network-firewall.html 12.3 - Deny Communications with Known Malicious IP Addresses 13.10 Perform Application Layer Filtering CM-7: LEAST FUNCTIONALITY 1.3 At a minimum, block known bad IP addresses and high-risk protocols, such as remote management (for example, RDP and SSH) and intranet protocols (for example, SMB and Kerberos). If you have a complex network topology, such as a hub/spoke setup, you may need to create user-defined routes (UDR) to ensure the traffic goes through the desired route. For example, you have the option to use an UDR to redirect egress internet traffic through a specific Azure Firewall or a network virtual appliance. If you have a complex network topology, such as a hub/spoke setup, you may need to create custom VPC route tables to ensure the traffic goes through the desired route.  For example, you have the option to use a custom route to redirect egress internet traffic through a specific AWS Firewall or a network virtual appliance. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 12.4 - Deny Communication over Unauthorized Ports Virtual network traffic routing: AWS VPC configure custom route tables: 14.1 - Segment the Network Based on Sensitivity https://docs.microsoft.com/azure/virtual-network/virtual-networks-udr-overview https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 14.2 - Enable Firewall Filtering Between VLANs NS-4 Network Security 12.6 - Deploy Network-Based IDS Sensors 13.2 Deploy a Host-Based Intrusion Detection Solution SC-7: BOUNDARY PROTECTION 11.4 Deploy intrusion detection/intrusion prevention systems (IDS/IPS) Use network intrusion detection and intrusion prevention systems (IDS/IPS) to inspect the network and payload traffic to or from your workload. Ensure that IDS/IPS is always tuned to provide high-quality alerts to your SIEM solution. Use Azure Firewall\u2019s IDPS capability to protect your virtual network to alert on and/or block traffic to and from known malicious IP addresses and domains. Azure Firewall IDPS: Use AWS Network Firewall\u2019s IPS capability to protect your VPC to alert on and/or block traffic to and from known malicious IP addresses and domains. IPS stateful rule groups in AWS Network Firewall: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 12.7 - Deploy Network-Based Intrusion Prevention Systems 13.3 - Deploy a Network Intrusion Detection Solution SI-4: INFORMATION SYSTEM MONITORING https://docs.microsoft.com/azure/firewall/premium-features#idps https://docs.aws.amazon.com/network-firewall/latest/developerguide/stateful-rule-groups-ips.html 13.7 Deploy a Host-Based Intrusion Prevention Solution For more in-depth host level detection and prevention capability, use host-based IDS/IPS or a host-based endpoint detection and response (EDR) solution in conjunction with the network IDS/IPS. For more in-depth host-level detection and prevention capabilities, deploy host-based IDS/IPS or a host-based endpoint detection and response (EDR) solution, such as Microsoft Defender for Endpoint, at the VM level in conjunction with the network IDS/IPS. For more in-depth host-level detection and prevention capabilities, deploy host-based IDS/IPS or a host-based endpoint detection and response (EDR) solution, such as third-party solution for host-based IDS/IPS, at the VM level in conjunction with the network IDS/IPS. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 13.8 - Deploy a Network Intrusion Prevention Solution Microsoft Defender for Endpoint capability: https://docs.microsoft.com/windows/security/threat-protection/microsoft-defender-atp/overview-endpoint-detection-response https://aws.amazon.com/marketplace/search?searchTerms=IPS Note: If using a third-party IDS/IPS from marketplace, use Transit Gateway and Gateway Balancer to direct the traffic for in-line inspection. Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops NS-5 Network Security 9.5 - Implement Application Firewalls 13.10 - Perform Application Layer Filtering SC-5: DENIAL OF SERVICE PROTECTION 1.1 Deploy DDOS protection Deploy distributed denial of service (DDoS) protection to protect your network and applications from attacks. DDoS Protection Basic is automatically enabled to protect the Azure underlying platform infrastructure (e.g., Azure DNS) and requires no configuration from the users. Manage Azure DDoS Protection Standard using the Azure portal: AWS Shield Standard is automatically enabled with standard mitigations, to protect your workload from common network and transport layer (Layer 3 and 4) DDoS attacks AWS Shield Features: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 12.3 - Deny Communications with Known Malicious IP Addresses SC-7: BOUNDARY PROTECTION 1.2 https://docs.microsoft.com/azure/virtual-network/manage-ddos-protection https://docs.aws.amazon.com/waf/latest/developerguide/ddos-overview.html 1.3 For higher levels of protection of your application layer (Layer 7) attacks such as HTTP floods and DNS floods, enable the DDoS standard protection plan on your VNet to protect resources that are exposed to the public networks. For higher levels of protection of your applications against application layer (Layer 7) attack such as HTTPS floods, and DNS floods, enable AWS Shield Advanced protection on Amazon EC2, Elastic Load Balancing (ELB), Amazon CloudFront, AWS Global Accelerator, and Amazon Route 53. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 6.6 Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops NS-6 Network Security 9.5 - Implement Application Firewalls 13.10 - Perform Application Layer Filtering SC-7: BOUNDARY PROTECTION 1.1 Deploy web application firewall Deploy a web application firewall (WAF) and configure the appropriate rules to protect your web applications and APIs from application-specific attacks. Use web application firewall (WAF) capabilities in Azure Application Gateway, Azure Front Door, and Azure Content Delivery Network (CDN) to protect your applications, services and APIs against application layer attacks at the edge of your network. How to deploy Azure WAF: Use AWS Web Application Firewall (WAF) in Amazon CloudFront distribution, Amazon API Gateway, Application Load Balancer, or AWS AppSync to protect your applications, services, and APIs against application layer attacks at the edge of your network. How AWS WAF works: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 12.3 - Deny Communications with Known Malicious IP Addresses 1.2 https://docs.microsoft.com/azure/web-application-firewall/overview https://docs.aws.amazon.com/waf/latest/developerguide/how-aws-waf-works.html 12.9 - Deploy Application Layer Filtering Proxy Server 1.3 Set your WAF in \"detection\" or \"prevention mode,\" depending on your needs and threat landscape. Use AWS Managed Rules for WAF to deploy built-in baseline groups, and customize it to your application needs for the user-case rule groups. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 18.10 - Deploy Web Application Firewalls (WAFs) 6.6 AWS WAF Security Automations: Choose a built-in ruleset, such as OWASP Top 10 vulnerabilities, and tune it to your application needs. To simplify the WAF rules deployment, you can also use the AWS WAF Security Automations solution to automatically deploy pre-defined AWS WAF rules that filters web-based attacks on your web ACL. https://docs.aws.amazon.com/solutions/latest/aws-waf3-security-automations/welcome.html Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops AWS Managed Rules for AWS WAF: https://docs.aws.amazon.com/waf/latest/developerguide/aws-managed-rule-groups.html NS-7 Network Security 9.2 - Ensure Only Approved Ports, Protocols and Services Are Running 4.4 - Implement and Manage a Firewall on Severs AC-4: INFORMATION FLOW ENFORCEMENT 1.1 Simplify network security configuration When managing a complex network environment, use tools to simplify, centralize and enhance the network security management. Use the following features to simplify the implementation and management of the virtual network, NSG rules, and Azure Firewall rules: Adaptive Network Hardening in Microsoft Defender for Cloud: Use AWS Firewall Manager to centralize the network protection policy management across the following services. AWS Firewall Manager: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 4.8 - Uninstall or Disable Unnecessary Services on Enterprise Assets and Software SC-2: APPLICATION PARTITIONING 1.2 - Use Azure Virtual Network Manager to group, configure, deploy, and manage virtual networks and NSG rules across regions and subscriptions. https://docs.microsoft.com/azure/security-center/security-center-adaptive-network-hardening - AWS WAF policies https://docs.aws.amazon.com/waf/latest/developerguide/getting-started-fms-intro.html SC-7: BOUNDARY PROTECTION 1.3 - Use Microsoft Defender for Cloud Adaptive Network Hardening to recommend NSG hardening rules that further limit ports, protocols and source IPs based on threat intelligence and traffic analysis result. - AWS Shield Advanced policies Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Use Azure Firewall Manager to centralize the firewall policy and route management of the virtual network. To simplify the firewall rules and network security groups implementation, you can also use the Azure Firewall Manager Azure Resource Manager (ARM) template. Azure Firewall Manager: - VPC security group policies https://docs.aws.amazon.com/waf/latest/developerguide/fms-findings.html https://docs.microsoft.com/azure/firewall-manager/overview - Network Firewall policies Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops AWS Firewall Manager can automatically analyze your firewall-related policies and create findings for non-compliant resources and for detected attacks and sends them to AWS Security Hub for investigation. Create an Azure Firewall and a firewall policy - ARM template https://docs.microsoft.com/azure/firewall-manager/quick-firewall-policy NS-8 Network Security 9.2 - Ensure Only Approved Ports, Protocols and Services Are Running 4.4 - Implement and Manage a Firewall on Severs CM-2: BASELINE CONFIGURATION 4.1 Detect and disable insecure services and  protocols Detect and disable insecure services and protocols at the OS, application, or software package layer. Deploy compensating controls if disabling insecure services and protocols are not possible. Use Microsoft Sentinel\u2019s built-in Insecure Protocol Workbook to discover the use of insecure services and protocols such as SSL/TLSv1, SSHv1, SMBv1, LM/NTLMv1, wDigest, weak ciphers in Kerberos, and Unsigned LDAP Binds. Disable insecure services and protocols that do not meet the appropriate security standard. Azure Sentinel insecure protocols workbook: Enable VPC Flow Logs and use GuardDuty to analyze the VPC Flow Logs to identify the possible insecure services and protocols that do not meet the appropriate security standard. Use GuardDuty with VPC Flow Logs as the data source: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 4.8 - Uninstall or Disable Unnecessary Services on Enterprise Assets and Software CM-6: CONFIGURATION SETTINGS A2.1 https://docs.microsoft.com/azure/sentinel/quickstart-get-visibility#use-built-in-workbooks https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.html#guardduty_vpc CM-7: LEAST FUNCTIONALITY A2.2 Note: If disabling insecure services or protocols is not possible, use compensating controls such as blocking access to the resources through network security groups, Azure Firewall, or Azure Web Application Firewall to reduce the attack surface. If the logs in the AWS environment can be forwarded to Microsoft Sentinel, you can also use Microsoft Sentinel\u2019s built-in Insecure Protocol Workbook to discover the use of insecure services and protocols Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management A2.3 Note: If disabling insecure services or protocols is not possible, use compensating controls such as blocking access to the resources through security groups, AWS Network Firewall, or AWS Web Application Firewall to reduce the attack surface. Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops NS-9 Network Security nan 12.7 - Ensure Remote Devices Utilize a VPN and are Connecting to CA-3: SYSTEM INTERCONNECTIONS nan Connect on-premises or cloud network privately Use private connections for secure communication between different networks, such as cloud service provider datacenters and on-premises infrastructure in a colocation environment. For lightweight site-to-site or point-to-site connectivity, use Azure virtual private network (VPN) to create a secure connection between your on-premises site or end-user device and the Azure virtual network. Azure VPN overview: For lightweight site-to-site or point-to-site connectivity, use AWS VPN to create a secure connection (when IPsec overhead is not a concern) between your on-premises site or end-user device to the AWS network. AWS Direct Connect introduction: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture an Enterprise\u2019s AAA Infrastructure AC-17: REMOTE ACCESS https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-about-vpngateways https://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html AC-4: INFORMATION FLOW ENFORCEMENT For enterprise-level high performance connections, use Azure ExpressRoute (or Virtual WAN) to connect Azure datacenters and on-premises infrastructure in a co-location environment. For enterprise-level high performance connections, use AWS Direct Connect to connect AWS VPCs and resources with your on-premises infrastructure in a co-location environment. Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management What are the ExpressRoute connectivity models: AWS VPN introduction: When connecting two or more Azure virtual networks together, use virtual network peering. Network traffic between peered virtual networks is private and is kept on the Azure backbone network. https://docs.microsoft.com/azure/expressroute/expressroute-connectivity-models You have the option to use VPC Peering or Transit Gateway to establish connectivity between two or more VPCs within or across regions.  Network traffic between peered VPC is private and is kept on the AWS backbone network.  When you need to join multiple VPCs to create a large flat subnet, you also have the option to use VPC Sharing. https://docs.aws.amazon.com/vpn/ Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Virtual network peering: Transit Gateway: https://docs.microsoft.com/azure/virtual-network/virtual-network-peering-overview https://docs.aws.amazon.com/vpc/latest/tgw/what-is-transit-gateway.html Create and accept VPC peering connections: https://docs.aws.amazon.com/vpc/latest/peering/create-vpc-peering-connection.html VPC Sharing: https://docs.aws.amazon.com/whitepapers/latest/building-scalable-secure-multi-vpc-network-infrastructure/amazon-vpc-sharing.html NS-10 Network Security 7.7 - Use of DNS Filtering Services 4.9 - Configure Trusted DNS Servers on Enterprise Assets SC-20: SECURE NAME / ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) nan Ensure Domain Name System (DNS) security Ensure that Domain Name System (DNS) security configuration protects against known risks: Use Azure recursive DNS  (usually assigned to your VM through DHCP or preconfigured in the service) or a trusted external DNS server in your workload recursive DNS setup, such as in the VM's operating system or in the application. Azure DNS overview: Use the Amazon DNS Server (i.e. Amazon Route 53 Resolver server which is usually assigned to you through DHCP or preconfigured in the service) or a centralized trusted DNS resolver server in your workload recursive DNS setup, such as in the VM's operating system or in the application. Amazon Route 53 DNSSEC configuration: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture 9.2 - Use DNS Filtering Services SC-21: SECURE NAME / ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER) - Use trusted authoritative and recursive DNS services across your cloud environment to ensure the client (such as operating systems and applications) receive the correct resolution result. https://docs.microsoft.com/azure/dns/dns-overview https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html - Separate the public and private DNS resolution so the DNS resolution process for the private network can be isolated from the public network. Use Azure Private DNS for a private DNS zone setup where the DNS resolution process does not leave the designated virtual network. Use a custom DNS to restrict the DNS resolution to only allow trusted resolution to your client. Use Amazon Route 53 to create a private hosted zone setup where the DNS resolution process does not leave the designated VPCs. Use Amazon Route 53 firewall to regulate and filter the outbound DNS/UDP traffic in your VPC for the following use cases: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management - Ensure your DNS security strategy also includes mitigations against common attacks, such as dangling DNS, DNS amplifications attacks, DNS poisoning and spoofing, and so on. Secure Domain Name System (DNS) Deployment Guide: - Prevent attacks such as DNS exfiltration in your VPC Amazon Route 53 firewall: Use Microsoft Defender for DNS for the advanced protection against the following security threats to your workload or your DNS service: https://csrc.nist.gov/publications/detail/sp/800-81/2/final - Set up allow or deny lists for the domains that your applications can query https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver-dns-firewall.html Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops - Data exfiltration from your Azure resources using DNS tunneling - Malware communicating with a command-and-control server Azure Private DNS: Configure Domain Name System Security Extensions (DNSSEC) feature in Amazon Route 53 to secure DNS traffic to protect your domain from DNS spoofing or a man-in-the-middle attack. Amazon Route 53 domain registration: - Communication with malicious domains such as as phishing and crypto mining https://docs.microsoft.com/azure/dns/private-dns-overview https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html - DNS attacks in communication with malicious DNS resolvers Amazon Route 53 also provides a DNS registration service where Route 53 can be used as the authoritative name servers for your domains. The following best practices should be followed to ensure the security of your domain names: Azure Defender for DNS: - Domain names should be automatically renewed by the Amazon Route 53 service. You can also use Microsoft Defender for App Service to detect dangling DNS records if you decommission an App Service website without removing its custom domain from your DNS registrar. https://docs.microsoft.com/azure/security-center/defender-for-dns-introduction - Domain names should have the Transfer Lock feature enabled in order to keep them secure. - he Sender Policy Framework (SPF) is should be used to stop spammers from spoofing your domain. Prevent dangling DNS entries and avoid subdomain takeover: https://docs.microsoft.com/azure/security/fundamentals/subdomain-takeover"},{"location":"Azure/Security/MCSB/Posture%20and%20Vulnerability%20Mgmt/","title":"MCSB_v1 - Posture and Vulnerability Mgmt","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 Customer Security Stakeholders: PV-1 Posture and Vulnerability Management 5.1 - Establish Secure Configurations 4.1 - Establish and Maintain a Secure Configuration Process CM-2: BASELINE CONFIGURATION 1.1 Define and establish secure configurations Define the security configuration baselines for different resource types in the cloud. Alternatively, use configuration management tools to establish the configuration baseline automatically before or during resource deployment so the environment can be compliant by default after the deployment. Use the Microsoft Cloud Security Benchmark and service baseline to define your configuration baseline for each respective Azure offering or service. Refer to the Azure reference architecture and Cloud Adoption Framework landing zone architecture to understand the critical security controls and configurations that may be needed across Azure resources. Illustration of Guardrails implementation in Enterprise Scale Landing Zone: Use the Microsoft Cloud Security Benchmark - multi-cloud guidance for AWS and other input to define your configuration baseline for each respective AWS offering or service. Refer to the security pillar and other pillars in the AWS Well-Architectured Framework to understand the critical security controls and configurations that may be needed across AWS resources. AWS Control Tower: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 11.1 - Maintain Standard Security Configurations for Network Devices 4.2 - Establish and Maintain a Secure Configuration Process for Network Infrastructure CM-6: CONFIGURATION SETTINGS 2.2 https://docs.microsoft.com/azure/cloud-adoption-framework/ready/enterprise-scale/architecture#landing-zone-expanded-definition https://docs.aws.amazon.com/controltower/latest/userguide/what-is-control-tower.html Use Azure landing zone (and Blueprints) to accelerate the workload deployment by setting up configuration of services and application environments, including Azure Resource Manager templates, Azure RBAC controls, and Azure Policy. Use AWS CloudFormation templates and AWS Config rules in the AWS landing zone definition to automate deployment and configuration of services and application environments. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Working with security policies in Microsoft Defender for Cloud: AWS Config rules: https://docs.microsoft.com/azure/security-center/tutorial-security-policy https://aws.amazon.com/config/ Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Tutorial: Create and manage policies to enforce compliance: AWS landing zone https://docs.microsoft.com/azure/governance/policy/tutorials/create-and-manage Azure Blueprints: https://docs.microsoft.com/azure/governance/blueprints/overview PV-2 Posture and Vulnerability Management 5.4 - Deploy System Configuration Management Tools 4.1 - Establish and Maintain a Secure Configuration Process CM-2: BASELINE CONFIGURATION 2.2 Audit and enforce secure configurations Continuously monitor and alert when there is a deviation from the defined configuration baseline. Enforce the desired configuration according to the baseline configuration by denying the non-compliant configuration or deploying a configuration. Use Microsoft Defender for Cloud to configure Azure Policy to audit and enforce configurations of your Azure resources. Use Azure Monitor to create alerts when there is a configuration deviation detected on the resources. Understand Azure Policy effects: Use AWS Config rules to audit configurations of your AWS resources. And you can choose to resolve the configuration drift using AWS Systems Manager Automation associated with the AWS Config rule. Use Amazon CloudWatch to create alerts when there is a configuration deviation detected on the resources. Remediating Noncompliant AWS Resources by AWS Config Rules: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 5.5 - Implement Automated Configuration Monitoring Systems 4.2 - Establish and Maintain a Secure Configuration Process for Network Infrastructure CM-6: CONFIGURATION SETTINGS https://docs.microsoft.com/azure/governance/policy/concepts/effects https://docs.aws.amazon.com/config/latest/developerguide/remediation.html 11.3 - Use Automated Tools to Verify Standard Device Configurations and Detect Changes Use Azure Policy [deny] and [deploy if not exist] rules to enforce secure configuration across Azure resources. For resource configuration audit and enforcement not supported by AWS Config, you may need to write custom scripts or use third-party tooling to implement the configuration audit and enforcement. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Create and manage policies to enforce compliance: Detecting unmanaged configuration changes to stacks and resources: For resource configuration audit and enforcement not supported by Azure Policy, you may need to write custom  scripts or use third-party tooling to implement the configuration audit and enforcement. https://docs.microsoft.com/azure/governance/policy/tutorials/create-and-manage You can also centrally monitor your configuration drifting by onboarding your AWS account to Microsoft Defender for Cloud. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-drift.html Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Get compliance data of Azure resources: AWS Config Comformance Pack: https://docs.microsoft.com/azure/governance/policy/how-to/get-compliance-data https://aws.amazon.com/about-aws/whats-new/2019/11/introducing-aws-config-conformance-packs/ PV-3 Posture and Vulnerability Management 5.1 - Establish Secure Configurations 4.1 - Establish and Maintain a Secure Configuration Process CM-2: BASELINE CONFIGURATION 2.2 Define and establish secure configurations for compute resources Define the secure configuration baselines for your compute resources, such as VMs and containers. Use configuration management tools to establish the configuration baseline automatically before or during the compute resource deployment so the environment can be compliant by default after the deployment. Alternatively, use a pre-configured image to build the desired configuration baseline into the compute resource image template. Use Azure recommended operating system security baselines (for both Windows and Linux) as a benchmark to define your compute resource configuration baseline. Linux OS security configuration baseline: Use EC2 AWS Machine Images (AMI) from trusted sources on marketplace as a benchmark to define your EC2 configuration baseline. Enable Azure Automation State Configuration: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 5.5 - Implement Automated Configuration Monitoring Systems CM-6: CONFIGURATION SETTINGS 11.5 https://docs.microsoft.com/azure/governance/policy/samples/guest-configuration-baseline-linux https://docs.microsoft.com/en-us/azure/automation/automation-dsc-onboarding#enable-physicalvirtual-windows-machines Additionally, you can use a custom VM image (using Azure Image Builder) or container image with Azure Automanage Machine Configuration (formerly called Azure Policy Guest Configuration) and Azure Automation State Configuration to establish the desired security configuration. Additionally, you can use EC2 Image Builder to build custom AMI template with a Systems Manager agent to establish the desired security configuration. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint Windows OS security configuration baseline: Note: The AWS Systems Manager Agent is preinstalled on some Amazon Machine Images (AMIs) provided by AWS. https://docs.microsoft.com/azure/governance/policy/samples/guest-configuration-baseline-windows Enable Azure Automation State Configuration: Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops For workload applications running within your EC2 instances, AWS Lambda or containers environment, you may use AWS System Manager AppConfig to establish the desired configuration baseline. https://docs.microsoft.com/en-us/azure/automation/automation-dsc-onboarding#enable-physicalvirtual-windows-machines Security configuration recommendation for compute resources: https://docs.microsoft.com/azure/security-center/recommendations-reference Azure Automation State Configuration Overview: https://docs.microsoft.com/azure/automation/automation-dsc-overview PV-4 Posture and Vulnerability Management 5.4 - Deploy System Configuration Management Tools 4.1 - Establish and Maintain a Secure Configuration Process CM-2: BASELINE CONFIGURATION 2.2 Audit and enforce secure configurations for compute resources Continuously monitor and alert when there is a deviation from the defined configuration baseline in your compute resources. Enforce the desired configuration according to the baseline configuration by denying the non-compliant configuration or deploying a configuration in compute resources. Use Microsoft Defender for Cloud and Azure Automanage Machine Configuration (formerly called Azure Policy Guest Configuration) to regularly assess and remediate configuration deviations on your Azure compute resources, including VMs, containers, and others. In addition, you can use Azure Resource Manager templates, custom operating system images, or Azure Automation State Configuration to maintain the security configuration of the operating system.  Microsoft VM templates in conjunction with Azure Automation State Configuration can assist in meeting and maintaining security requirements. Use Change Tracking and Inventory in Azure Automation to track changes in virtual machines hosted in Azure, on-premises, and other cloud environments to help you pinpoint operational and environmental issues with software managed by the Distribution Package Manager. Install the Guest Attestation agent on virtual machines to monitor for boot integrity on confidential virtual machines. How to implement Microsoft Defender for Cloud vulnerability assessment recommendations: Use AWS System Manager's State Manager feature to regularly assess and remediate configuration deviations on your EC2 instances. In addition, you can use CloudFormation templates, custom operating system images to maintain the security configuration of the operating system. AMI templates in conjunction with Systems Manager can assist in meeting and maintaining security requirements. AWS System Manager State Manager: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 5.5 - Implement Automated Configuration Monitoring Systems CM-6: CONFIGURATION SETTINGS https://docs.microsoft.com/azure/security-center/security-center-vulnerability-assessment-recommendations https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-state.html 11.3 - Use Automated Tools to Verify Standard Device Configurations and Detect Changes Note: Azure Marketplace VM images published by Microsoft are managed and maintained by Microsoft. You can also centrally monitor and manage the operating system configuration drift through Azure Automation State Configuration and onboard the applicable resources to Azure security governance using the following methods : Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint How to create an Azure virtual machine from an ARM template: - Onboard your AWS account into Microsoft Defender for Cloud Connect your AWS accounts to Microsoft Defender for Cloud: https://docs.microsoft.com/azure/virtual-machines/windows/ps-template - Use Azure Arc for servers to connect your EC2 instances to Microsoft Defender for Cloud https://docs.microsoft.com/en-us/azure/defender-for-cloud/quickstart-onboard-aws?pivots=env-settings Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Azure Automation State Configuration overview: For workload applications running within your EC2 instances, AWS Lambda or containers environment, you may use AWS System Manager AppConfig to audit and enforce the desired configuration baseline. Enable Azure Automation State Configuration: https://docs.microsoft.com/azure/automation/automation-dsc-overview https://docs.microsoft.com/en-us/azure/automation/automation-dsc-onboarding#enable-physicalvirtual-windows-machines Note: AMIs published by Amazon Web Services in AWS Marketplace are managed and maintained by Amazon Web Services. Create a Windows virtual machine in the Azure portal: https://docs.microsoft.com/azure/virtual-machines/windows/quick-create-portal Container security in Microsoft Defender for Cloud: https://docs.microsoft.com/azure/security-center/container-security Change Tracking and Inventory overview: https://learn.microsoft.com/azure/automation/change-tracking/overview?tabs=python-2 Guest attestation for confidential VMs: https://learn.microsoft.com/azure/confidential-computing/guest-attestation-confidential-vms PV-5 Posture and Vulnerability Management 3.1 - Run Automated Vulnerability Scanning Tools 5.5 - Establish and Maintain an Inventory of Service Accounts RA-3: RISK ASSESSMENT 6.1 Perform vulnerability assessments Perform vulnerabilities assessment for your cloud resources at all tiers in a fixed schedule or on-demand. Track and compare the scan results to verify the vulnerabilities are remediated. The assessment should include all type of vulnerabilities, such as vulnerabilities in Azure services, network, web, operating systems, misconfigurations, and so on. Follow recommendations from Microsoft Defender for Cloud for performing vulnerability assessments on your Azure virtual machines, container images, and SQL servers. Microsoft Defender for Cloud has a built-in vulnerability scanner for virtual machines. Use a third-party solution for performing vulnerability assessments on network devices and applications (e.g., web applications) How to implement Microsoft Defender for Cloud vulnerability assessment recommendations: https://docs.microsoft.com/azure/security-center/security-center-vulnerability-assessment-recommendations Use Amazon Inspector to scan your Amazon EC2 instances and container images residing in Amazon Elastic Container Registry (Amazon ECR) for software vulnerabilities and unintended network exposure. Use a third-party solution for performing vulnerability assessments on network devices and applications (e.g., web applications) Amazon Inspector: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 3.3 - Protect Dedicated Assessment Accounts 7.1 - Establish and Maintain a Vulnerability Management Process RA-5: VULNERABILITY SCANNING 6.2 https://docs.aws.amazon.com/inspector/latest/user/what-is-inspector.html 3.6 - Compare Back-to-back Vulnerability Scans 7.5 - Perform Automated Vulnerability Scans of Internal Enterprise Assets 6.6 Be aware of the potential risks associated with the privileged access used by the vulnerability scanners. Follow the privileged access security best practice to secure any administrative accounts used for the scanning. Export scan results at consistent intervals and compare the results with previous scans to verify that vulnerabilities have been remediated. When using vulnerability management recommendations suggested by Microsoft Defender for Cloud, you can pivot into the selected scan solution's portal to view historical scan data. Integrated vulnerability scanner for virtual machines: Refer to control ES-1, \"Use Endpoint Detection and Response (EDR)\", to onboard your AWS account into Microsoft Defender for Cloud and deploy Microsoft Defender for servers (with Microsoft Defender for Endpoint integrated) in your EC2 instances. Microsoft Defender for servers provides a native threat and vulnerability management capability for your VMs. The vulnerability scanning result will be consolidated in the Microsoft Defender for Cloud dashboard. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 7.6 - Perform Automated Vulnerability Scans of Externally-Exposed Enterprise Assets 11.2 https://docs.microsoft.com/azure/security-center/built-in-vulnerability-assessment Investigate weaknesses with Microsoft Defender for Endpoint's threat and vulnerability management: When conducting remote scans, do not use a single, perpetual, administrative account. Consider implementing JIT (Just In Time) provisioning methodology for the scan account. Credentials for the scan account should be protected, monitored, and used only for vulnerability scanning. Track the status of vulnerability findings to ensure they are properly remediated or suppressed if they're considered false positive. https://docs.microsoft.com/en-us/azure/defender-for-cloud/deploy-vulnerability-assessment-tvm Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops SQL vulnerability assessment: Note: Microsoft Defender services (including Defender for servers, containers, App Service, Database, and DNS) embed certain vulnerability assessment capabilities. The alerts generated from Azure Defender services should be monitored and reviewed together with the result from Microsoft Defender for Cloud vulnerability scanning tool. https://docs.microsoft.com/azure/azure-sql/database/sql-vulnerability-assessment When conducting remote scans, do not use a single, perpetual, administrative account. Consider implementing a temporary provisioning methodology for the scan account. Credentials for the scan account should be protected, monitored, and used only for vulnerability scanning. Note: Ensure you setup email notifications in Microsoft Defender for Cloud. Exporting Microsoft Defender for Cloud vulnerability scan results: https://docs.microsoft.com/azure/security-center/built-in-vulnerability-assessment#exporting-results PV-6 Posture and Vulnerability Management 3.4 - Deploy Automated Operating System Patch Management Tools 7.2 - Establish and Maintain a Remediation Process RA-3: RISK ASSESSMENT 6.1 Rapidly and automatically remediate vulnerabilities Rapidly and automatically deploy patches and updates to remediate vulnerabilities in your cloud resources. Use the appropriate risk-based approach to prioritize the remediation of vulnerabilities. For example, more severe vulnerabilities in a higher value asset should be addressed as a higher priority. Use Azure Automation Update Management or a third-party solution to ensure that the most recent security updates are installed on your Windows and Linux VMs. For Windows VMs, ensure Windows Update has been enabled and set to update automatically. How to configure Update Management for virtual machines in Azure: Use AWS Systems Manager - Patch Manager to ensure that the most recent security updates are installed on your operating systems and applications. Patch Manager supports patch baselines to allow you to define a list of approved and rejected patches for your systems. AWS Systems Manager - Patch Manager: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 3.5 - Deploy Automated Software Patch Management Tools 7.3 - Perform Automated Operating System Patch Management RA-5: VULNERABILITY SCANNING 6.2 https://docs.microsoft.com/azure/automation/update-management/overview https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-patch.html 3.7 - Utilize a Risk-rating Process 7.4 - Perform Automated Application Patch Management SI-2: FLAW REMEDIATION 6.5 Prioritize which updates to deploy first using a common risk scoring program (such as Common Vulnerability Scoring System) or the default risk ratings provided by your third-party scanning tool and tailor to your environment. You should also consider which applications present a high security risk and which ones require high uptime. For third-party software, use a third-party patch management solution or Microsoft System Center Updates Publisher for Configuration Manager. You can also use Azure Automation Update Management to centrally manage the patches and updates of your AWS EC2 Windows and Linux instances. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 7.7 - Remediate Detected Vulnerabilities 11.2 Manage updates and patches for your Azure VMs: Update Management overview: https://docs.microsoft.com/azure/automation/update-management/manage-updates-for-vm For third-party software, use a third-party patch management solution or Microsoft System Center Updates Publisher for Configuration Manager. https://docs.microsoft.com/en-us/azure/automation/update-management/overview Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops PV-7 Posture and Vulnerability Management 20.1 - Establish a Penetration Testing Program 18.1 - Establish and Maintain a Penetration Testing Program CA-8: PENETRATION TESTING 6.6 Conduct regular red team operations Simulate real-world attacks to provide a more complete view of your organization's vulnerability. Red team operations and penetration testing complement the traditional vulnerability scanning approach to discover risks. As required, conduct penetration testing or red team activities on your Azure resources and ensure remediation of all critical security findings. Penetration testing in Azure: As required, conduct penetration testing or red team activities on your AWS resources and ensure remediation of all critical security findings. AWS Customer Support Policy for Penetration Testing: Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management 20.2 - Conduct Regular External and Internal Penetration Tests 18.2 - Perform Periodic External Penetration Tests RA-5: VULNERABILITY SCANNING 11.2 https://docs.microsoft.com/azure/security/fundamentals/pen-testing https://aws.amazon.com/security/penetration-testing/ 20.3 - Perform Periodic Red Team Exercises 18.3 - Remediate Penetration Test Findings 11.3 Follow industry best practices to design, prepare and conduct this kind of testing to ensure it will not cause damage or disruption to your environment. This should always include discussing testing scope and constraints with relevant stakeholders and resource owners. Follow the Microsoft Cloud Penetration Testing Rules of Engagement to ensure your penetration tests are not in violation of Microsoft policies. Use Microsoft's strategy and execution of Red Teaming and live site penetration testing against Microsoft-managed cloud infrastructure, services, and applications. Follow the AWS Customer Support Policy for Penetration Testing to ensure your penetration tests are not in violation of AWS policies. Infrastructure and endpoint security: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-infrastructure-endpoint 18.4 - Validate Security Measures Penetration Testing Rules of Engagement: 18.5 - Perform Periodic Internal Penetration Tests https://www.microsoft.com/msrc/pentest-rules-of-engagement?rtc=1 Application Security and DevOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Microsoft Cloud Red Teaming: https://download.microsoft.com/download/C/1/9/C1990DBA-502F-4C2A-848D-392B93D9B9C3/Microsoft_Enterprise_Cloud_Red_Teaming.pdf Technical Guide to Information Security Testing and Assessment: https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-115.pdf"},{"location":"Azure/Security/MCSB/Privileged%20Access/","title":"MCSB_v1 - Privileged Access","text":"ID Control Domain CIS Controls v7.1 ID(s) CIS Controls v8 ID(s) NIST SP800-53 r4 ID(s) PCI-DSS v3.2.1 ID(s) Recommendation Security Principle Azure Guidance Implementation and additional context AWS Guidance Implementation and additional context.1 Customer Security Stakeholders: PA-1 Privileged Access 4.3 - Ensure the Use of Dedicated Administrative Accounts 5.4 - Restrict Administrator Privileges to Dedicated Administrator Accounts AC-2: ACCOUNT MANAGEMENT 7.1 Separate and limit highly privileged/administrative users Ensure you identify all high business impact accounts. Limit the number of privileged/administrative accounts in your cloud's control plane, management plane and data/workload plane. You must secure all roles with direct or indirect administrative access to Azure hosted resources. Administrator role permissions in Azure AD: You must secure all roles with direct or indirect administrative access to AWS hosted resources. AWS Best Practices for Root User: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys 14.6 - Protect Information Through Access Control Lists 6.8 - Define and Maintain Role-Based Access Control AC-6: LEAST PRIVILEGE 7.2 https://docs.microsoft.com/azure/active-directory/users-groups-roles/directory-assign-admin-roles https://docs.aws.amazon.com/accounts/latest/reference/best-practices-root-user.html 8.1 Azure Active Directory (Azure AD) is Azure's default identity and access management service. The most critical built-in roles in Azure AD are Global Administrator and Privileged Role Administrator, because users assigned to these two roles can delegate administrator roles. With these privileges, users can directly or indirectly read and modify every resource in your Azure environment: The privileged/administrative users need to be secured include: Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture - Global Administrator / Company Administrator: Users with this role have access to all administrative features in Azure AD as well as services that use Azure AD identities. Use Azure Privileged Identity Management security alerts: - Root user: Root user is the highest-level privileged accounts in your AWS account. Root accounts should be highly restricted and only used in emergency situation. Refer to emergency access controls in PA-5 (Setup emergency access). - Privileged Role Administrator: Users with this role can manage role assignments in Azure AD, as well as within Azure AD Privileged Identity Management (PIM). In addition, this role allows management of all aspects of PIM and administrative units. https://docs.microsoft.com/azure/active-directory/privileged-identity-management/pim-how-to-configure-security-alerts - IAM identities (users, groups, roles) with the privileged permission policy: IAM identities assigned with a permission policy such as AdministratorAccess can have full access to AWS services and resources. Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Outside of Azure AD, Azure has built-in roles that can be critical for privileged access at the resource level. Securing privileged access for hybrid and cloud deployments in Azure AD: If you are using Azure Active Directory (Azure AD) as the identity provider for AWS, refer to the Azure guidance for managing the privileged roles in Azure AD. Security Operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center - Owner: Grants full access to manage all resources, including the ability to assign roles in Azure RBAC. https://docs.microsoft.com/azure/active-directory/users-groups-roles/directory-admin-roles-secure - Contributor: Grants full access to manage all resources, but does not allow you to assign roles in Azure RBAC, manage assignments in Azure Blueprints, or share image galleries. Ensure that you also restrict privileged accounts in other management, identity, and security systems that have administrative access to your business-critical assets, such as AWS Cognito, security tools, and system management tools with agents installed on business critical systems. Attackers who compromise these management and security systems can immediately weaponize them to compromise business critical assets. - User Access Administrator: Lets you manage user access to Azure resources. Note: You may have other critical roles that need to be governed if you use custom roles in the Azure AD level or resource level with certain privileged permissions assigned. In addition, users with the following three roles in Azure Enterprise Agreement (EA) portal should also be restricted as they can be used to directly or indirectly manage Azure subscriptions. - Account Owner: Users with this role can manage subscriptions, including the creation and deletion of subscriptions. - Enterprise Administrator: Users assigned with this role can manage (EA) portal users. - Department Administrator: Users assigned with this role can change account owners within the department. Lastly, ensure that you also restrict privileged accounts in other management, identity, and security systems that have administrative access to your business-critical assets, such as Active Directory Domain Controllers (DCs), security tools, and system management tools with agents installed on business-critical systems. Attackers who compromise these management and security systems can immediately weaponize them to compromise business critical assets. PA-2 Privileged Access nan nan AC-2: ACCOUNT MANAGEMENT N/A Avoid standing access for user accounts and permissions Instead of creating standing privileges, use just-in-time (JIT) mechanism to assign privileged access to the different resource tiers. Enable just-in-time (JIT) privileged access to Azure resources and Azure AD using Azure AD Privileged Identity Management (PIM). JIT is a model in which users receive temporary permissions to perform privileged tasks, which prevents malicious or unauthorized users from gaining access after the permissions have expired. Access is granted only when users need it. PIM can also generate security alerts when there is suspicious or unsafe activity in your Azure AD organization. Azure PIM just-in-time access deployment: Use AWS Security Token Service (AWS STS) to create temporary security credentials to access the resources through the AWS API. Temporary security credentials work almost identically to the long-term access key credentials that your IAM users can use, with the following differences: IAM Temporary credentials through AWS Security Token Service (AWS STS): Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys https://docs.microsoft.com/azure/active-directory/privileged-identity-management/pim-deployment-plan - Temporary security credentials have a short-term life, from minutes to hours. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html Restrict inbound traffic to your sensitive virtual machines (VM) management ports with Microsoft Defender for Cloud's just-in-time (JIT) for VM access feature. This ensures privileged access to the VM is granted only when users need it. - Temporary security credentials are not stored with the user but are generated dynamically and provided to the user when requested. Security architecture: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-architecture Understanding just-in-time (JIT) VM access: https://learn.microsoft.com/azure/defender-for-cloud/just-in-time-access-overview?tabs=defender-for-container-arch-aks Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Security Operations: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-operations-center PA-3 Privileged Access 16.7 - Establish Process for Revoking Access 6.1 - Establish an Access Granting Process AC-2: ACCOUNT MANAGEMENT 7.1 Manage lifecycle of identities and entitlements Use an automated process or technical control to manage the identity and access lifecycle including the request, review, approval, provision, and deprovision. Use Azure AD entitlement management features to automate access request workflows (for Azure resource groups). This enables workflows for Azure resource groups to manage access assignments, reviews, expiration, and dual or multi-stage approval. What are Azure AD access reviews: Use AWS Access Advisor to pull the access logs for the user accounts and entitlements for resources.  Build a manual or automated workflow to integrate with AWS IAM to manage access assignments, reviews, and deletions. IAM Access Advisor: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys 6.2 - Establish an Access Revoking Process AC-5: SEPARATION OF DUTIES 7.2 https://docs.microsoft.com/azure/active-directory/governance/access-reviews-overview https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor-view-data.html AC-6: LEAST PRIVILEGE 8.1 Use Permissions Management to detect, automatically right-size, and continuously monitor unused and excessive permissions assigned to user and workload identities across multi-cloud infrastructures. Note: There are third-party solutions available on AWS Marketplace for managing the lifecycle of identities and entitlements. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops What is Azure AD entitlement management: AWS Marketplace Identity and Access Management solutions: https://docs.microsoft.com/azure/active-directory/governance/entitlement-management-overview https://aws.amazon.com/marketplace/solutions/security/identity-access-management Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Overview of Permissions Management: https://learn.microsoft.com/azure/active-directory/cloud-infrastructure-entitlement-management/overview PA-4 Privileged Access 4.1 - Maintain Inventory of Administrative Accounts 5.1 - Establish and Maintain an Inventory of Accounts AC-2: ACCOUNT MANAGEMENT 7.1 Review and reconcile user access regularly Conduct regular review of privileged account entitlements. Ensure the access granted to the accounts are valid for administration of control plane, management plane, and workloads. Review all privileged accounts and the access entitlements in Azure including Azure tenants, Azure services, VM/IaaS, CI/CD processes, and enterprise management and security tools. Create an access review of Azure resource roles in Privileged Identity Management (PIM): Review all privileged accounts and the access entitlements in AWS including AWS accounts, services, VM/IaaS, CI/CD processes, and enterprise management and security tools. IAM Access Analyzer: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys 16.6 - Maintain an Inventory of Accounts 5.3 - Disable Dormant Accounts AC-6: LEAST PRIVILEGE 7.2 https://docs.microsoft.com/azure/active-directory/privileged-identity-management/pim-resource-roles-start-access-review https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html 16.8 - Disable Any Unassociated Accounts 5.5 - Establish and Maintain an Inventory of Service Accounts 8.1 Use Azure AD access reviews to review Azure AD roles, Azure resource access roles, group memberships, and access to enterprise applications. Azure AD reporting can also provide logs to help discover stale accounts, or accounts which have not been used for certain amount of time. Use IAM Access Advisor, Access Analyzer and Credential Reports to review resource access roles, group memberships, and access to enterprise applications. IAM Access Analyzer and Credential Reports reporting can also provide logs to help discover stale accounts, or accounts which have not been used for certain amount of time. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops Disable Dormant Accounts A3.4 How to use Azure AD identity and access reviews: Credential report: 16.9 - Disable Dormant Accounts In addition, Azure AD Privileged Identity Management can be configured to alert when an excessive number of administrator accounts are created for a specific role, and to identify administrator accounts that are stale or improperly configured. https://docs.microsoft.com/azure/active-directory/governance/access-reviews-overview If you are using Azure Active Directory (Azure AD) as the identity provider for AWS, use Azure AD access review to review the privileged accounts and access entitlements periodically. https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management IAM Access Advisor: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor-view-data.html PA-5 Privileged Access nan nan AC-2: ACCOUNT MANAGEMENT nan Set up emergency access Set up emergency access to ensure that you are not accidentally locked out of your critical cloud infrastructure (such as your identity and access management system) in an emergency. To prevent being accidentally locked out of your Azure AD organization, set up an emergency access account (e.g., an account with Global Administrator role) for access when normal administrative accounts cannot be used. Emergency access accounts are usually highly privileged, and they should not be assigned to specific individuals. Emergency access accounts are limited to emergency or \"break glass\"' scenarios where normal administrative accounts can't be used. Manage emergency access accounts in Azure AD: AWS \"root\" accounts should not be used for regular administrative tasks. As the \"root\" account is highly privileged, it should not be assigned to specific individuals. It's use should be limited to only emergency or \"break glass\u201d scenarios when normal administrative accounts can't be used. For daily administrative tasks, separate privileged user accounts should be used and assigned the appropriate permissions via IAM roles. Best practices to protect your account's root user: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys https://docs.microsoft.com/azure/active-directory/users-groups-roles/directory-emergency-access https://docs.aws.amazon.com/accounts/latest/reference/best-practices-root-user.html Emergency access accounts should be rarely used and can be highly damaging to the organization if compromised, but their availability to the organization is also critically important for the few scenarios when they are required. You should ensure that the credentials (such as password, certificate, or smart card) for emergency access accounts are kept secure and known only to individuals who are authorized to use them only in an emergency. You may also use additional controls, such dual controls (e.g., splitting the credential into two pieces and giving it to separate persons) to enhance the security of this process. You should also monitor the sign-in and audit logs to ensure that emergency access accounts are only used when authorized. You should also ensure that the credentials (such as password, MFA tokens and access keys) for root accounts are kept secure and known only to individuals who are authorized to use them only in an emergency. MFA should be enabled for the root account, and you may also use additional controls, such as dual controls (e.g., splitting the credential into two pieces and giving it to separate persons) to enhance the security of this process. Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops You should also monitor the sign-in and audit logs in CloudTrail or EventBridge to ensure that root access accounts are only used when authorized. Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Security Operations (SecOps): https://docs.microsoft.com//azure/cloud-adoption-framework/organize/cloud-security-operations-center PA-6 Privileged Access 4.6 - Use Dedicated Workstations For All Administrative Tasks 12.8 - Establish and Maintain Dedicated Computing Resources for All Administrative Work AC-2: ACCOUNT MANAGEMENT nan Use privileged access workstations / channel for administrative tasks Secured, isolated workstations are critically important for the security of sensitive roles like administrator, developer, and critical service operator. Use Azure Active Directory, Microsoft Defender, and/or Microsoft Intune to deploy privileged access workstations (PAW) on-premises or in Azure for privileged tasks. The PAW should be centrally managed to enforce secured configuration, including strong authentication, software and hardware baselines, and restricted logical and network access. Understand privileged access workstations: Use Session Manager in AWS Systems Manager to create an access path (a connection session) to the EC2 instance or a browser session to the AWS resources for privileged tasks. Session Manager allows RDP, SSH, and HTTPS connectivity to your destination hosts through port forwarding. AWS Systems Manager Session Manager: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 11.6 - Use Dedicated Machines For All Network Administrative Tasks 13.5 Manage Access Control for Remote Assets SC-2 APPLICATION PARTITIONING https://learn.microsoft.com/en-us/security/privileged-access-workstations/overview https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager.html 12.12 - Manage All Devices Remotely Logging into Internal Network SC-7: BOUNDARY PROTECTION You may also use Azure Bastion which is a fully platform-managed PaaS service that can be provisioned inside your virtual network. Azure Bastion allows RDP/SSH connectivity to your virtual machines directly from the Azure portal using a web browser. You may also choose to deploy a privileged access workstations (PAW) centrally managed through Azure Active Directory, Microsoft Defender, and/or Microsoft Intune. The central management should enforce secured configuration, including strong authentication, software and hardware baselines, and restricted logical and network access. Security Operations (SecOps): https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/organize/cloud-security-operations-center Privileged access workstations deployment: https://docs.microsoft.com/security/compass/privileged-access-deploymenthttps Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys PA-7 Privileged Access 14.6 - Protect Information Through Access Control Lists 3.3 - Configure Data Access Control Lists AC-2: ACCOUNT MANAGEMENT 7.1 Follow just enough administration (least privilege) principle Follow the just enough administration (least privilege) principle to manage permissions at fine-grained level. Use features such as role-based access control (RBAC) to manage resource access through role assignments. Use Azure role-based access control (Azure RBAC) to manage Azure resource access through role assignments. Through RBAC, you can assign roles to users, groups, service principals, and managed identities. There are pre-defined built-in roles for certain resources, and these roles can be inventoried or queried through tools such as Azure CLI, Azure PowerShell, and the Azure portal. What is Azure role-based access control (Azure RBAC): Use AWS policy to manage AWS resource access. There are six types of policies: identity-based policies, resource-based policies, permissions boundaries, AWS Organizations service control policy (SCP), Access Control List, and session policies. You may use AWS managed policies for common permission use cases. However, you should be mindful that managed policies may carry excessive permissions that should not be assigned to the users. IAM access policies: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 6.8 - Define and Maintain Role-Based Access Control AC-3: ACCESS ENFORCEMENT 7.2 https://docs.microsoft.com/azure/role-based-access-control/overview https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html AC-6: LEAST PRIVILEGE The privileges you assign to resources through Azure RBAC should always be limited to what's required by the roles. Limited privileges will complement the just-in-time (JIT) approach of Azure AD Privileged Identity Management (PIM), and those privileges should be reviewed periodically. If required, you can also use PIM to define a time-bound assignment, which is a condition in a role assignment where a user can only activate the role within the specified start and end dates. You may also use AWS ABAC (attribute-based access control) to assign permissions based on attributes (tags) attached to IAM resources, including IAM entities (users or roles) and AWS resources. Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management How to configure RBAC in Azure: AWS ABAC: Note: Use Azure built-in roles to allocate permissions and only create custom roles when required. https://docs.microsoft.com/azure/role-based-access-control/role-assignments-portal https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction_attribute-based-access-control.html Posture management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-posture-management How to use Azure AD identity and access reviews: Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys https://docs.microsoft.com/azure/active-directory/governance/access-reviews-overview Azure AD Privileged Identity Management - Time-bound assignment: https://docs.microsoft.com/azure/active-directory/privileged-identity-management/pim-configure#what-does-it-do PA-8 Privileged Access 16.7 - Establish Process for Revoking Access 6.1 - Establish an Access Granting Process AC-4: INFORMATION FLOW ENFORCEMENT nan Determine access process for cloud provider support Establish an approval process and access path for requesting and approving vendor support request and temporary access to your data through a secure channel. In support scenarios where Microsoft needs to access your data, use Customer Lockbox to review and either approve or reject each data access request made by Microsoft. Understand Customer Lockbox: In support scenarios where AWS support teams need to access your data, create an account in the AWS Support portal to request support. Review the available options such as providing read-only data access, or the screen sharing option for AWS support to access to your data. Access permissions for AWS Support: Application security and DevSecOps: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-application-security-devsecops 6.2 - Establish an Access Revoking Process AC-2: ACCOUNT MANAGEMENT https://docs.microsoft.com/azure/security/fundamentals/customer-lockbox-overview https://docs.aws.amazon.com/awssupport/latest/user/accessing-support.html AC-3: ACCESS ENFORCEMENT Security Compliance Management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-compliance-management Identity and key management: https://docs.microsoft.com/azure/cloud-adoption-framework/organize/cloud-security-identity-keys"},{"location":"Azure/Security/MCSB/Readme/","title":"MCSB_v1 - Readme","text":"Unnamed: 0 Unnamed: 1 Unnamed: 2 nan Microsoft Cloud Security Benchmark v1 nan nan This spreadsheet is designed to provide you a private preview version of the Microsoft Cloud Security Benchmark v1. For the web version of the content, please refer to ttps://docs.microsoft.com/en-us/security/benchmark/azure/overview nan a. The control mappings between MCSB and industry benchmarks (such as NIST, CIS and PCI) only indicate that a specific Azure feature can be used to fully or partially address a control requirement defined in NIST, CIS or PCI. You should be aware that such implementation does not necessarily translate to the full compliance of the corresponding control in CIS, NIST or PCI. b. This document is developed as a reference and should not be used to define all means by which a customer can meet specific compliance requirements and regulations. Customers should seek legal support from their organization on approved customer implementations. nan nan nan nan This multi-cloud guidance follows the below principles: nan 1. The security guidance for non-Azure platforms will follow the same cloud-neutral security principles at each control level as Azure's. 2. The security guidance for non-Azure platforms will provide the same level of granularity and same scope in the technical guidance as Azure's. 3. The non-Microsoft cloud service provider\u2019s (CSP) native solution or feature will usually be recommended as the first preference for each control. However, when there is a more mature multi-cloud solution available in Azure, it'll be prioritized as the default recommendation. 4. If neither the CSP's native technology nor Azure solutions are available to satisfy a security principle, third-party solutions will be recommended from the Azure or the other CSP's Marketplace. However, Microsoft Cloud Security Benchmark will not name any specific third-party vendor product or solution. nan nan nan nan nan nan nan Guidance  - Column Header Descriptions nan ID# The Microsoft Cloud Security Benchmark ID. nan Control Domain The security control domain. nan Security Principle The technology-agnostic and cloud neutral principle for various security topics in each control domains. nan Recommendation The control recommendation in summarized format. nan Azure Guidance The technical guidance for Azure platforms. nan AWS Guidance The technical guidance for Amazon Web Services platforms. nan Implementation and additional context The implementation details and other relevant context which links to the Azure or AWS service offering documentation articles."},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2023/10/17/hello-world-from-mkdocs-material/","title":"\"Hello world!!!\" from mkdocs-material","text":"<p>...</p>"},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/","title":"Create a blog with MkDocs,mkdocs-material, mkdocs-rss-plugin and GitHub Pages","text":"<p>A few time ago I maintained a blog with Wordpress. I was happy with it, but I wanted to try something new. </p> <p>I tried Jekyll but it didn't convince me, I discovered mkdocs so I decided to use MkDocs and mkdocs-material. I was happy with the result, so I decided to write this post to explain how to create a blog with MkDocs, mkdocs-material and some plugins.</p> <p>These is the first post of a serie of posts to create a blog with MkDocs, mkdocs-material and GitHub Pages and some customization.</p> <p>Some knowledge:</p> <ul> <li> <p>MkDocs is a fast, simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file.</p> </li> <li> <p>Material for MkDocs is a theme for MkDocs, a static site generator geared towards (technical) project documentation. It is built using Google's Material Design guidelines. Material for MkDocs provides a polished and responsive experience out of the box, and it is as easy to use for the beginner as it is for the seasoned developer.</p> </li> <li> <p>GitHub Pages is a static site hosting service that takes HTML, CSS, and JavaScript files straight from a repository on GitHub, optionally runs the files through a build process, and publishes a website. You can see more information about GitHub Pages here.</p> </li> <li> <p>This plugin generates an RSS feed for your MkDocs site. You can see more information about mkdocs-rss-plugin here.</p> </li> </ul>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#steps-to-deploy","title":"Steps to deploy","text":"","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#create-a-new-repository","title":"Create a new repository","text":"<p>Create a new repository on GitHub named <code>username.github.io</code>, where <code>username</code> is your username (or organization name) on GitHub. If the first part of the repository doesn\u2019t exactly match your username, it won\u2019t work, so make sure to get it right.</p>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#enable-github-pages-on-your-repository","title":"Enable GitHub Pages on your repository","text":"<p>Go into the repository settings and, if you are not using GitHub Pages already, enable GitHub Pages on the <code>gh-pages</code> branch.</p>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#clone-the-repository","title":"Clone the repository","text":"<p>Go to the folder where you want to store your project, and clone the new repository:</p> <pre><code>git clone ssh://github.com/username/username.github.io\ncd username.github.io\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#create-requirementstxt-in-root-folder-for-mkdocs-mkdocs-material-and-plugins","title":"Create requirements.txt in root folder for mkdocs, mkdocs-material and plugins","text":"<pre><code>mkdocs==1.5.3\nmkdocs-material==9.4.6\nmkdocs-rss-plugin==1.8.0\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#create-a-python-virtual-environment-and-install-requirementstxt","title":"Create a Python Virtual Environment and install requirements.txt","text":"<p>In username.github.io$ path:</p> <pre><code>sudo apt update\nsudo apt install libcairo2\nsudo apt install python3.10-venv\npython3 -m venv mysite\nsource mysite/bin/activate\npip install -r requirements.txt\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#initialize-your-site","title":"Initialize your site","text":"<pre><code>mkdocs new .\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#add-configuration-to-mkdocsyml-in-root-folder","title":"Add configuration to mkdocs.yml in root folder","text":"<p>For this post I am going to add the following configuration:</p> <ul> <li>basic configuration</li> <li>configuration for theme mkdocs-material</li> <li>some native plugins of mkdocs-material and some ones that I like</li> </ul> <pre><code>site_name: My Site \nsite_description: A blog about Azure, DevOps and other stuff\nsite_author: Rafael Fern\u00e1ndez\n\ntheme: \n  name: material\n  features:\n    - navigation.tabs\n    - navigation.expand\n    - navigation.sections\n    - toc.integrate\n    - toc.nested\n    - toc.smoothscroll\n    - footer\n\nplugins:\n  - search  \n  - blog\n  - tags:\n      tags_file: tags.md      \n\n  - rss:\n      match_path: blog/posts/.* \n      date_from_meta:\n        as_creation: date\n      categories:\n        - categories\n        - tags\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#add-a-new-post","title":"Add a new post","text":"<p>In blog/post folder create a new folder with the name of the post and create a new file with the name of the post and the extension .md. For example: <code>welcome.md</code> </p> <pre><code>---\ndate: 2023-10-18\ncategories:\n  - Hello\n  - World\n---\n\n# \"Hello world!!!\" from mkdocs-material\n\n...\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#check-your-site","title":"Check your site","text":"<p>In username.github.io$ path:</p> <pre><code>mkdocs serve\n</code></pre> <p>You can check your site in http://127.0.0.1:8000/ and make live changes in your site and see the results in your browser.</p>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#publish-your-site","title":"Publish your site","text":"<p>In username.github.io$ path:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>After a seconds, you can check your site in https://username.github.io/ </p>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#automate-deploy-with-github-actions","title":"Automate deploy with GitHub Actions","text":"<pre><code>name: ci # (1)!\non:\n  push:\n    branches:      \n      - main\npermissions:\n  contents: write\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v4\n        with:\n          python-version: 3.x\n      - run: echo \"cache_id=$(date --utc '+%V')\" &gt;&gt; $GITHUB_ENV # (3)!\n      - uses: actions/cache@v3\n        with:\n          key: mkdocs-material-${{ env.cache_id }}\n          path: .cache\n          restore-keys: |\n            mkdocs-material-\n      - run: pip install -r requirements.txt # (4)!\n      - run: mkdocs gh-deploy --force\n</code></pre> <ol> <li> <p>You can change the name to your liking.</p> </li> <li> <p>At some point, GitHub renamed <code>master</code> to <code>main</code>. If your default branch     is named <code>master</code>, you can safely remove <code>main</code>, vice versa.</p> </li> <li> <p>Store the <code>cache_id</code> environmental variable to access it later during cache     <code>key</code> creation. The name is case-sensitive, so be sure to align it with <code>${{ env.cache_id }}</code>.</p> <ul> <li>The <code>--utc</code> option makes sure that each workflow runner uses the same time zone.</li> <li>The <code>%V</code> format assures a cache update once a week.</li> <li>You can change the format to <code>%F</code> to have daily cache updates.</li> </ul> <p>You can read the [manual page] to learn more about the formatting options of the <code>date</code> command.</p> </li> <li> <p>Add [MkDocs plugins] or Markdown     extensions with <code>pip</code> to requirements.txt to be used during the build.</p> </li> </ol> <p>In the next post I will explain how to customize your site with mkdocs-material and some plugins writing mkdocs.yml.</p> <p>That's it folks</p>","tags":["mkdocs"]},{"location":"blog/2023/10/18/create-a-blog-with-mkdocsmkdocs-material-mkdocs-rss-plugin-and-github-pages/#urls-for-reference","title":"urls for reference","text":"<ul> <li>https://www.mkdocs.org/</li> <li>https://pages.github.com/</li> <li>https://squidfunk.github.io/mkdocs-material/setup/setting-up-a-blog/</li> <li>https://guts.github.io/mkdocs-rss-plugin/ ...</li> </ul>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/","title":"Enhance your mkdocks.yml","text":"<p>In the previous post I explained how to create a blog with MkDocs and mkdocs-material theme.</p> <p>mkdocs.yml is the configuration file for MkDocs. In this file we can configure the theme, the plugins, the pages, etc.</p> <p>In this post I am going to explain you how to create a blog with MkDocs and mkdocs-material theme, add some plugins and configure it.</p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#minimal-configuration-for-mkdocsyml-with-mkdocs-material","title":"Minimal configuration for mkdocs.yml with mkdocs-material","text":"<pre><code>site_name: My Site\ntheme: \n  name: material\n#plugins:\n\n#markdown_extensions:\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#theme","title":"Theme","text":"<p>I only change the palette for now.</p> <pre><code>theme: \n  name: material\n  palette:\n    primary: blue\n    accent: white  \n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#plugins-for-mkdoc","title":"Plugins for mkdoc","text":"","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#glightbox","title":"glightbox","text":"<p>glightbox add image zoom functionality to your documentation.</p> requirements.txt<pre><code>mkdocs-glightbox\n</code></pre> mkdocs.yml<pre><code>plugins:\n  - glightbox\n</code></pre> <p>Example:</p> <p></p> <p>Imagen de marymarkevich en Freepik</p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#mkdocs-minify-plugin","title":"mkdocs-minify-plugin","text":"<p>An MkDocs plugin to minify HTML, JS or CSS files prior to being written to disk.</p> requiremets.txt<pre><code>mkdocs-minify-plugin\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#extensions","title":"Extensions","text":"","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#material-for-mkdocs","title":"Material for MkDocs","text":"<p>MkDocs supports a large number of Python Markdown extensions</p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#mermaid","title":"mermaid","text":"<p>mermaid2 is a plugin for MkDocs that allows you to embed diagrams written in mermaid.js in your Markdown documentation.</p> mkdocs.yml<pre><code>  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> Example<pre><code>  ```mermaid\n  graph LR\n      A[Square Rect] -- Link text --&gt; B((Circle))\n      A --&gt; C(Round Rect)\n      B --&gt; D{Rhombus}\n      C --&gt; D\n  ```\n</code></pre> <pre><code>graph LR\n    A[Square Rect] -- Link text --&gt; B((Circle))\n    A --&gt; C(Round Rect)\n    B --&gt; D{Rhombus}\n    C --&gt; D\n</code></pre> <p>You can find more information about mermaid.js in https://mermaid-js.github.io/mermaid/#/</p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#admonitions","title":"Admonitions","text":"<p>Admonitions is a markdown extension of materials for MkDocs that allows you to add admonition blocks to your Markdown documentation.</p> mkdocs.yml<pre><code>markdown_extensions:\n  - admonition\n  - pymdownx.details\n  - pymdownx.superfences\n</code></pre> <p>Example:</p> <pre><code>!!! Example\n    Example\n!!! Error\n    Error\n!!! Warning\n    Warning    \n!!! Success\n    Success\n!!! Info\n    Info    \n!!! Tip\n    Tip\n!!! Question\n    Question\n!!! Quote\n    Quote\n</code></pre> <p>Example</p> <p>Example</p> <p>Error</p> <p>Error</p> <p>Warning</p> <p>Warning    </p> <p>Success</p> <p>Success</p> <p>Info</p> <p>Info    </p> <p>Tip</p> <p>Tip</p> <p>Question</p> <p>Question</p> <p>Quote</p> <p>Quote</p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#icons-emojis","title":"Icons, Emojis","text":"<p>With material you can use more than 10000 icons and thousand of emojis in your documentation.</p> mkdocs.yml<pre><code>markdown_extensions:  \n  - attr_list\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n</code></pre> <p>Example:</p> <pre><code>:smile:\n:man_head:\n:face_with_monocle:\n:jack_o_lantern:\n</code></pre> <p> </p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#annotations","title":"Annotations","text":"<p>One of the flagship features of Material for MkDocs is the ability to inject annotations \u2013 little markers that can be added almost anywhere in a document and expand a tooltip containing arbitrary Markdown on click or keyboard focus.</p> mkdocs.yml<pre><code>markdown_extensions:\n  - attr_list\n  - md_in_html\n  - pymdownx.superfences\n</code></pre> <p>Examples:</p> <pre><code>This is a paragraph with a annotation(1).\n{ .annotate }\n\n1.  :man_raising_hand: I'm an annotation! I can contain `code`, __formatted\n    text__, images, ... basically anything that can be expressed in Markdown.\n</code></pre> <p>This is a paragraph with a annotation(1).</p> <ol> <li> I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be expressed in Markdown.</li> </ol> <pre><code>This is a paragraph with a annotation(1).\n{ .annotate }\n\n1.  :man_raising_hand: I'm an annotation! with a nested annotation(1)\n    { .annotate }\n\n    1. I'm a nested annotation!\n</code></pre> <p>This is a paragraph with a annotation(1).</p> <ol> <li> <p> I'm an annotation! with a nested annotation(1)</p> <ol> <li>I'm a nested annotation!</li> </ol> </li> </ol>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#buttons","title":"Buttons","text":"mkdocs.yml<pre><code>markdown_extensions:\n  - attr_list  \n</code></pre> <p>Examples:</p> <pre><code>[This is a button](#)\n{ .md-button }\n</code></pre> <p>This is a button</p> <pre><code>[This is a button](#)\n{ .md-button .md-button--primary }\n</code></pre> <p>This is a button</p> <pre><code>[Send :fontawesome-regular-face-laugh-wink:](#){ .md-button }\n</code></pre> <p>Send </p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#content-tabs","title":"Content tabs","text":"mkdocs.yml<pre><code>markdown_extensions:\n  - pymdownx.superfences\n  - pymdownx.tabbed:\n      alternate_style: true \n</code></pre> <p>Example:</p> <pre><code>=== \"azcli\"\n\n    ``` azcli    \n    az group create --name myResourceGroup --location westeurope\n    ```\n\n=== \"pwsh\"\n\n    ``` pwsh    \n    New-AzResourceGroup -Name myResourceGroup -Location westeurope    \n    ```\n</code></pre> azclipwsh bubble_sort.py<pre><code>az group create --name myResourceGroup --location westeurope\n</code></pre> <pre><code>New-AzResourceGroup -Name myResourceGroup -Location westeurope    \n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#footnotes","title":"Footnotes","text":"mkdocs.yml<pre><code>markdown_extensions:\n  - footnotes\n</code></pre> <p>Example:</p> <pre><code>This is a paragraph with a footnote[^1].\n\n[^1]: And here is the definition.\n</code></pre> <p>This is a paragraph with a footnote<sup>1</sup>.</p>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#formatting","title":"Formatting","text":"mkdocs.yml<pre><code>markdown_extensions:\n  - pymdownx.critic\n  - pymdownx.caret\n  - pymdownx.keys\n  - pymdownx.mark\n  - pymdownx.tilde\n</code></pre> <p>Example:</p> <pre><code>- ~~Mistaken text.~~\n- ^^Superscript^^\n- ==Marked text.==\n</code></pre> <ul> <li>Mistaken text.</li> <li>Superscript</li> <li>Marked text.</li> </ul>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#mkdocsyml-complete","title":"mkdocs.yml complete","text":"<pre><code>site_name: My Site\nsite_description: A blog about Azure, DevOps and other stuff\nsite_author: Rafael Fern\u00e1ndez\nsite_url: https://rfernandezdo.github.io\n\ntheme: \n  name: material\n  palette:\n    primary: blue\n    accent: white\n  features:\n    - navigation.tabs\n    - navigation.expand\n    - navigation.sections\n    - toc.integrate\n    - toc.nested\n    - toc.smoothscroll\n    - footer\n    - content.code.copy\n    - content.code.annotate\n    - content.tooltips\nextra:\n  social:\n    - icon: fontawesome/brands/linkedin\n      link: https://www.linkedin.com/in/rafaelfernandezd/\n      name: LinkedIn\n    - icon: fontawesome/brands/github\n      link: https://github.com/rfernandezdo\n      name: GitHub\n    - icon: fontawesome/solid/square-rss\n      link: https://rfernandezdo.github.io/feed_rss_created.xml\n      name: RSS feed\ncopyright: Copyright &amp;copy; 2023-now Rafael Fern\u00e1ndez\n\nplugins:\n  - search  \n  - mermaid2\n  - blog  \n  - tags:\n      tags_file: tags.md    \n  - rss:\n      match_path: blog/posts/.* \n      date_from_meta:\n        as_creation: date\n      categories:\n        - categories\n        - tags\n  - minify:\n      minify_html: true\n      minify_js: true\n      minify_css: true\n      htmlmin_opts:\n          remove_comments: true\n      cache_safe: true\n  - glightbox:\n      zoomable: true\n      draggable: true\n      skip_classes:\n        - skip-lightbox\n    #- meta in insiders, review in next release\n  - social\nmarkdown_extensions:\n  - admonition\n  - pymdownx.details\n  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n  - md_in_html\n  - attr_list\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n  - pymdownx.tabbed:\n      alternate_style: true\n  - pymdownx.highlight:\n      anchor_linenums: true\n      line_spans: __span\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - footnotes\n  - pymdownx.critic\n  - pymdownx.caret\n  - pymdownx.keys\n  - pymdownx.mark\n  - pymdownx.tilde\n  - def_list\n  - pymdownx.tasklist:\n      custom_checkbox: true\n</code></pre>","tags":["mkdocs"]},{"location":"blog/2023/10/21/enhance-your-mkdocksyml/#urls-for-reference","title":"urls for reference","text":"<ul> <li>Font Awesome</li> <li>Emojis ...</li> </ul> <ol> <li> <p>And here is the definition.\u00a0\u21a9</p> </li> </ol>","tags":["mkdocs"]},{"location":"blog/2023/11/03/trunk/","title":"Trunk","text":"","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#what-is-trunk","title":"What is Trunk ?","text":"<p>Trunk is a tool that runs a suite of security and best practice checks against your code. It is designed to be used in CI/CD pipelines, but can also be used as a standalone tool.</p> <p>Support for the following languages is currently available:</p>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#installing-trunk","title":"Installing Trunk","text":"Trunk cliTrunk VSCode extension <pre><code>curl https://get.trunk.io -fsSL | bash\n</code></pre> <pre><code>code --install-extension Trunk.io  \n</code></pre>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#trunk-checks","title":"Trunk checks","text":"","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#trunk-checks-cli","title":"Trunk checks cli","text":"<p>Trunk detects checks to enable in function of the files in the current directory, but you can also enable and disable checks manually.</p> <ul> <li>trunck check list: list all available checks</li> <li>trunck check enable checkname: enable a check</li> <li>trunck check disable checkname: disable a check</li> <li>trunck check: run all enabled checks</li> </ul> <p>For example, to enable the Terraform check:</p> <pre><code>trunk check enable terraform \n1 linter was enabled:\n  terraform 1.1.0\n</code></pre> <p>Info</p> <p>You can also enable checks by modifing .trunk.yml file in your repository. See the configuration page  for more information.</p> <p>Examples: </p> trunk commnad line check example<pre><code>trunk check   \n\nChecking 68% [====================================================================================================================================================================&gt;                                                                              ]  38/56  9.4s \n \u21b3 checkov                                                                                                                                                                                                                                                                      \n   \u21b3 modules/webapps/linux_function_app/private_endpoint.tf [lint] \u2827                                                                                                                                                                                                            \n   \u21b3 modules/webapps/linux_function_app/variables.tf [lint] \u2827                                                                                                                                                                                                                   \n \u21b3 terrascan                                                                                                                                                                                                                                                                    \n   \u21b3 modules/webapps/linux_function_app/locals.tf [lint] \u2827                                                                                                                                                                                                                      \n   \u21b3 modules/webapps/linux_function_app/main.tf [lint] \u2827                                                                              \n</code></pre>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#trunk-checks-vscode","title":"Trunk checks vscode","text":"<p>In the case of the VSCode extension, you can review your checks in your IDE:</p> <p></p> <p>And you can disable checks from quick fix menu:</p> <p></p>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#trunk-updates","title":"Trunk updates","text":"","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#trunk-updates-cli","title":"Trunk updates cli","text":"<p>Trunk is updated regularly with new checks and improvements. You can update Trunk by running the following command:</p> <pre><code>trunk update\n</code></pre>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#trunk-updates-vscode","title":"Trunk updates vscode","text":"<p>In the case of the VSCode extension, it will be updated automatically:</p> <p></p>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/03/trunk/#references","title":"References","text":"<ul> <li>Trunk</li> <li>Trunk VSCode extension</li> </ul>","tags":["vscode","Trunk"]},{"location":"blog/2023/11/04/starting-to-develop-in-c/","title":"Starting to develop in c#","text":"<p>First, I need to clarify that I'm not a C# developer. I'm learning C# so I can better understand the code that has to be deployed to some Azure services when .NET is used.</p> <p>If someone that knows me is reading this post, he/she will be thinking: </p> <ul> <li>\"What the hell is he doing?\"</li> <li>\"He is crazy\"</li> <li>\"He is going to die trying\".</li> <li>The end of the world is approaching!!</li> </ul> <p>Maybe the last thought can be really true but I have to say that I have decided to learn a programming language and that I have chosen C# because many of the examples for Azure Developers that I have seen are written in C#.</p> <p>I repeat, I am not a developer but I'd like to share with you my experience learning C#.</p>","tags":["csharp"]},{"location":"blog/2023/11/04/starting-to-develop-in-c/#my-first-steps","title":"My first Steps","text":"<p>You have a lot of resources for learning on Learn .NET and in c# documentation.</p> <p>In my case I prefer to simplify and follow csharp-notebooks, these materials are designed to be used with  C# 101 SERIES.</p> <p>After that, I will follow the free course (New) Foundational C# with Microsoft.</p> <p>And after that, I think that I will be ready to start with Tutorials for getting started with .NET and plan next steps.</p> <p>That's all folks!!</p>","tags":["csharp"]},{"location":"blog/2023/11/15/azure--services/","title":"Azure  Services","text":"<p>I have decided to create a new category on my blog to talk about Azure services.</p> <p>The main goal of this category is to provide a quick overview of some Azure services and some design considerations.</p> <p>What is this category due to?</p> <p>In some cases, it is because I am working with this Service and I think it is a good idea to share my experience with you and write it down for me, in others, it is because I am studying/reviewing an Azure Service and I think it is a good idea. Share my notes with you.</p> <p>I hope you like it.</p> <p>I am going to start with Azure Communication Services</p> <p>That's all folks!, thanks for reading !</p>","tags":["General","English"]},{"location":"blog/2023/11/18/azure-communication-services/","title":"Azure Communication Services","text":"","tags":["Azure Communication Services"]},{"location":"blog/2023/11/18/azure-communication-services/#what-is-azure-communication-services","title":"What is Azure Communication Services?","text":"<p>Azure Communication Services are cloud-based services with REST APIs and client library SDKs available to help you integrate communication into your applications. You can add communication to your applications without being an expert in underlying technologies such as media encoding or telephony.</p> <p>Azure Communication Services supports various communication formats:</p> <ul> <li>Voice and Video Calling</li> <li>Rich Text Chat</li> <li>SMS</li> <li>Email</li> </ul> <p>And offers the following services:</p> <ul> <li>SMS: Send and receive SMS messages from your applications.</li> <li>Phone calling: Enable your applications to make and receive PSTN calls.</li> <li>Voice and video calling: Enable your applications to make and receive voice and video calls.</li> <li>Chat: Enable your applications to send and receive chat messages.</li> <li>Email: Send and receive emails from your applications.</li> <li>Network traversal: Enable your applications to connect to other clients behind firewalls and NATs.</li> <li>Advanced Messaging:<ul> <li>WhatsApp(Public Preview): Enable you to send and receive WhatsApp messages using the Azure Communication Services Messaging SDK. </li> </ul> </li> <li>Job Router(Public Preview): It's a tool designed to optimize the management of customer interactions across various communication applications.</li> </ul> <p>Some Use Cases:</p> <ul> <li>Telemedicine: Enable patients to connect with doctors and nurses through video consultations.</li> <li>Remote education: Enable students to connect with teachers and other students through video classes.</li> <li>Financial Advisory: Enhancing global advisor and client interactions with rich capabilities such as translation for chat.</li> <li>Retail Notifications: Send notifications to customers about their orders via SMS or email.</li> <li>Professional Support: Enable customers to connect with support agents through chat, voice, or video.</li> </ul>","tags":["Azure Communication Services"]},{"location":"blog/2023/11/18/azure-communication-services/#design-considerations","title":"Design considerations","text":"<p>You have  some data flow diagrams to help you to understand how Azure Communication Services works here</p> <p>Some aspects to consider:</p> <ul> <li>You need to apply throttling patterns to avoid overloading the service,  HTTP status code 429 (Too many requests).</li> <li>Plan how to map users from your identity domain to Azure Communication Services identities. You can follow any kind of pattern. For example, you can use 1:1, 1:N, N:1, or M:N</li> <li>Check regional availability. You can see more information about regional availability here.</li> <li>Check the service limits. You can see more information about service limits here.</li> <li>Check security baseline. You can see more information about security baseline here.</li> </ul>","tags":["Azure Communication Services"]},{"location":"blog/2023/11/18/azure-communication-services/#pricing","title":"Pricing","text":"<p>Azure Communication Services is a pay-as-you-go service. You only pay for what you use, and there are no upfront costs. You can see more information about pricing here.</p> <p>The bad news are:</p> <ul> <li>In some services pricing vary by country.</li> <li>You don't have a free tier, but you have something free.</li> <li>You don't have Azure Reservations or equivalent.</li> </ul>","tags":["Azure Communication Services"]},{"location":"blog/2023/11/18/azure-communication-services/#conclusion","title":"Conclusion","text":"<p>Azure Communication Services is a very interesting service but you need to consider the cost of the service and the regional availability before to use it.</p> <p>That's it folks!, thanks for reading !.</p>","tags":["Azure Communication Services"]},{"location":"blog/2023/11/21/azure-well-architected-framework-waf-mind-maps/","title":"Azure Well-Architected Framework (WAF) mind maps","text":"","tags":["Azure Well-Architected Framework"]},{"location":"blog/2023/11/21/azure-well-architected-framework-waf-mind-maps/#microsoft-well-architected-framework-pillars-design-principles-mind-map","title":"Microsoft Well-Architected Framework Pillars Design Principles Mind Map","text":"<p>Para cuando lo renderice correctamente materials:</p> <pre><code>mindmap\n    root((Pillars))        \n        Reliability(Reliability)\n            DesignPrinciples(Design Principles)\n                Design for business requirements[\"**Design for business requirements:**\n                Gather business requirements with a focus on the intended utility of the workload.\"]\n                Design for resilience[\"**Design for resilience:**\n                The workload must continue to operate with full or reduced functionality.\"]\n                Design for recovery[\"**Design for recovery:**\n                The workload must be able to anticipate and recover from most failures, of all magnitudes, with minimal disruption to the user experience and business objectives.\"]\n                Design for operations[\"**Design for operations:**\n                Shift left in operations to anticipate failure conditions.\"]\n                Keep it simple[\"**Keep it simple:**\n                Avoid overengineering the architecture design, application code, and operations.\"]\n        Security(Security)\n            DesignPrinciples(Design Principles)\n                Plan your security readiness[\"**Plan your security readiness:**\n                Strive to adopt and implement security practices in architectural design decisions and operations with minimal friction.\"]\n                Design to protect confidentiality[\"**Design to protect confidentiality:**\n                Prevent exposure to privacy, regulatory, application, and proprietary information through access restrictions and obfuscation techniques.\"]\n                Design to protect integrity[\"**Design to protect integrity:**\n                Prevent corruption of design, implementation, operations, and data to avoid disruptions that can stop the system from delivering its intended utility or cause it to operate outside the prescribed limits. The system should provide information assurance throughout the workload lifecycle.\"]\n                Design to protect availability[\"**Design to protect availability:**\n                Prevent or minimize system and workload downtime and degradation in the event of a security incident by using strong security controls. You must maintain data integrity during the incident and after the system recovers.\"]\n                Sustain and evolve your security posture[\"**Sustain and evolve your security posture:**\n                 Incorporate continuous improvement and apply vigilance to stay ahead of attackers who are continuously evolving their attack strategies.\"]       \n        CostOptimization(Cost Optimization)\n            DesignPrinciples(Design Principles)\n                Develop cost-management discipline[\"**Develop cost-management discipline:**\n                Build a team culture that has awareness of budget, expenses, reporting, and cost tracking.\"]\n                Design with a cost-efficiency mindset[\"**Design with a cost-efficiency mindset:**\n                Spend only on what you need to achieve the highest return on your investments.\"]\n                Design for usage optimization[\"**Design for usage optimization:**\n                Maximize the use of resources and operations. Apply them to the negotiated functional and nonfunctional requirements of the solution.\"]\n                Design for rate optimization[\"**Design for rate optimization:**\n                Increase efficiency without redesigning, renegotiating, or sacrificing functional or nonfunctional requirements.\"]\n                Monitor and optimize over time[\"**Monitor and optimize over time:**\n                Continuously right-size investment as your workload evolves with the ecosystem.\"]\n        OperationalExcellence(Operational Excellence)\n            DesignPrinciples(Design Principles)\n               Embrace DevOps culture[\"**Embrace DevOps culture:**\n               Empower development and operations teams to continuously improve their system design and processes by working together with a mindset of collaboration, shared responsibility, and ownership.\"]\n               Establish development standards[\"**Establish development standards:**\n               Optimize productivity by standardizing development practices, enforcing quality gates, and tracking progress and success through systematic change management.\"]\n               Evolve operations with observability[\"**Evolve operations with observability:**\n                Gain visibility into the system, derive insight, and make data-driven decisions.\"]\n               Deploy with confidence[\"**Deploy with confidence:**\n               Reach the desired state of deployment with predictability.\"]\n               Automate for efficiency[\"**Automate for efficiency:**\n                Replace repetitive manual tasks with software automation that completes them quicker, with greater consistency and accuracy, and reduces risks.\"]\n               Adopt safe deployment practices[\"**Adopt safe deployment practices:**\n               Implement guardrails in the deployment process to minimize the effect of errors or unexpected conditions.\"]\n        PerformanceEfficiency(Performance Efficiency)        \n            DesignPrinciples(Design Principles)\n               Negotiate realistic performance targets[\"**Negotiate realistic performance targets:**\n               The intended user experience is defined, and there's a strategy to develop a benchmark and measure targets against the pre-established business requirements.\"]\n               Design to meet capacity requirements[\"**Design to meet capacity requirements:**\n               Provide enough supply to address anticipated demand.\"]\n               Achieve and sustain performance[\"**Achieve and sustain performance:**\n                Protect against performance degradation while the system is in use and as it evolves.\"]\n               Improve efficiency through optimization[\"**Improve efficiency through optimization:**\n                Improve system efficiency within the defined performance targets to increase workload value.\"]\n</code></pre> <p>English Mermaid Live Editor</p> <p>Spanish Mermaid Live Editor</p>","tags":["Azure Well-Architected Framework"]},{"location":"blog/2023/11/21/azure-well-architected-framework-waf-mind-maps/#microsoft-well-architected-framework-pillars-tradeofs-mind-map","title":"Microsoft Well-Architected Framework Pillars Tradeofs Mind Map","text":"<p>Para cuando lo renderice correctamente materials:</p> <pre><code>mindmap\n    root((Pillars))        \n        Reliability(Reliability)\n            Tradeoffs(Tradeoffs)\n                Reliability tradeoffs with Security[\"`**Reliability tradeoffs with Security**`\"]\n                     Tradeoff: Increased workload surface area. The Security pillar prioritizes a reduced and contained surface area to minimize attack vectors and reduce the management of security controls.[\"`**Tradeoff: Increased workload surface area.** The Security pillar prioritizes a reduced and contained surface area to minimize attack vectors and reduce the management of security controls.`\"]\n                        Tradeoff: Security control bypass. The Security pillar recommends that all controls remain active in both normal and stressed systems.[\"`**Tradeoff: Security control bypass.** The Security pillar recommends that all controls remain active in both normal and stressed systems.`\"]\n                            Tradeoff: Old software versions. The Security pillar encourages a *get current, stay current* approach to vendor security patches.[\"`**Tradeoff: Old software versions.** The Security pillar encourages a *get current, stay current* approach to vendor security patches.`\"]\n                Reliability tradeoffs with Cost Optimization[\"`**Reliability tradeoffs with Cost Optimization**`\"]\n                    Tradeoff: Increased implementation redundancy or waste. A cost-optimized workload minimizes underutilized resources and avoids over-provisioning resources.[\"`**Tradeoff: Increased implementation redundancy or waste.** A cost-optimized workload minimizes underutilized resources and avoids over-provisioning resources.`\"]\n                        Tradeoff: Increased investment in operations that aren't aligned with functional requirements. One approach to cost optimization is evaluating the value that's provided by any deployed solution.[\"`**Tradeoff: Increased investment in operations that aren't aligned with functional requirements.** One approach to cost optimization is evaluating the value that's provided by any deployed solution.`\"]\n                Reliability tradeoffs with Operational Excellence[\"`**Reliability tradeoffs with Operational Excellence**`\"]\n                    Tradeoff: Increased operational complexity. Operational Excellence, like Reliability itself, prioritizes simplicity.[\"`**Tradeoff: Increased operational complexity.** Operational Excellence, like Reliability itself, prioritizes simplicity.`\"]\n                        Tradeoff: Increased effort to generate team knowledge and awareness. The Operational Excellence pillar recommends keeping and maintaining a documentation repository for procedures and topologies. [\"`**Tradeoff: Increased effort to generate team knowledge and awareness.** The Operational Excellence pillar recommends keeping and maintaining a documentation repository for procedures and topologies.`\"]\n                Reliability tradeoffs with Performance Efficiency[\"`**Reliability tradeoffs with Performance Efficiency**`\"]\n                    Tradeoff: Increased latency. Performance Efficiency requires a system to achieve performance targets for user and data flows.[\"`**Tradeoff: Increased latency.** Performance Efficiency requires a system to achieve performance targets for user and data flows.`\"]\n                        Tradeoff: Increased over-provisioning. The Performance Efficiency pillar discourages over-provisioning, instead recommending the use of just enough resources to satisfy demand.[\"`**Tradeoff: Increased over-provisioning.** The Performance Efficiency pillar discourages over-provisioning, instead recommending the use of just enough resources to satisfy demand.`\"]\n        Security(Security)\n            Tradeoffs(Tradeoffs)\n                Security tradeoffs with Reliability[\"`**Security tradeoffs with Reliability**`\"]\n                    Tradeoff: Increased complexity. The Reliability pillar prioritizes simplicity and recommends that points of failure are minimized.[\"`**Tradeoff: Increased complexity.** The Reliability pillar prioritizes simplicity and recommends that points of failure are minimized.`\"]\n                        Tradeoff: Increased critical dependencies. The Reliability pillar recommends minimizing critical dependencies. A workload that minimizes critical dependencies, especially external ones, has more control over its points of failure.[\"`**Tradeoff: Increased critical dependencies.** The Reliability pillar recommends minimizing critical dependencies. A workload that minimizes critical dependencies, especially external ones, has more control over its points of failure.`\"]\n                            Tradeoff: Increased complexity of disaster recovery. A workload must reliably recover from all forms of disaster.[\"`**Tradeoff: Increased complexity of disaster recovery.** A workload must reliably recover from all forms of disaster.`\"]\n                                Tradeoff: Increased rate of change. A workload that experiences runtime change is exposed to more risk of reliability impact due to that change.[\"`**Tradeoff: Increased rate of change.** A workload that experiences runtime change is exposed to more risk of reliability impact due to that change.`\"]\n                Security tradeoffs with Cost Optimization[\"`**Security tradeoffs with Cost Optimization**`\"]\n                    Tradeoff: Additional infrastructure. One approach to cost optimizing a workload is to look for ways to reduce the diversity and number of components and increase density.[\"`**Tradeoff: Additional infrastructure.** One approach to cost optimizing a workload is to look for ways to reduce the diversity and number of components and increase density.`\"]\n                        Tradeoff: Increased demand on infrastructure. The Cost Optimization pillar prioritizes driving down demand on resources to enable the use of cheaper SKUs, fewer instances, or reduced consumption.[\"`**Tradeoff: Increased demand on infrastructure.** The Cost Optimization pillar prioritizes driving down demand on resources to enable the use of cheaper SKUs, fewer instances, or reduced consumption.`\"]\n                            Tradeoff: Increased process and operational costs. Personnel process costs are part of the overall total cost of ownership and are factored into a workload's return on investment. Optimizing these costs is a recommendation of the Cost Optimization pillar.[\"`**Tradeoff: Increased process and operational costs.** Personnel process costs are part of the overall total cost of ownership and are factored into a workload's return on investment. Optimizing these costs is a recommendation of the Cost Optimization pillar.`\"]\n                Security tradeoffs with Operational Excellence[\"`**Security tradeoffs with Operational Excellence**`\"]\n                    Tradeoff: Complications in observability and serviceability. Operational Excellence requires architectures to be serviceable and observable. The most serviceable architectures are those that are the most transparent to everyone involved.[\"`**Tradeoff: Complications in observability and serviceability.** Operational Excellence requires architectures to be serviceable and observable. The most serviceable architectures are those that are the most transparent to everyone involved.`\"]\n                        Tradeoff: Decreased agility and increased complexity. Workload teams measure their velocity so that they can improve the quality, frequency, and efficiency of delivery activities over time. Workload complexity factors into the effort and risk involved in operations[\"`**Tradeoff: Decreased agility and increased complexity.** Workload teams measure their velocity so that they can improve the quality, frequency, and efficiency of delivery activities over time. Workload complexity factors into the effort and risk involved in operations`\"]\n                            Tradeoff: Increased coordination efforts. A team that minimizes external points of contact and review can control their operations and timeline more effectively.[\"`**Tradeoff: Increased coordination efforts.** A team that minimizes external points of contact and review can control their operations and timeline more effectively.`\"]             \n                Security tradeoffs with Performance Efficiency[\"`**Security tradeoffs with Performance Efficiency**`\"]\n                    Tradeoff: Increased latency and overhead. A performant workload reduces latency and overhead.[\"`**Tradeoff: Increased latency and overhead.** A performant workload reduces latency and overhead.`\"]\n                        Tradeoff: Increased chance of misconfiguration. Reliably meeting performance targets depends on predictable implementations of the design.[\"`**Tradeoff: Increased chance of misconfiguration.** Reliably meeting performance targets depends on predictable implementations of the design.`\"]\n        Cost Optimization[\"Cost Optimization`\"]\n            Tradeoffs(Tradeoffs)\n                Cost Optimization tradeoffs with Reliability[\"`**Cost Optimization tradeoffs with Reliability**`\"]\n                    Tradeoff: Reduced resiliency. A workload incorporates resiliency measures to attempt to avoid and withstand specific types and quantities of malfunction.[\"`**Tradeoff: Reduced resiliency.** A workload incorporates resiliency measures to attempt to avoid and withstand specific types and quantities of malfunction.`\"]\n                        Tradeoff: Limited recovery strategy. A workload that's reliable has a tested incident response and recovery plan for disaster scenarios.[\"`**Tradeoff: Limited recovery strategy.** A workload that's reliable has a tested incident response and recovery plan for disaster scenarios.`\"]\n                            Tradeoff: Increased complexity. A workload that uses straightforward approaches and avoids unnecessary or overengineered complexity is generally easier to manage in terms of reliability.[\"`**Tradeoff: Increased complexity.** A workload that uses straightforward approaches and avoids unnecessary or overengineered complexity is generally easier to manage in terms of reliability.`\"]\n                Cost Optimization tradeoffs with Security[\"`**Cost Optimization tradeoffs with Security**`\"]\n                    Tradeoff: Reduced security controls. Security controls are established across multiple layers, sometimes redundantly, to provide defense in depth.[\"`**Tradeoff: Reduced security controls.** Security controls are established across multiple layers, sometimes redundantly, to provide defense in depth.`\"]\n                        Tradeoff: Increased workload surface area. The Security pillar prioritizes a reduced and contained surface area to minimize attack vectors and the management of security controls.[\"`**Tradeoff: Increased workload surface area.** The Security pillar prioritizes a reduced and contained surface area to minimize attack vectors and the management of security controls.`\"]\n                            Tradeoff: Removed segmentation. The Security pillar prioritizes strong segmentation to support the application of targeted security controls and to control the blast radius.[\"`**Tradeoff: Removed segmentation.** The Security pillar prioritizes strong segmentation to support the application of targeted security controls and to control the blast radius.`\"]\n                Cost Optimization tradeoffs with Operational Excellence[\"`**Cost Optimization tradeoffs with Operational Excellence**`\"]\n                    Tradeoff: Compromised software development lifecycle SDLC capacities. A workload's SDLC process provides rigor, consistency, specificity, and prioritization to change management in a workload.[\"`**Tradeoff: Compromised software development lifecycle capacities.** A workload's SDLC process provides rigor, consistency, specificity, and prioritization to change management in a workload.`\"]\n                        Tradeoff: Reduced observability. Observability is necessary to help ensure that a workload has meaningful alerting and successful incident response.[\"`**Tradeoff: Reduced observability.** Observability is necessary to help ensure that a workload has meaningful alerting and successful incident response.`\"]\n                            Tradeoff: Deferred maintenance. Workload teams are expected to keep code, tooling, software packages, and operating systems patched and up to date in a timely and orderly way.[\"`**Tradeoff: Deferred maintenance.** Workload teams are expected to keep code, tooling, software packages, and operating systems patched and up to date in a timely and orderly way.`\"]\n                Cost Optimization tradeoffs with Performance Efficiency[\"`**Cost Optimization tradeoffs with Performance Efficiency**`\"]\n                    Tradeoff: Underprovisioned or underscaled resources. A performance-efficient workload has enough resources to serve demand but doesn't have excessive unused overhead, even when usage patterns fluctuate.[\"`**Tradeoff: Underprovisioned or underscaled resources.** A performance-efficient workload has enough resources to serve demand but doesn't have excessive unused overhead, even when usage patterns fluctuate.`\"]\n                        Tradeoff: Lack of optimization over time. Evaluating the effects of changes in functionality, changes in usage patterns, new technologies, and different approaches on the workload is one way to try to increase efficiency.[\"`**Tradeoff: Lack of optimization over time.** Evaluating the effects of changes in functionality, changes in usage patterns, new technologies, and different approaches on the workload is one way to try to increase efficiency.`\"]\n        Operational Excellence[\"Operational Excellence\"]\n            Tradeoffs(Tradeoffs)\n                Operational Excellence tradeoffs with Reliability[\"`**Operational Excellence tradeoffs with Reliability**`\"]\n                    Tradeoff: Increased complexity. Reliability prioritizes simplicity, because simple design minimizes misconfiguration and reduces unexpected interactions.[\"`**Tradeoff: Increased complexity.** Reliability prioritizes simplicity, because simple design minimizes misconfiguration and reduces unexpected interactions.`\"]\n                        Tradeoff: Increased potentially destabilizing activities. The Reliability pillar encourages the avoidance of activities or design choices that can destabilize a system and lead to disruptions, outages, or malfunctions[\"`**Tradeoff: Increased potentially destabilizing activities.** The Reliability pillar encourages the avoidance of activities or design choices that can destabilize a system and lead to disruptions, outages, or malfunctions.`\"]\n                Operational Excellence tradeoffs with Security[\"`**Operational Excellence tradeoffs with Security**`\"]\n                    Tradeoff: Increased surface area. The Security pillar recommends a reduced workload surface area in terms of components and exposure to operations. This reduction minimizes attack vectors and produces a smaller scope for security control and testing.[\"`**Tradeoff: Increased surface area.** The Security pillar recommends a reduced workload surface area in terms of components and exposure to operations. This reduction minimizes attack vectors and produces a smaller scope for security control and testing.`\"]\n                        Tradeoff: Increased desire for transparency. A secure workload is based on designs that protect the confidentiality of data that flows through the components of the system.[\"`**Tradeoff: Increased desire for transparency.** A secure workload is based on designs that protect the confidentiality of data that flows through the components of the system.`\"]\n                            Tradeoff: Reduced segmentation. A key security approach for isolating access and function is to design a strong segmentation strategy. This design is implemented through resource isolation and identity controls.[\"`**Tradeoff: Reduced segmentation.** A key security approach for isolating access and function is to design a strong segmentation strategy. This design is implemented through resource isolation and identity controls.`\"]                    \n                Operational Excellence tradeoffs with Cost Optimization[\"`**Operational Excellence tradeoffs with Cost Optimization**`\"]\n                     Tradeoff: Increased resource spending. A major cost driver for a workload is the cost of its resources. Deploying fewer resources, right-sizing resources, and reducing consumption generally helps keep costs low.[\"`**Tradeoff: Increased resource spending.** A major cost driver for a workload is the cost of its resources. Deploying fewer resources, right-sizing resources, and reducing consumption generally helps keep costs low.`\"]\n                        Tradeoff: Decreased focus on delivery activities. Workload team members deliver increased workload value by efficiently performing tasks that are aligned to their capabilities.[\"`**Tradeoff: Decreased focus on delivery activities.** Workload team members deliver increased workload value by efficiently performing tasks that are aligned to their capabilities.`\"]\n                            Tradeoff: Increased tooling demands and diversity. The Cost Optimization pillar recommends the reduction of tooling sprawl, consolidation of vendors, and a right-sized approach to all tooling purchases.[\"`**Tradeoff: Increased tooling demands and diversity.** The Cost Optimization pillar recommends the reduction of tooling sprawl, consolidation of vendors, and a right-sized approach to all tooling purchases.`\"]\n                Operational Excellence tradeoffs with Performance Efficiency[\"`**Operational Excellence tradeoffs with Performance Efficiency**`\"]\n                    Tradeoff: Increased resource utilization. The Performance Efficiency pillar recommends the allocation of as much of the available compute and network as possible to the requirements of the workload.[\"`**Tradeoff: Increased resource utilization.** The Performance Efficiency pillar recommends the allocation of as much of the available compute and network as possible to the requirements of the workload.`\"]\n                        Tradeoff: Increased latency. To create performant workloads, teams look for ways to reduce the time and resources that workloads consume to perform their tasks.[\"`**Tradeoff: Increased latency.** To create performant workloads, teams look for ways to reduce the time and resources that workloads consume to perform their tasks.`\"]\n        Performance Efficiency(\"Performance Efficiency\")\n            Tradeoffs(Tradeoffs)\n                Performance Efficiency tradeoffs with Reliability[\"`**Performance Efficiency tradeoffs with Reliability**`\"]\n                    Tradeoff: Reduced replication and increased density. A cornerstone of reliability is ensuring resilience by using replication and limiting the blast radius of malfunctions.[\"`**Tradeoff: Reduced replication and increased density.** A cornerstone of reliability is ensuring resilience by using replication and limiting the blast radius of malfunctions.`\"]\n                        Tradeoff: Increased complexity. Reliability prioritizes simplicity.[\"`**Tradeoff: Increased complexity.** Reliability prioritizes simplicity.`\"]\n                            Tradeoff: Testing and observation on active environments. Avoiding the unnecessary use of production systems is a self-preservation approach for reliability.[\"`**Tradeoff: Testing and observation on active environments.** Avoiding the unnecessary use of production systems is a self-preservation approach for reliability.`\"]                  \n                Performance Efficiency tradeoffs with Security[\"`**Performance Efficiency tradeoffs with Security**`\"]\n                    Tradeoff: Reduction of security controls. Security controls are established across multiple layers, sometimes redundantly, to provide defense in depth[\"`**Tradeoff: Reduction of security controls.** Security controls are established across multiple layers, sometimes redundantly, to provide defense in depth.`\"]\n                        Tradeoff: Increased workload surface area. Security prioritizes a reduced and contained surface area to minimize attack vectors and reduce the management of security controls.[\"`**Tradeoff: Increased workload surface area.** Security prioritizes a reduced and contained surface area to minimize attack vectors and reduce the management of security controls.`\"]\n                            Tradeoff: Removing segmentation. The Security pillar prioritizes strong segmentation to enable fine-grained security controls and reduce blast radius.[\"`**Tradeoff: Removing segmentation.** The Security pillar prioritizes strong segmentation to enable fine-grained security controls and reduce blast radius.`\"]                   \n                Performance Efficiency tradeoffs with Cost Optimization[\"`**Performance Efficiency tradeoffs with Cost Optimization**`\"]\n                    Tradeoff: Too much supply for demand. Both Cost Optimization and Performance Efficiency prioritize having just enough supply to serve demand.[\"`**Tradeoff: Too much supply for demand.** Both Cost Optimization and Performance Efficiency prioritize having just enough supply to serve demand.`\"]\n                        Tradeoff: More components. One cost optimization technique is to consolidate with a smaller number of resources by increasing density, removing duplication, and co-locating functionality.[\"`**Tradeoff: More components.** One cost optimization technique is to consolidate with a smaller number of resources by increasing density, removing duplication, and co-locating functionality.`\"]\n                        Tradeoff: Increased investment on items that aren't aligned with functional requirements. One approach to cost optimization is evaluating the value provided by any solution that's deployed.[\"`**Tradeoff: Increased investment on items that aren't aligned with functional requirements.** One approach to cost optimization is evaluating the value provided by any solution that's deployed.`\"]                    \n                Performance Efficiency tradeoffs with Operational Excellence[\"`**Performance Efficiency tradeoffs with Operational Excellence**`\"]\n                    Tradeoff: Reduced observability. Observability is necessary to provide a workload with meaningful alerting and help ensure successful incident response.[\"`**Tradeoff: Reduced observability.** Observability is necessary to provide a workload with meaningful alerting and help ensure successful incident response.`\"]\n                        Tradeoff: Increased complexity in operations. A complex environment has more complex interactions and a higher likelihood of a negative impact from routine, ad hoc, and emergency operations.[\"`**Tradeoff: Increased complexity in operations.** A complex environment has more complex interactions and a higher likelihood of a negative impact from routine, ad hoc, and emergency operations.`\"]\n                            Tradeoff: Culture stress. Operational Excellence is rooted in a culture of blamelessness, respect, and continuous improvement.[\"`**Tradeoff: Culture stress.** Operational Excellence is rooted in a culture of blamelessness, respect, and continuous improvement.`\"]\n\n\n</code></pre> <p>English Mermaid Live Editor</p> <p>Spanish Mermaid live editor</p>","tags":["Azure Well-Architected Framework"]},{"location":"blog/2023/11/21/azure-well-architected-framework-waf-mind-maps/#references","title":"References","text":"<ul> <li>Microsoft Well-Architected Framework pillars</li> </ul>","tags":["Azure Well-Architected Framework"]},{"location":"blog/2023/11/30/comparing-container-apps-with-other-azure-container-options/","title":"Comparing Container Apps with other Azure container options","text":"","tags":["Azure Container Apps"]},{"location":"blog/2023/11/30/comparing-container-apps-with-other-azure-container-options/#container-option-comparisons","title":"Container option comparisons","text":"Service Primary Use Advantages Disadvantages Azure Container Apps Building serverless microservices and jobs based on containers Optimized for general purpose containers. Provides a fully managed experience based on best-practices. Doesn't provide direct access to Kubernetes APIs. Azure App Service Fully managed hosting for web applications including websites and web APIs Integrated with other Azure services. Ideal option for building web apps. Might not be suitable for non-web applications. Azure Container Instances Provides a single isolated container on demand It's a great solution for any scenario that can operate in isolated containers, including simple applications, task automation, and build jobs. Concepts like scale, load balancing, and certificates are not provided. Azure Kubernetes Service Provides a fully managed Kubernetes option in Azure Supports any Kubernetes workload. Complete control over cluster configurations and operations. Requires management of the full cluster within your subscription. Azure Functions Serverless Functions-as-a-Service (FaaS) solution Optimized for running event-driven applications using the functions programming model. Limited to ephemeral functions deployed as either code or containers. Azure Spring Apps Fully managed service for Spring developers Service manages the infrastructure of Spring applications allowing developers to focus on their code. Only suitable for running Spring-based applications. Azure Red Hat OpenShift Jointly engineered, operated, and supported by Red Hat and Microsoft to provide an integrated product and support experience Offers built-in solutions for automated source code management, container and application builds, deployments, scaling, health management. Dependent on OpenShift. If your team or organization is not using OpenShift, this may not be the ideal option. <p>Please note that the advantages and disadvantages may vary according to specific use cases.</p>","tags":["Azure Container Apps"]},{"location":"blog/2023/11/30/comparing-container-apps-with-other-azure-container-options/#references","title":"References","text":"<ul> <li>Azure Container Apps https://learn.microsoft.com/en-us/azure/container-apps/compare-options</li> </ul>","tags":["Azure Container Apps"]},{"location":"blog/2023/11/30/azure-updates-rss-feed/","title":"Azure updates RSS feed","text":"<p>All the Azure updates in one place.</p> <ul> <li>All</li> </ul>"},{"location":"blog/2023/11/30/azure-updates-rss-feed/#by-category","title":"By category","text":"<ul> <li> <p>Featured</p> </li> <li> <p>AI + Machine Learning</p> </li> <li> <p>Analytics</p> </li> <li> <p>Blockchain</p> </li> <li> <p>Compute</p> </li> <li> <p>Containers</p> </li> <li> <p>Databases</p> </li> <li> <p>Developer Tools</p> </li> <li> <p>DevOps</p> </li> <li> <p>Hybrid + multicloud</p> </li> <li> <p>Identity</p> </li> <li> <p>Integration</p> </li> <li> <p>Internet of Things</p> </li> <li> <p>Management</p> </li> <li> <p>Media</p> </li> <li> <p>Migration</p> </li> <li> <p>Mixed Reality</p> </li> <li> <p>Mobile</p> </li> <li> <p>Networking</p> </li> <li> <p>Security</p> </li> <li> <p>Storage </p> </li> <li> <p>Virtual desktop infrastructure</p> </li> <li> <p>Web</p> </li> </ul>"},{"location":"blog/2023/11/30/azure-updates-rss-feed/#custom","title":"Custom","text":"<p>https://azurecomcdn.azureedge.net/en-gb/updates/feed/?category=category1%2Ccategory2%2Ccategory3</p> <p>For example: </p> <p>https://azurecomcdn.azureedge.net/en-gb/updates/feed/?category=featured%2Cai-machine-learning%2Canalytics</p>"},{"location":"blog/2023/12/01/azure-functions/","title":"Azure Functions","text":"","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#introduction","title":"Introduction","text":"<p>Azure Functions is a serverless compute service provided by Microsoft Azure. This analysis aims to provide a comprehensive understanding of Azure Functions, its architecture, deployment, scalability, security, and more.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#service-overview","title":"Service Overview","text":"<p>Azure Functions allows developers to run small pieces of code (called \"functions\") without worrying about application infrastructure. With Azure Functions, the cloud infrastructure provides all the up-to-date servers needed to keep your applications running at scale.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#architecture-and-components","title":"Architecture and Components","text":"<p>Azure Functions is built on an event-driven, compute-on-demand experience that extends the existing Azure application platform with capabilities to implement code triggered by events occurring in Azure or third-party services.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#deployment-and-configuration","title":"Deployment and Configuration","text":"<p>Azure Functions can be deployed using the Azure portal, Azure Resource Manager (ARM) templates, or the Azure Command-Line Interface (CLI). Configuration settings can be managed through environment variables and application settings.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#scalability-and-performance","title":"Scalability and Performance","text":"<p>Azure Functions supports auto-scaling based on the load, ensuring optimal performance. It also provides features like load balancing to distribute incoming traffic across multiple instances of a function app.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#security-and-compliance","title":"Security and Compliance","text":"<p>Azure Functions provides built-in authentication and authorization support. It also supports network isolation with Azure Virtual Network (VNet) and encryption of data at rest and in transit. Azure Functions complies with key international and industry-specific compliance standards like ISO, SOC, and GDPR.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Azure Functions integrates with Azure Monitor and Application Insights for monitoring and logging. It provides real-time information on how your function app is performing and where your application is spending its time.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#use-cases-and-examples","title":"Use Cases and Examples","text":"<p>Azure Functions is commonly used for processing data, integrating systems, working with the internet-of-things (IoT), and building simple APIs and microservices.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#best-practices-and-tips","title":"Best Practices and Tips","text":"<p>When using Azure Functions, it's recommended to keep functions small and focused on a single task. Also, avoid long-running functions as they may cause unexpected timeout issues.</p> <p>If you are using long-running functions, consider using Durable Functions, which are an extension of Azure Functions that lets you write stateful functions in a serverless environment.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/01/azure-functions/#conclusion","title":"Conclusion","text":"<p>Azure Functions is a powerful service for running event-driven applications at scale. It offers a wide range of features and capabilities that can meet the needs of almost any application. We encourage you to explore Azure Functions further and see how it can benefit your applications.</p>","tags":["Azure Functions"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/","title":"Instalar WSL2 en Windows 11 con chocolatey","text":"","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#introduccion","title":"Introducci\u00f3n","text":"<p>Windows Subsystem for Linux (WSL) es una caracter\u00edstica de Windows 11 que permite ejecutar un entorno de Linux en Windows. WSL2 es la segunda versi\u00f3n de WSL que ofrece un kernel de Linux completo y un mejor rendimiento en comparaci\u00f3n con WSL1. Este an\u00e1lisis proporciona una gu\u00eda paso a paso para instalar WSL2 en Windows 11.</p>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#pasos-a-seguir","title":"Pasos a seguir","text":"","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#1-instalar-chocolatey","title":"1. Instalar Chocolatey","text":"<p>Chocolatey es un administrador de paquetes para Windows que facilita la instalaci\u00f3n y gesti\u00f3n de software. Para instalar Chocolatey, siga los siguientes pasos:</p> <ol> <li> <p>Abra PowerShell como administrador.</p> </li> <li> <p>Ejecute el siguiente comando para instalar Chocolatey:</p> </li> </ol> <pre><code>Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\n</code></pre> <ol> <li>Espere a que se complete la instalaci\u00f3n de Chocolatey.</li> </ol>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#2-instalar-wsl2","title":"2. Instalar WSL2","text":"<p>Para instalar WSL2 en Windows 11, siga los siguientes pasos:</p> <ol> <li> <p>Abra PowerShell como administrador.</p> </li> <li> <p>Ejecute el siguiente comando para instalar WSL2:</p> </li> </ol> <p><pre><code>choco install wsl2\n</code></pre> 3. Espere a que se complete la instalaci\u00f3n de WSL2.</p>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#3-configurar-wsl2","title":"3. Configurar WSL2","text":"<p>Para configurar WSL2 en Windows 11, siga los siguientes pasos:</p> <ol> <li> <p>Abra PowerShell como administrador.</p> </li> <li> <p>Ejecute el siguiente comando para configurar WSL2 como la versi\u00f3n predeterminada:</p> </li> </ol> <pre><code>wsl --set-default-version 2\n</code></pre> <ol> <li>Reinicie su computadora para aplicar los cambios.</li> </ol>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#4-instalar-una-distribucion-de-linux","title":"4. Instalar una distribuci\u00f3n de Linux","text":"<p>Para instalar una distribuci\u00f3n de Linux en WSL2, siga los siguientes pasos:</p> <ol> <li> <p>Abra PowerShell.</p> </li> <li> <p>Busque la distribuci\u00f3n de Linux que desea instalar (por ejemplo, Ubuntu, Debian, Fedora)</p> </li> </ol> <pre><code>wsl --list --online\n</code></pre> <ol> <li>Ejecute el siguiente comando para instalar la distribuci\u00f3n de Linux seleccionada:</li> </ol> <pre><code>wsl --install -d &lt;nombre de la distribuci\u00f3n&gt;\n</code></pre> <ol> <li>Espere a que se complete la instalaci\u00f3n de la distribuci\u00f3n de Linux.</li> </ol>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#5-iniciar-wsl2","title":"5. Iniciar WSL2","text":"<p>Para iniciar WSL2 en Windows 11, siga los siguientes pasos:</p> <ol> <li> <p>Abra PowerShell.</p> </li> <li> <p>Ejecute el siguiente comando para iniciar la distribuci\u00f3n de Linux instalada:</p> </li> </ol> <pre><code>wsl\n</code></pre>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/04/instalar-wsl2-en-windows-11-con-chocolatey/#referencias","title":"Referencias","text":"<ul> <li>Chocolatey</li> <li>What is the Windows Subsystem for Linux?</li> </ul>","tags":["Windows Subsystem for Linux 2"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/","title":"Depurar logs de OneDrive para detectar problemas de sincronizaci\u00f3n","text":"<p>Necesitas WSL2</p> <p>Para poder seguir este tutorial necesitas tener instalado WSL2 en tu equipo, si no lo tienes, puedes seguir este tutorial Instalar WSL2 en Windows 11 con chocolatey</p>","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#introduccion","title":"Introducci\u00f3n","text":"<p>Llevo unos d\u00edas con sync pending en algunos ficheros en mi OneDrive for Business sin ninguna raz\u00f3n aparente, por lo que he decidido investigar un poco y compartir como he resuelto el problema.</p> <p>Lo primero es seguir la siguiente documentaci\u00f3n de Microsoft que puede ser \u00fatil para alguien que tenga problemas de sincronizaci\u00f3n con OneDrive:</p> <p>Fix OneDrive sync problems</p> <p>Pero si no funciona, se puede obtener m\u00e1s informaci\u00f3n de los logs de OneDrive.</p>","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#pasos-a-seguir","title":"Pasos a seguir","text":"","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#1-acceder-a-los-logs-de-onedrive","title":"1. Acceder a los logs de OneDrive","text":"<p>Para acceder a los logs de OneDrive, se debe seguir los siguientes pasos:</p> <ol> <li>Abrir el Explorador de archivos.</li> <li>Hacer clic en la flecha hacia arriba en la barra de direcciones.</li> <li>Pegar la siguiente ruta en la barra de direcciones y presionar Enter:</li> </ol> BusinessPersonal <pre><code>%localappdata%\\Microsoft\\OneDrive\\logs\\Business1\n</code></pre> <pre><code>%localappdata%\\Microsoft\\OneDrive\\logs\\Personal\n</code></pre> <p>Ahora es necesario seleccionar los archivos de log m\u00e1s recientes y copiarlos a un directorio, los archivos pueden tener extensi\u00f3n .odl,.odlgz, .odlsent  o .aold, tambi\u00e9n se debe incluir el fichero ObfuscationStringMap.txt o general.keystore.</p>","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#2-instalar-el-visor-de-logs-de-onedrive","title":"2. Instalar el visor de logs de OneDrive","text":"<p>Para instalar el visor de logs de OneDrive, se debe seguir los siguientes pasos:</p> <p>Descarga https://raw.githubusercontent.com/ydkhatri/OneDrive/main/odl.py y ejecuta el siguiente comando:</p> <pre><code>pip3 install pycryptodome\npip3 install construct\npython odl.py -o &lt;ruta de salida&gt;/fichero.csv &lt;ruta de los logs&gt;\n</code></pre> <p>Por ejemplo:</p> <pre><code>python3 odl.py -o output/fichero.csv input/\nWARNING: Multiple instances of some keys were found in the ObfuscationMap.\nRead 40493 items from map\nRecovered Unobfuscation key Churreradenumneros, version=1, utf_type=utf16\nSearching  /mnt/c/Users/userdemo/Escritorio/input/SyncEngine-2023-09-04.0637.32.2.odl\nWrote 821 rows\nSearching  /mnt/c/Users/userdemo/Escritorio/input/FileCoAuth-2023-09-03.0804.13536.1.odlgz\nWrote 203 rows\nSearching  /mnt/c/Users/userdemo/Escritorio/input/FileCoAuth-2023-09-03.0804.14112.1.odlgz\n.......\n............\n...............\nWrote 872 rows\nFinished processing files, output is at output/fichero.csv\nuserdemo@DESKTOP:/mnt/c/Users/userdemo/Escritorio$\n</code></pre>","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#3-analizar-los-logs","title":"3. Analizar los logs","text":"<p>Una vez que se ha generado el fichero CSV, se puede abrir con Excel o cualquier editor de texto para analizar los logs y detectar problemas de sincronizaci\u00f3n, busca error o warn para averiguar que puede estar provocando el problema.</p>","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#solucion","title":"Soluci\u00f3n","text":"<p>En mi caso, tras poder leer los logs de OneDrive, he descubierto que OneDrive no pod\u00eda escribir varios ficheros en disco, luego record\u00e9 que el otro d\u00eda mi equipo no se apag\u00f3 bien.</p> <p>Tras un chkdsk c: /F /R,  fin de la historia, ahora todo funciona, espero que le resulte \u00fatil a alguien.</p>","tags":["OneDrive for Business"]},{"location":"blog/2023/12/05/depurar-logs-de-onedrive-para-detectar-problemas-de-sincronizaci%C3%B3n/#referencias","title":"Referencias","text":"<ul> <li>https://github.com/ydkhatri/OneDrive/tree/main</li> </ul>","tags":["OneDrive for Business"]},{"location":"blog/2024/02/24/azure-policy/","title":"Azure Policy","text":"<p>Azure Policy serves as a powerful tool for implementing governance across your Azure environment. It helps ensure resource consistency, regulatory compliance, security, cost management, and efficient operations</p> <p>As organizations leverage the power of Azure for their cloud infrastructure, ensuring governance, compliance, and security becomes paramount. Azure Policy, along with policies and initiatives, provides a robust framework to enforce and assess compliance with organizational standards and regulatory requirements. Let's delve into these concepts to understand how they work together.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/24/azure-policy/#azure-policy-overview","title":"Azure Policy Overview","text":"<p>Azure Policy is a service in Azure that allows you to create, assign, and manage policies. These policies enforce different rules and effects over resources, so those resources stay compliant with corporate standards and service-level agreements.</p> <p>Azure Policy helps to address questions like:</p> <ul> <li>Are all virtual machines encrypted using Azure Disk Encryption?</li> <li>Are resources deployed only in certain Azure regions?</li> <li>Are specific tags applied to resources for tracking and organization?</li> </ul> <p>Policies in Azure Policy are defined using JSON-based policy definitions. These definitions can be simple or complex, depending on the requirements. Once a policy is created, it can be assigned to specific scopes within Azure, such as subscriptions, resource groups, or even individual resources.</p> <p>Info</p> <p>It's important to recognize that with the introduction of Azure Arc, you can extend your policy-based governance across different cloud providers and even to your local datacenters.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/24/azure-policy/#policies","title":"Policies","text":"<p>Policies in Azure Policy are rules that enforce different requirements and effects on resources. These policies can be related to security, compliance, or management. For instance, you can have a policy that ensures all publicly accessible storage accounts are secured with a firewall or a policy that enforces a specific naming convention for virtual machines.</p> <p>Key attributes of policies include: - Effect: Determines what happens when the condition in the policy is met (e.g., deny the action, audit the action, append a tag). - Condition: Defines when the policy is enforced based on properties of the resource being evaluated. - Action: Specifies what happens when a resource violates the policy (e.g., deny deployment, apply audit).</p> <p>Policies can be built-in (provided by Azure) or custom (defined by the organization). They play a vital role in maintaining compliance and security standards across Azure environments.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/24/azure-policy/#initiatives","title":"Initiatives","text":"<p>Initiatives in Azure Policy are collections of policies that are grouped together as a single unit. This simplifies the process of assigning multiple policies to different scopes simultaneously. Initiatives help in enforcing complex requirements and compliance standards by grouping related policies together.</p> <pre><code>graph TD;\n    A[Azure Policy] --&gt;|Contains| B1[Policy 1]\n    A[Azure Policy] --&gt;|Contains| B2[Policy 2]\n    A[Azure Policy] --&gt;|Contains| B3[Policy 3]\n    A[Azure Policy] --&gt;|Contains| B4[Policy 4]\n    B1[Policy 1] --&gt;|Belongs to| C[Initiative 1]\n    B2[Policy 2] --&gt;|Belongs to| C[Initiative 1]\n    B3[Policy 3] --&gt;|Belongs to| D[Initiative 2]\n\n\n    classDef azurePolicy fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef policy fill:#fc9,stroke:#333,stroke-width:2px;\n    classDef initiative fill:#9cf,stroke:#333,stroke-width:2px;\n\n    class A,B1,B2,B3,B4 azurePolicy;\n    class C,D initiative;\n    class D1,D2,E1,E2 policy;\n</code></pre> <p>Initiatives allow you to:</p> <ul> <li>Apply multiple policies at once to a scope (like a subscription or management group).</li> <li>Monitor compliance against a set of defined standards or regulations.</li> <li>Streamline governance by organizing policies logically.</li> </ul> <p>By using initiatives, you can efficiently manage and enforce compliance with regulatory standards (e.g., CIS benchmarks, PCI DSS) or organizational best practices.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/24/azure-policy/#assignments","title":"Assignments","text":"<p>Assignments in Azure Policy are the mechanism to apply policies or initiatives to specific scopes within Azure. You can assign policies to subscriptions, resource groups, or even individual resources. Assignments help in enforcing governance and compliance standards across your Azure environment.</p> <pre><code>graph TD;\n    A[Azure Policy] --&gt;|Contains| B1[Policy 1]\n    A[Azure Policy] --&gt;|Contains| B2[Policy 2]\n    A[Azure Policy] --&gt;|Contains| B3[Policy 3]\n    A[Azure Policy] --&gt;|Contains| B4[Policy 4]\n    B1[Policy 1] --&gt;|Belongs to| C[Initiative 1]\n    B2[Policy 2] --&gt;|Belongs to| C[Initiative 1]\n    B3[Policy 3] --&gt;|Belongs to| D[Initiative 2]\n    C[Initiative 1] --&gt;|Assigned to| E[Subscription 1]\n    D[Initiative 2] --&gt;|Assigned to| F[Resource Group 1]\n    B4[Policy 4] --&gt;|Assigned to| G[Management Group 1]\n\n    classDef azurePolicy fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef policy fill:#fc9,stroke:#333,stroke-width:2px;\n    classDef initiative fill:#9cf,stroke:#333,stroke-width:2px;\n    classDef assignment fill:#9f9,stroke:#333,stroke-width:2px;\n\n    class A,B1,B2,B3,B4 azurePolicy;\n    class C,D initiative;\n    class E,F,G assignment;\n    class D1,D2,E1,E2 policy;\n\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/02/24/azure-policy/#conclusion","title":"Conclusion","text":"<p>In conclusion, Azure Policy, policies, and initiatives are fundamental components of Azure's governance framework. They enable organizations to define and enforce rules for Azure resources, ensuring adherence to compliance standards, security protocols, and operational guidelines. By leveraging these capabilities, Azure users can maintain control over their cloud environment while promoting consistency and security across deployments. If you're looking to enhance governance and compliance within Azure, exploring Azure Policy, policies, and initiatives is a crucial step forward.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/24/azure-policy/#references","title":"References","text":"<ul> <li>Azure Policy overview</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/azure-policy-defintion-schema/","title":"Azure Policy, defintion schema","text":"<p>This is the schema for the Azure Policy definition:</p> <pre><code>{\n    \"properties\": {\n        \"displayName\": {\n            \"type\": \"string\",\n            \"description\": \"The display name of the policy definition.\"\n        },\n        \"policyType\": {\n            \"type\": \"string\",\n            \"description\": \"The policy type of the policy definition.\"\n        },\n        \"mode\": {\n            \"type\": \"string\",\n            \"description\": \"The mode of the policy definition.\"\n        },\n        \"description\": {\n            \"type\": \"string\",\n            \"description\": \"The description of the policy definition.\"\n        },\n        \"mode\": {\n            \"type\": \"string\",\n            \"description\": \"The mode of the policy definition.\"\n        },\n        \"metadata\": {\n            \"type\": \"object\",\n            \"description\": \"The metadata of the policy definition.\"\n        },\n        \"parameters\": {\n            \"type\": \"object\",\n            \"description\": \"The parameters of the policy definition.\"\n        },\n        \"policyRule\": {\n            \"type\": \"object\",\n            \"description\": \"The policy rule of the policy definition. If/then rule.\"\n        }       \n\n    }\n}\n</code></pre> <p>You can see other elements in the schema like id, type, and name, It's depens of how you want to deploy the policy definition.</p> <p>Full schema is in Azure Policy definition schema.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/azure-policy-defintion-schema/#example","title":"Example","text":"<p>Here is an example of a policy definition:</p> <pre><code>{\n    \"properties\": {\n        \"displayName\": \"Require a tag and its value\",\n        \"policyType\": \"Custom\",\n        \"mode\": \"Indexed\",\n        \"description\": \"This policy requires a specific tag and its value.\",\n        \"metadata\": {\n            \"category\": \"Tags\"\n        },\n        \"parameters\": {\n            \"tagName\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Name\",\n                    \"description\": \"Name of the tag, such as 'environment'\"\n                }\n            },\n            \"tagValue\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Value\",\n                    \"description\": \"Value of the tag, such as 'production'\"\n                }\n            }\n        },\n        \"policyRule\": {\n            \"if\": {\n                \"field\": \"[concat('tags[', parameters('tagName'), ']')]\",\n                \"exists\": \"false\"\n            },\n            \"then\": {\n                \"effect\": \"deny\"\n            }\n        }\n    }\n}\n</code></pre> <p>This policy definition requires a specific tag and its value. If the tag does not exist, the policy denies the action.</p> <p>How you can see, the most important part of the policy definition is the policy rule. </p> <p>Note</p> <p>The policy rule is where you describe the logic that enforces the policy.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/azure-policy-defintion-schema/#conclusion","title":"Conclusion","text":"<p>Understanding the schema for Azure Policy definitions is essential for creating and managing policies effectively. By defining the necessary attributes and rules, you can enforce compliance, security, and operational standards across your Azure environment. Leveraging the Azure Policy definition schema allows you to tailor policies to your organization's specific requirements and ensure consistent governance practices.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/azure-policy-defintion-schema/#references","title":"References","text":"<ul> <li>Azure Policy definition schema</li> <li>Azure Policy</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/26/writing-your-first-policy-in-azure-with-portal/","title":"Writing Your First Policy in Azure with Portal","text":"<p>Azure Policy is a service in Azure that you use to create, assign and manage policies. These policies enforce different rules and effects over your resources, so those resources stay compliant with your corporate standards and service level agreements.</p> <p>In this post, we'll walk through the steps of creating your first policy in Azure.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/26/writing-your-first-policy-in-azure-with-portal/#prerequisites","title":"Prerequisites","text":"<ol> <li>An active Azure subscription.</li> <li>Access to Azure portal.</li> </ol>","tags":["Azure Policy"]},{"location":"blog/2024/02/26/writing-your-first-policy-in-azure-with-portal/#step-1-open-azure-policy","title":"Step 1: Open Azure Policy","text":"<ul> <li>Login to the Azure Portal.</li> <li>In the left-hand menu, click on <code>All services</code>.</li> <li>In the <code>All services</code> blade, search for <code>Policy</code>.</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/26/writing-your-first-policy-in-azure-with-portal/#step-2-create-a-new-policy-definition","title":"Step 2: Create a New Policy Definition","text":"<ul> <li>Click on <code>Definitions</code> under the <code>Authoring</code> section.</li> <li>Click on <code>+ Policy definition</code>.</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/26/writing-your-first-policy-in-azure-with-portal/#step-3-fill-out-the-policy-definition","title":"Step 3: Fill Out the Policy Definition","text":"<p>You will need to fill out several fields:</p> <ul> <li>Definition location: The location where the policy is stored.</li> <li>Name: This is a unique name for your policy.</li> <li>Description: A detailed description of what the policy does.</li> <li>Category: You can categorize your policy for easier searching and filtering.</li> </ul> <p>The most important part of the policy definition is the policy rule itself. The policy rule is where you describe the logic that enforces the policy. </p> <p>Here's an example of a simple policy rule that ensures all indexed resources have tags and deny creation or update if they do not.</p> <pre><code>{\n    \"properties\": {\n        \"displayName\": \"Require a tag and its value\",\n        \"policyType\": \"Custom\",\n        \"mode\": \"Indexed\",\n        \"description\": \"This policy requires a specific tag and its value.\",\n        \"metadata\": {\n            \"category\": \"Tags\"\n        },\n        \"parameters\": {\n            \"tagName\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Name\",\n                    \"description\": \"Name of the tag, such as 'environment'\"\n                }\n            },\n            \"tagValue\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Value\",\n                    \"description\": \"Value of the tag, such as 'production'\"\n                }\n            }\n        },\n        },\n        \"policyRule\": {\n            \"if\": {\n                \"not\": {\n                    \"field\": \"[concat('tags[', parameters('tagName'), ']')]\",\n                    \"equals\": \"[parameters('tagValue')]\"\n                    }\n                },\n            \"then\": {\n                \"effect\": \"deny\"\n            }\n        }\n    }\n</code></pre> <p>But, in portal, you can add properties directly in the form but you can't add displayName, policyType and metadata because they are added by portal itself, so you can add only mode,parameters and policyRule, Policy definition could be like this:</p> <ul> <li>Definition location: <code>Tenant Root Group</code></li> <li>Name: <code>Require a tag and its value</code></li> <li>Description: <code>This policy requires a specific tag and its value.</code></li> <li>Category: <code>Tags</code></li> <li>POLICY RULE:</li> </ul> <pre><code>{\n\n        \"mode\": \"Indexed\", \n        \"parameters\": {\n            \"tagName\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Name\",\n                    \"description\": \"Name of the tag, such as 'environment'\"\n                }\n            },\n            \"tagValue\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Value\",\n                    \"description\": \"Value of the tag, such as 'production'\"\n                }\n            }\n        },\n        \"policyRule\": {\n            \"if\": {\n                \"not\": {\n                    \"field\": \"[concat('tags[', parameters('tagName'), ']')]\",\n                    \"equals\": \"[parameters('tagValue')]\"\n                    }\n                },\n            \"then\": {\n                \"effect\": \"deny\"\n            }\n        }\n}\n</code></pre> <p>Once you've filled out all the fields and written your policy rule, click on <code>Save</code>.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/26/writing-your-first-policy-in-azure-with-portal/#step-4-assign-the-policy","title":"Step 4: Assign the Policy","text":"<ul> <li>Go back to the <code>Policy</code> service in the Azure portal.</li> <li>Click on <code>Assignments</code> under the <code>Authoring</code> section.</li> <li>Click on <code>+ Assign Policy</code>.</li> <li>In Basics, fill out the following fields:<ul> <li>Scope<ul> <li>Scope: Select the scope where you want to assign the policy.</li> <li>Exclusions: Add any exclusions if needed.</li> </ul> </li> <li>Basics<ul> <li>Policy definition: Select the policy you created.</li> <li>Assignment name: A unique name for the assignment.</li> <li>Description: A detailed description of the assignment.</li> <li>Policy enforcement: <code>Enabled</code>.</li> </ul> </li> </ul> </li> <li>In Parameters: Fill out any parameters needed for the policy.</li> <li>In Non-compliance message: A message to display when a resource is non-compliant.</li> <li>Click on <code>Review + create</code>: Review the assignment and click on <code>Create</code>.</li> </ul> <p>Congratulations! You've just created and assigned your first policy in Azure. It will now evaluate any new or existing resources within its scope.</p> <p>Remember, Azure Policy is a powerful tool for maintaining compliance and managing your resources at scale. Happy coding!</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/","title":"Writing Your First Initiative with Portal","text":"<p>Azure Policy is a service in Azure that you use to create, assign and manage policies. These policies enforce different rules and effects over your resources, so those resources stay compliant with your corporate standards and service level agreements.</p> <p>In this post, we'll walk through the steps of creating your first initiative in Azure.</p> <p>Info</p> <p>You need to have a good understanding of Azure Policy before creating an initiative. If you're new to Azure Policy, check out our post on Azure Policy and Writing Your First Policy in Azure with Portal.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/#prerequisites","title":"Prerequisites","text":"<ol> <li>An active Azure subscription.</li> <li>Access to Azure portal.</li> <li>Azure Policy defined in your subscription, if you don't have one, you can follow the steps in Writing Your First Policy in Azure with Portal.</li> </ol>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/#step-1-open-azure-policy","title":"Step 1: Open Azure Policy","text":"<ul> <li>Login to the Azure Portal.</li> <li>In the left-hand menu, click on <code>All services</code>.</li> <li>In the <code>All services</code> blade, search for <code>Policy</code>.</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/#step-2-create-a-new-initiative-definition","title":"Step 2: Create a New Initiative Definition","text":"<ul> <li>Click on <code>Defitinions</code> under the <code>Authoring</code> section.</li> <li>Click on <code>+ Initiative definition</code>.</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/#step-3-fill-out-the-initiative-definition","title":"Step 3: Fill Out the Initiative Definition","text":"<p>You will need to fill out several fields:</p> <ul> <li>Basics:</li> <li>Initiative location: The location where the initiative is stored.</li> <li>Name: This is a unique name for your initiative.</li> <li>Description: A detailed description of what the initiative does.</li> <li>Category: You can categorize your initiative for easier searching and filtering.</li> <li>Policies:</li> <li>Add policy definition(s): Here you can add the policies that will be part of the initiative.</li> <li>Initiative parameters:</li> <li>Add parameter: Here you can add parameters that will be used in the initiative.   </li> <li>Policy parameters:</li> <li> <p>Add policy parameter: Here you can add parameters that will be used in the policies that are part of the initiative. You can use the parameters defined in the initiative as value for different policies.   </p> </li> <li> <p>Click on <code>Review + create</code>: Review the assignment and click on <code>Create</code>.</p> </li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/#step-4-assign-the-initiative","title":"Step 4: Assign the Initiative","text":"<ul> <li>Go to <code>Policy</code> again.</li> <li>Go to <code>Assignments</code> under the <code>Authoring</code> section.</li> <li>Click on <code>+ Assign initiative</code>.</li> </ul> <p>You will need to fill out several fields: - Basics:   - Scope: Select the scope where you want to assign the initiative.   - Basics:      - Initiative definition: Select the initiative you just created.     - Assignment name: A unique name for the assignment.     - Description: A detailed description of what the assignment does.     - Policy enforcement: Choose the enforcement mode for the assignment. - Parameters:   - Add parameter: Initialize parameters that will be used in the  initiative. - Remediation:    - Auto-remediation: Enable or disable auto-remediation. That means that if a resource is not compliant, it will be remediated automatically. In other post it will be explained how to create a remediation task. - Non-compliance messages:   - Non-compliance message: Define a message that will be shown when a resource is not compliant.</p> <ul> <li>Click on <code>Review + create</code>: Review the assignment and click on <code>Create</code>.</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/25/writing-your-first-initiative-with-portal/#conclusion","title":"Conclusion","text":"<p>Creating an initiative in Azure Policy is a powerful way to group policies together and enforce them across your Azure environment. By defining initiatives, you can streamline governance, simplify compliance management, and ensure consistent application of policies to your resources. Start creating initiatives today to enhance the security, compliance, and operational efficiency of your Azure environment.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/","title":"Manage Azure Policy GitHub Action","text":"<p>It's recommended to review:</p> <ul> <li>Azure Policy</li> <li>Writing Your First Policy in Azure with Portal</li> <li>Writing Your First Initiative in Azure with Portal</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#overview","title":"Overview","text":"<p>The Manage Azure Policy GitHub Action empowers you to enforce organizational standards and assess compliance at scale using Azure policies. With this action, you can seamlessly integrate policy management into your CI/CD pipelines, ensuring that your Azure resources adhere to the desired policies.</p> <p>Info</p> <p>This project does not have received any updates since some time, but it is still a simple option to develop your Azure Policies. As everything cannot be good to say that this deployment method has a major drawback, deletions must be done by hand :S</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#key-features","title":"Key Features","text":"<ol> <li> <p>Customizable Workflows: GitHub workflows are highly customizable. You have complete control over the sequence in which Azure policies are rolled out. This flexibility enables you to follow safe deployment practices and catch regressions or bugs well before policies are applied to critical resources.</p> </li> <li> <p>Azure Login Integration: The action assumes that you've already authenticated using the Azure Login action. Make sure you've logged in using an Azure service principal with sufficient permissions to write policies on selected scopes. Refer to the full documentation of Azure Login Action for details on permissions.</p> </li> <li> <p>Policy File Structure: Your policy files should be organized in a specific directory structure within your GitHub repository. Here's how it should look:</p> <pre><code>|- policies/\n   |- &lt;policy1_name&gt;/\n      |- policy.json\n      |- assign.&lt;name1&gt;.json\n      |- assign.&lt;name2&gt;.json\n      ...\n   |- &lt;policy2_name&gt;/\n      |- policy.json\n      |- assign.&lt;name1&gt;.json\n      |- assign.&lt;name2&gt;.json\n      ...\n</code></pre> <ul> <li>Each policy resides in a subfolder under the <code>policies/</code> directory.</li> <li>The <code>policy.json</code> file contains the policy definition.</li> <li>Assignment files (e.g., <code>assign.&lt;name1&gt;.json</code>) specify how the policy is applied.</li> </ul> </li> <li> <p>Inputs for the Action:</p> <ul> <li>Paths: Specify the mandatory path(s) to the directory containing your Azure policy files.</li> </ul> </li> </ol>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#sample-workflow","title":"Sample Workflow","text":"<p>Here's an example of how you can apply policies at the Management Group scope using the Manage Azure Policy action:</p> <pre><code>name: 'Test Policy'\non:\n  push:\n    branches: \n    - \"*\" \n    paths: \n     - 'policies/**'\n     - 'initiatives/**'\n  workflow_dispatch:\n\njobs:\n  apply-azure-policy:    \n    runs-on: ubuntu-latest\n    steps:\n    # Azure Login\n    - name: Login to Azure\n      uses: azure/login@v1\n      with:\n        creds: ${{ secrets.AZURE_CREDENTIALS }}\n        allow-no-subscriptions: true\n\n    - name: Checkout\n      uses: actions/checkout@v2 \n\n    - name: Create or Update Azure Policies\n      uses: azure/manage-azure-policy@v0\n      with:      \n        paths:  |                \n          policies/**\n          initiatives/**\n        assignments:  |\n          assign.*_testRG_*.json\n</code></pre> <p>Remember to replace the placeholder values (such as <code>secrets.AZURE_CREDENTIALS</code>) with your actual configuration, you can follow this instructions to create a service principal and get the credentials: Create a service principal and get the credentials</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#example-of-use-for-policy","title":"Example of use for Policy","text":"<p>In this example we define all our policies and initiatives at management group level and assign to resource group, and we have a policy that requires a specific tag and its value.</p> <p>You need to create a folder structure like this:</p> <pre><code>|- policies/\n   |- require-tag-and-its-value/\n      |- policy.json\n      |- assign.testRG_testazurepolicy.json\n|- initiatives/\n   |- initiative1/\n      |- policyset.json\n      |- assign.testRG_testazurepolicy.json\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#policies","title":"policies","text":"<p>Info</p> <ul> <li>The <code>policy.json</code> file contains the policy definition, and the <code>assign.&lt;name&gt;.json</code> file specifies how the policy is applied.  </li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#policyjson","title":"policy.json","text":"<p>Info</p> <ul> <li>The <code>id</code> value specifies where you are going to define the policy.</li> </ul> policy.json<pre><code>{\n    \"id\": \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000/providers/Microsoft.Authorization/policyDefinitions/requite-tag-and-its-value\",\n    \"type\": \"Microsoft.Authorization/policyDefinitions\",\n    \"name\": \"requite-tag-and-its-value\",\n    \"properties\": {\n        \"displayName\": \"Require a tag and its value\",\n        \"policyType\": \"Custom\",\n        \"mode\": \"Indexed\",\n        \"description\": \"This policy requires a specific tag and its value.\",\n        \"metadata\": {\n            \"category\": \"Tags\"\n        },\n        \"parameters\": {\n            \"tagName\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Name\",\n                    \"description\": \"Name of the tag, such as 'environment'\"\n                }\n            },\n            \"tagValue\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Value\",\n                    \"description\": \"Value of the tag, such as 'production'\"\n                }\n            }\n        }\n        },\n        \"policyRule\": {\n            \"if\": {\n                \"not\": {\n                    \"field\": \"[concat('tags[', parameters('tagName'), ']')]\",\n                    \"equals\": \"[parameters('tagValue')]\"\n                    }\n                },\n            \"then\": {\n                \"effect\": \"deny\"\n            }\n        }\n    }\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#assigntestrg_testazurepolicyjson","title":"assign.testRG_testazurepolicy.json","text":"<p>Info</p> <ul> <li>Change the <code>id</code> and <code>scope</code> values in the <code>assign.&lt;name&gt;.json</code> file to match your Azure subscription and resource group.</li> <li>id specifies where you are going to deploy the assignment.</li> <li>id and name are related, name can not be any value, it should be the same as the last part of the id. You can generete a new GUID and use it as name with (1..24 | %{ '{0:x}' -f (Get-Random -Max 16) }) -join ''</li> <li>name and id are related.</li> <li>The <code>policyDefinitionId</code> value should match the <code>id</code> value in the <code>policy.json</code> file.</li> </ul> assign.testRG_testazurepolicy.json<pre><code>{\n    \"id\": \"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-testazurepolicy/providers/Microsoft.Authorization/policyAssignments/599a2c3a1a3b1f8b8e547b3e\",\n    \"type\": \"Microsoft.Authorization/policyAssignments\",\n    \"name\": \"599a2c3a1a3b1f8b8e547b3e\",     \n    \"properties\": {\n        \"description\": \"This policy audits the presence of a specific tag and its value.\",\n        \"displayName\": \"Require a tag and its value\",\n        \"parameters\": {\n            \"tagName\": {\n              \"value\": \"environment\"\n            },\n            \"tagValue\": {\n              \"value\": \"production\"\n            }\n          },\n          \"nonComplianceMessages\": [\n            {\n              \"message\": \"This resource is not compliant with the policy. Please apply the required tag and its value.\"\n            }\n          ],\n          \"enforcementMode\": \"Default\",\n          \"policyDefinitionId\": \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000/providers/Microsoft.Authorization/policyDefinitions/requite-tag-and-its-value\",\n          \"scope\": \"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-testazurepolicy\"\n    }    \n}\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#initiatives","title":"initiatives","text":"<p>Info</p> <ul> <li>The <code>policyset.json</code> file contains the policy definition, and the <code>assign.&lt;name&gt;.json</code> file specifies how the initiative is applied.</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#policysetjson","title":"policyset.json","text":"<p>Info</p> <ul> <li>The <code>id</code> value specifies where you are going to define the initiative.</li> <li>The <code>policyDefinitions</code> array contains the policy definitions that are part of the initiative.</li> <li>The <code>parameters</code> object defines the parameters that can be passed to the policies within the initiative.</li> <li>The <code>policyDefinitionId</code> value should match the <code>id</code> value in the <code>policy.json</code> file of the policy.</li> </ul> policyset.json<pre><code>{\n    \"id\": \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000/providers/Microsoft.Authorization/policySetDefinitions/initiative1\",\n    \"type\": \"Microsoft.Authorization/policySetDefinitions\",\n    \"name\": \"initiative1\",\n    \"properties\": {\n        \"displayName\": \"Initiative 1\",\n        \"description\": \"This initiative contains a set of policies for testing.\",\n        \"metadata\": {\n            \"category\": \"Test\"\n        },\n        \"parameters\": {\n            \"tagName\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Name\",\n                    \"description\": \"Name of the tag, such as 'environment'\"\n                }\n            },\n            \"tagValue\": {\n                \"type\": \"String\",\n                \"metadata\": {\n                    \"displayName\": \"Tag Value\",\n                    \"description\": \"Value of the tag, such as 'production'\"\n                }\n            }\n        },\n        \"policyDefinitions\": [\n            {\n                \"policyDefinitionId\": \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000/providers/Microsoft.Authorization/policyDefinitions/requite-tag-and-its-value\",\n                \"parameters\": {\n                    \"tagName\": {\n                        \"value\": \"[parameters('tagName')]\"\n                    },\n                    \"tagValue\": {\n                        \"value\": \"[parameters('tagValue')]\"\n                    },\n                    \"effect\": {\n                        \"value\": \"Deny\"\n                    }\n                }\n            }\n        ]\n    }\n}\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#assigntestrg_testazurepolicysetjson","title":"assign.testRG_testazurepolicyset.json","text":"assign.testRG_testazurepolicyset.json<pre><code>{\n    \"id\": \"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-testazurepolicy/providers/Microsoft.Authorization/policyAssignments/ada0f4a34b09cf6ad704cc62\",\n    \"type\": \"Microsoft.Authorization/policyAssignments\",\n    \"name\": \"ada0f4a34b09cf6ad704cc62\",     \n    \"properties\": {\n        \"description\": \"This initiative audits the presence of a specific tag and its value.\",\n        \"displayName\": \"Require a tag and its value\",\n        \"parameters\": {\n            \"tagName\": {\n              \"value\": \"environment\"\n            },\n            \"tagValue\": {\n              \"value\": \"production\"\n            }\n          },\n          \"nonComplianceMessages\": [\n            {\n              \"message\": \"This resource is not compliant with the policy. Please apply the required tag and its value.\"\n            }\n          ],\n          \"enforcementMode\": \"Default\",\n          \"policyDefinitionId\": \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000/providers/Microsoft.Authorization/policySetDefinitions/requite-tag-and-its-value\",\n          \"scope\": \"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg-testazurepolicy\"\n    }    \n}\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/02/28/manage-azure-policy-github-action/#conclusion","title":"Conclusion","text":"<p>By incorporating the Manage Azure Policy action into your GitHub workflows, you can seamlessly enforce policies, maintain compliance, and ensure the robustness of your Azure resources, although it has its drawbacks, it is one more step compared to a portal. Later we will see the deployment with a more robust tool: EPAC</p> <p>Learn more about Azure Policies and explore the action on the GitHub Marketplace.</p>","tags":["Azure Policy"]},{"location":"blog/2024/02/29/enterprise-azure-policy-as-code-epac/","title":"Enterprise Azure Policy as Code (EPAC)","text":"<p>Enterprise Azure Policy as Code (EPAC) is a powerful tool that allows organizations to manage Azure Policies as code in a git repository. It's designed for medium and large organizations with a larger number of Policies, Policy Sets, and Assignments, and/or complex deployment scenarios.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/02/29/enterprise-azure-policy-as-code-epac/#key-features-of-epac","title":"Key Features of EPAC","text":"<ul> <li>Single and multi-tenant policy deployment: EPAC supports both single and multi-tenant policy deployments, making it versatile for different organizational structures.</li> <li>Easy CI/CD Integration: EPAC can be easily integrated with any CI/CD tool, which makes it a great fit for DevOps environments.</li> <li>Operational scripts: EPAC includes operational scripts to simplify operational tasks.</li> <li>Integration with Azure Landing Zones: EPAC provides a mature integration with Azure Landing Zones. Utilizing Azure Landing Zones together with EPAC is highly recommended.</li> </ul>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/02/29/enterprise-azure-policy-as-code-epac/#who-should-use-epac","title":"Who Should Use EPAC?","text":"<p>EPAC is designed for medium and large organizations with a larger number of Policies, Policy Sets, and Assignments, and/or complex deployment scenarios. However, smaller organizations implementing fully-automated DevOps deployments of every Azure resource (known as Infrastructure as Code) can also benefit from EPAC.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/02/29/enterprise-azure-policy-as-code-epac/#how-does-epac-work","title":"How Does EPAC Work?","text":"<p>EPAC works by deploying all policies and policy assignments defined in the EPAC repository to the deploymentRootScope and its children. It takes possession of all Policy Resources at the deploymentRootScope and its children.</p> <p></p> <p>The process depicted in the image involves three key scripts that manage a deployment sequence. Here's a breakdown of the process:</p> <ol> <li> <p>Definition Files: The process begins with various definition files in JSON, CSV, or XLSX formats. These files contain policy definitions, policy set (initiative) definitions, assignments, exemptions, and global settings.</p> </li> <li> <p>Planning Script: The <code>Build-DeploymentPlans.ps1</code> script uses these definition files to create a deployment plan. This script requires Resource Policy Reader privileges.</p> </li> <li> <p>Deployment Scripts: The deployment plan is then used by two deployment scripts:</p> </li> <li><code>Deploy-PolicyPlan.ps1</code>: This script deploys Policy resources using the <code>policy-plan.json</code> file from the deployment plan. It requires Resource Policy Contributor privileges.</li> <li><code>Deploy-RolesPlan.ps1</code>: This script deploys Role Assignments using the <code>roles-plan.json</code> file from the deployment plan. It requires User Access Administrator privileges.</li> </ol> <p>The process includes optional approval gates after each deployment step. These are typically used in production environments to ensure each deployment step is reviewed and approved before moving to the next.</p> <p>Warning</p> <p>EPAC is a true desired state deployment technology. It takes possession of all Policy Resources at the deploymentRootScope and its children. It will delete any Policy resources not defined in the EPAC repo.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/02/29/enterprise-azure-policy-as-code-epac/#conclusion","title":"Conclusion","text":"<p>EPAC is a robust solution for managing Azure Policies as code. It offers a high level of assurance in highly controlled and sensitive environments, and a means for the development, deployment, management, and reporting of Azure policy at scale. </p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/02/29/enterprise-azure-policy-as-code-epac/#references","title":"References","text":"<ul> <li>EPAC Documentation</li> </ul>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/03/02/azure-policy-management-best-practices/","title":"Azure Policy Management Best Practices","text":"<ol> <li> <p>Version Control: Store your policy definitions in a version-controlled repository. This practice ensures that you can track changes, collaborate effectively, and roll back to previous versions if needed.</p> </li> <li> <p>Automated Testing: Incorporate policy testing into your CI/CD pipelines. Automated tests can help you catch policy violations early in the development process, reducing the risk of non-compliance.</p> </li> <li> <p>Policy Documentation: Document your policies clearly, including their purpose, scope, and expected behavior. This documentation helps stakeholders understand the policies and their impact on Azure resources.</p> </li> <li> <p>Policy Assignment: Assign policies at the appropriate scope (e.g., Management Group, Subscription, Resource Group) based on your organizational requirements. Avoid assigning policies at a broader scope than necessary to prevent unintended consequences.</p> </li> <li> <p>Policy Exemptions: Use policy exemptions judiciously. Document the reasons for exemptions and periodically review them to ensure they are still valid.</p> </li> <li> <p>Policy Enforcement: Monitor policy compliance regularly and take corrective action for non-compliant resources. Use Azure Policy's built-in compliance reports and alerts to track policy violations.</p> </li> <li> <p>Policy Remediation: Implement automated remediation tasks for policy violations where possible. Azure Policy's remediation tasks can help bring non-compliant resources back into compliance automatically.</p> </li> <li> <p>Policy Monitoring: Continuously monitor policy effectiveness and adjust policies as needed. Regularly review policy violations, exemptions, and compliance trends to refine your policy implementation.</p> </li> <li> <p>Policy Governance: Establish a governance framework for Azure Policy that includes policy creation, assignment, monitoring, and enforcement processes. Define roles and responsibilities for policy management to ensure accountability.</p> </li> <li> <p>Policy Lifecycle Management: Define a policy lifecycle management process that covers policy creation, testing, deployment, monitoring, and retirement. Regularly review and update policies to align with changing organizational requirements.</p> </li> <li> <p>Unique source of truth: Use EPAC, terraform, ARM,.... but use an unique source of truth for your policies.</p> </li> </ol> <p>By following these best practices, you can effectively manage Azure policies and ensure compliance with organizational standards across your Azure environment. Azure Policy plays a crucial role in maintaining governance, security, and compliance, and adopting these practices can help you maximize its benefits.</p>","tags":["Azure Policy"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/","title":"Privileged Access Management (PAM) Strategy with Microsoft Entra ID and some Azure Services","text":"<p>Today, I'd like to share a brief of a recommended strategy for Privileged Access Management (PAM) of other vendors with Microsoft Entra ID and some Azure Services. This strategy is divided into seven phases:</p> <pre><code>\ngraph LR;\n    A[Phase 1: Set Policy] \n    C[Phase 2: The Process of Discovery]\n    E[Phase 3: Protect Credentials]\n    G[Phase 4: Secure Privileged Access]\n    I[Phase 5: Least Privilege]\n    K[Phase 6: Control All Applications]\n    M[Phase 7: Detect and Respond]\n\n    A--&gt;C\n    C--&gt;E\n    E--&gt;G\n    G--&gt;I\n    I--&gt;K\n    K--&gt;M\n    M--&gt;A\n\n    classDef phase fill:#f9f,stroke:#333,stroke-width:2px;\n    class A,C,E,G,I,K,M phase;\n\n\n</code></pre> <p>Info</p> <p>Be hybrid, be secure with a single control plane, use Azure ARC to inherit the same security and compliance policies across your on-premises, multi-cloud, and edge environments as in Azure.</p>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-1-set-policy","title":"Phase 1: Set Policy","text":"<p>The first step in any PAM strategy is to establish a clear policy. This policy should define who has access to what, when they have access, and what they can do with that access. It should also include guidelines for password management and multi-factor authentication. For example:</p> <ul> <li>Define clear access control policies.</li> <li>Establish guidelines for password management and multi-factor authentication.</li> <li>Regularly review and update the policy to reflect changes in the organization.</li> </ul> <p>How to implement this:</p> <ul> <li>Use Azure Policy to define and manage policies for your Azure environment.</li> <li>Use Microsoft Entra multifactor authentication for implementing multi-factor authentication.</li> </ul>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-2-the-process-of-discovery","title":"Phase 2: The Process of Discovery","text":"<p>In this phase, we identify all the privileged accounts across the organization. This includes service accounts, local administrative accounts, domain administrative accounts, emergency accounts, and application accounts. For example:</p> <ul> <li>Use automated tools to identify all privileged accounts across the organization.</li> <li>Regularly update the inventory of privileged accounts.</li> <li>Identify any accounts that are no longer in use and deactivate them.</li> </ul> <p>How to implement this:</p> <ul> <li>Use Microsoft Entra Privileged Identity Management to discover, restrict and monitor administrators and their access to resources and provide just-in-time access when needed.</li> </ul>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-3-protect-credentials","title":"Phase 3: Protect Credentials","text":"<p>Once we've identified all privileged accounts, we need to ensure that these credentials are stored securely. This could involve using a secure vault, regularly rotating passwords, and using unique passwords for each account. For example:</p> <ul> <li>Store credentials in a secure vault.</li> <li>Implement regular password rotation.</li> <li>Use unique passwords for each account.</li> </ul> <p>How to implement this:</p> <ul> <li>Use Azure Key Vault to safeguard cryptographic keys and other secrets used by your apps and services and rotate secrets regularly.</li> <li>Implement Microsoft Entra ID Password Protection to protect against weak passwords that can be easily guessed or cracked.</li> </ul>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-4-secure-privileged-access","title":"Phase 4: Secure Privileged Access","text":"<p>Securing privileged access involves implementing controls to prevent unauthorized access. This could include limiting the number of privileged accounts, implementing least privilege, and using just-in-time access. For example:</p> <ul> <li>Limit the number of privileged accounts.</li> <li>Implement just-in-time access, where access is granted only for the duration of a task.</li> <li>Use session recording and monitoring for privileged access.</li> </ul> <p>How to implement this:</p> <ul> <li>Use Microsoft Entra ID Conditional Access to enforce controls on the access to apps in your environment based on specific conditions.</li> <li>Implement Microsoft Entra Privileged Identity Management for just-in-time access.</li> </ul>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-5-least-privilege","title":"Phase 5: Least Privilege","text":"<p>The principle of least privilege involves giving users the minimum levels of access \u2014 or permissions \u2014 they need to complete their job functions. By limiting the access rights of users, the risk of a security breach is reduced. For example:</p> <ul> <li>Implement role-based access control (RBAC) in Azure to grant the minimum necessary access to users.</li> <li>Regularly review user roles and access rights.</li> <li>Implement a process for revoking access when it's no longer needed.</li> </ul> <p>How to implement this:</p> <ul> <li>Implement Role-Based Access Control (RBAC) in Azure to grant the minimum necessary access to users.</li> <li>Use Microsoft Entra ID Access Reviews to efficiently manage group memberships, access to enterprise applications, and role assignments.</li> </ul>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-6-control-all-applications","title":"Phase 6: Control All Applications","text":"<p>In this phase, we ensure that all applications, whether on-premises or in the cloud, are controlled and monitored. This includes implementing application control policies and monitoring application usage. For example:</p> <ul> <li>Implement application control policies that dictate what applications can be run on systems.</li> <li>Monitor application usage and block unauthorized applications.</li> <li>Regularly update and patch all applications to reduce vulnerabilities.</li> </ul> <p>How to implement this:</p> <ul> <li>Use Microsoft Entra Application Proxy to control and secure access to on-premises and cloud apps.</li> <li>Enable Change Tracking and Inventory in Azure Automation to track changes to your Azure VMs. Use desired state configuration to ensure that your VMs are configured correctly.</li> <li>Implement Microsoft Intune to manage and secure your devices and applications.</li> </ul>","tags":["Security","PAM"]},{"location":"blog/2024/04/04/privileged-access-management-pam-strategy-with-microsoft-entra-id-and-some-azure-services/#phase-7-detect-and-respond","title":"Phase 7: Detect and Respond","text":"<p>The final phase involves setting up systems to detect and respond to any suspicious activity. This could involve setting up alerts for unusual activity, regularly auditing access logs, and having a response plan in place for when a breach occurs. For example:</p> <ul> <li>Set up alerts for unusual activity.</li> <li>Regularly audit access logs.</li> <li>Have a response plan in place for when a breach occurs, including steps for containment, eradication, and recovery.</li> </ul> <p>How to implement this:</p> <ul> <li>Use Microsoft Defender for Cloud for increased visibility into your security state and to detect and respond to threats.</li> <li>Implement Azure Sentinel, Microsoft's cloud-native SIEM solution, for intelligent security analytics.</li> </ul> <p>By following these seven phases, you can create a robust PAM strategy that protects your organization from security breaches and helps you maintain compliance with various regulations.</p> <p>Remember, a good PAM strategy is not a one-time effort but an ongoing process that needs to be regularly reviewed and updated. Microsoft and Azure services provide a robust set of tools to help you implement and manage your PAM strategy effectively.</p>","tags":["Security","PAM"]},{"location":"blog/2024/04/05/microsoft-azure-certifications/","title":"Microsoft Azure Certifications","text":"<p>Microsoft offers a wide range of certifications for IT professionals who want to demonstrate their expertise in Microsoft technologies. These certifications cover a variety of topics, including Azure, Office 365, Windows Server, and more.</p> <p>Microsoft divide this certifications into different categories, such as:</p> <ul> <li>Infrastructure</li> <li>Data and AI</li> <li>Digital app and innovation</li> <li>Modern work</li> <li>Business applications</li> <li>Security</li> </ul> <p>Inside of each category, you can find different certification levels:</p> <ul> <li>Fundamentals: This level is designed for individuals who are new to the technology and want to demonstrate their knowledge of the basics.</li> <li>Role-based: This level is designed for individuals who want to demonstrate their expertise in a specific role, such as Azure Administrator or Data Engineer.</li> <li>Specialty: This level is designed for individuals who want to demonstrate their expertise in a specific skill,  such as Azure Virtual Desktop or Azure SAP.</li> </ul> <p>In the case of role-based certifications, Microsoft offers different levels of certification, such as:</p> <ul> <li>Associate: This level is designed for individuals who have some experience in the technology and want to demonstrate their expertise in a specific role.</li> <li>Expert: This level is designed for individuals who have extensive experience in the technology and want to demonstrate their expertise in a specific role.</li> </ul> <p>Allways is a good idea to start with the fundamentals certifications, and then move on to the role-based certifications that are relevant to your career goals.</p> <p>In the majority of cases, you need associate certifications to get expert certifications.</p>","tags":["Certifications"]},{"location":"blog/2024/04/05/microsoft-azure-certifications/#azure-certifications","title":"Azure Certifications","text":"<p>Here's a table summarizing the Azure Certifications and their description:</p> Certification Exam required Description url Azure Administrator Associate AZ-104 The Azure Administrator certification is designed for individuals who want to demonstrate their expertise in managing Azure resources. This certification is ideal for IT professionals who are responsible for implementing, monitoring, and maintaining Azure solutions. https://learn.microsoft.com/en-us/certifications/azure-administrator Azure Developer Associate AZ-204 The Azure Developer certification is designed for individuals who want to demonstrate their expertise in developing applications on Azure. This certification is ideal for software developers who want to build and deploy cloud-based applications using Azure services. https://learn.microsoft.com/en-us/certifications/azure-developer Azure Data Engineer Associate DP-203 The Azure Data Engineer certification is designed for individuals who want to demonstrate their expertise in designing and implementing data solutions on Azure. This certification is ideal for data professionals who are responsible for building and maintaining data pipelines and data warehouses on Azure. https://learn.microsoft.com/en-us/certifications/azure-data-engineer Azure Database Administrator Associate DP-300 The Azure Database Administrator certification is designed for individuals who want to demonstrate their expertise in managing Azure databases. This certification is ideal for database administrators who are responsible for designing, implementing, and maintaining databases on Azure. https://learn.microsoft.com/en-us/certifications/azure-database-administrator DevOps Engineer Expert AZ-400 The Azure DevOps Engineer certification is designed for individuals who want to demonstrate their expertise in implementing DevOps practices on Azure. This certification is ideal for IT professionals who are responsible for building, testing, and deploying applications using Azure DevOps. https://learn.microsoft.com/en-us/certifications/devops-engineer Azure Security Engineer Associate AZ-500 The Azure Security Engineer certification is designed for individuals who want to demonstrate their expertise in securing Azure resources. This certification is ideal for IT professionals who are responsible for implementing security controls and monitoring security events on Azure. https://learn.microsoft.com/en-us/certifications/azure-security-engineer Azure Network Engineer Associate AZ-700 The Azure Network Engineer certification is designed for individuals who want to demonstrate their expertise in designing and implementing network solutions on Azure. This certification is ideal for network engineers who are responsible for building and maintaining network infrastructure on Azure. https://learn.microsoft.com/en-us/certifications/azure-network-engineer Windows Server Hybrid Administrator Associate AZ-800 AZ-801 The Windows Server Hybrid Administrator certification is designed for individuals who want to demonstrate their expertise in managing Windows Server resources on Azure. This certification is ideal for IT professionals who are responsible for implementing, monitoring, and maintaining Windows Server solutions on Azure. https://learn.microsoft.com/en-us/certifications/windows-server-hybrid-administrator Fabric Analytics Engineer Associate DP-600 The Fabric Analytics Engineer certification is designed for individuals who want to demonstrate their expertise in designing and implementing analytics solutions on Azure. This certification is ideal for data professionals who are responsible for building and maintaining analytics solutions on Azure. https://learn.microsoft.com/en-us/certifications/fabric-analytics-engineer Azure AI Engineer Associate AI-102 The Azure AI Engineer certification is designed for individuals who want to demonstrate their expertise in designing and implementing AI solutions on Azure. This certification is ideal for data scientists and AI developers who want to build and deploy AI models using Azure services. https://learn.microsoft.com/en-us/certifications/azure-ai-engineer Azure Data Scientist Associate DP-100 The Azure Data Scientist certification is designed for individuals who want to demonstrate their expertise in designing and implementing data science solutions on Azure. This certification is ideal for data scientists who are responsible for building and maintaining data science solutions on Azure. https://learn.microsoft.com/en-us/certifications/azure-data-scientist Azure Enterprise Data Analyst Associate DP-500 The Azure Enterprise Data Analyst certification is designed for individuals who want to demonstrate their expertise in designing and implementing data analysis solutions on Azure. This certification is ideal for data analysts who are responsible for building and maintaining data analysis solutions on Azure. https://learn.microsoft.com/en-us/certifications/azure-enterprise-data-analyst Azure Solutions Architect Expert AZ-305 The Azure Solutions Architect certification is designed for individuals who want to demonstrate their expertise in designing and implementing solutions on Azure. This certification is ideal for IT professionals who are responsible for designing and implementing cloud-based solutions using Azure services. https://learn.microsoft.com/en-us/certifications/azure-solutions-architect Azure for SAP Workloads Specialty AZ-120 The Azure for SAP Workloads certification is designed for individuals who want to demonstrate their expertise in deploying and managing SAP workloads on Azure. This certification is ideal for IT professionals who are responsible for implementing and maintaining SAP solutions on Azure. https://learn.microsoft.com/en-us/certifications/azure-for-sap-workloads Azure Virtual Desktop Specialty AZ-140 The Azure Virtual Desktop certification is designed for individuals who want to demonstrate their expertise in deploying and managing virtual desktop solutions on Azure. This certification is ideal for IT professionals who are responsible for implementing and maintaining virtual desktop solutions on Azure. https://learn.microsoft.com/en-us/certifications/azure-virtual-desktop Azure Cosmos DB Developer Specialty DP-420 The Azure Cosmos DB Developer certification is designed for individuals who want to demonstrate their expertise in developing applications that use Azure Cosmos DB. This certification is ideal for software developers who want to build and deploy applications that use Azure Cosmos DB. https://learn.microsoft.com/en-us/certifications/azure-cosmos-db-developer Azure Fundamentals AZ-900 The Azure Fundamentals certification is designed for individuals who are new to Azure and want to demonstrate their knowledge of the platform. This certification is a great starting point for anyone who wants to learn more about Azure and how it can help them build and deploy applications in the cloud. https://learn.microsoft.com/en-us/certifications/azure-fundamentals Azure AI Fundamentals AI-900 The Azure AI Fundamentals certification is designed for individuals who want to demonstrate their knowledge of AI concepts and how they can be applied to Azure services. This certification is ideal for anyone who wants to learn more about AI and how it can be used to build intelligent applications. https://learn.microsoft.com/en-us/certifications/azure-ai-fundamentals Azure Data Fundamentals DP-900 The Azure Data Fundamentals certification is designed for individuals who want to demonstrate their knowledge of data concepts and how they can be applied to Azure services. This certification is ideal for anyone who wants to learn more about data and how it can be used to build data-driven applications. https://learn.microsoft.com/en-us/certifications/azure-data-fundamentals <p>You can find more information about Microsoft certifications on the Microsoft Certification Poster and in the Microsoft Learning website.</p>","tags":["Certifications"]},{"location":"blog/2024/04/06/azure-arc/","title":"Azure ARC","text":"<p>Azure ARC is a service that extends Azure management capabilities to any infrastructure. It allows you to manage resources running on-premises, at the edge, or in multi-cloud environments using the same Azure management tools, security, and compliance policies that you use in Azure. Azure ARC enables you to manage and govern your resources consistently across all environments, providing a unified control plane for your hybrid cloud infrastructure. Let's explore how Azure ARC works and how you can leverage it to manage your resources effectively.</p>","tags":["Azure ARC"]},{"location":"blog/2024/04/06/azure-arc/#azure-arc-overview","title":"Azure ARC Overview","text":"<p>Azure ARC is a service that extends Azure management capabilities to any infrastructure. It allows you to manage resources running outside of Azure using the same Azure management tools, security, and compliance policies that you use in Azure. Azure ARC provides a unified control plane for managing resources across on-premises, multi-cloud, and edge environments, enabling you to govern your resources consistently.</p> <p>Azure ARC enables you to:</p> <ul> <li>Manage resources: Azure ARC allows you to manage resources running on-premises, at the edge, or in multi-cloud environments using Azure management tools like Azure Policy, Azure Monitor, and Microsoft Defender for Cloud.</li> <li>Governance: Azure ARC provides a unified control plane for managing and governing resources across all environments, enabling you to enforce security and compliance policies consistently.</li> <li>Security: Azure ARC extends Azure security capabilities to resources running outside of Azure, enabling you to protect your resources with Azure security features like Azure Security Center and Azure Defender.</li> <li>Compliance: Azure ARC enables you to enforce compliance policies across all environments, ensuring that your resources meet regulatory requirements and organizational standards.</li> </ul>","tags":["Azure ARC"]},{"location":"blog/2024/04/06/azure-arc/#azure-arc-components","title":"Azure ARC Components","text":"<p>Azure ARC consists of the following components:</p> <ul> <li>Azure ARC-enabled servers: Azure ARC-enabled servers allow you to manage and govern servers running on-premises or at the edge using Azure management tools. You can connect your servers to Azure ARC to manage them using Azure Policy, Azure Monitor, and Microsoft Defender for Cloud.</li> <li>Azure ARC-enabled Kubernetes clusters: Azure ARC-enabled Kubernetes clusters allow you to manage and govern Kubernetes clusters running on-premises or in other clouds using Azure management tools. You can connect your Kubernetes clusters to Azure ARC to manage them using Azure Policy, Azure Monitor, and Microsoft Defender for Cloud.</li> <li>Azure ARC-enabled data services: Azure ARC-enabled data services allow you to manage and govern data services running on-premises or in other clouds using Azure management tools. You can connect your data services to Azure ARC to manage them using Azure Policy, Azure Monitor, and Microsoft Defender for Cloud.</li> <li>SQL Server enabled by Azure Arc: SQL Server enabled by Azure Arc allows you to run SQL Server on any infrastructure using Azure management tools. You can connect your SQL Server instances to Azure ARC to manage them using Azure Policy, Azure Monitor, and Microsoft Defender for Cloud.</li> <li>Azure Arc-enabled private clouds: Azure Arc resource bridge hosts other components such as custom locations, cluster extensions, and other Azure Arc agents in order to deliver the level of functionality with the private cloud infrastructures it supports.</li> </ul>","tags":["Azure ARC"]},{"location":"blog/2024/04/06/azure-arc/#azure-arc-use-cases","title":"Azure ARC Use Cases","text":"<p>Azure ARC can be used in a variety of scenarios to manage and govern resources across on-premises, multi-cloud, and edge environments. Some common use cases for Azure ARC include:</p> <ul> <li>Hybrid cloud management: Azure ARC enables you to manage resources consistently across on-premises, multi-cloud, and edge environments using the same Azure management tools and policies.</li> <li>Security and compliance: Azure ARC allows you to enforce security and compliance policies consistently across all environments, ensuring that your resources meet regulatory requirements and organizational standards.</li> <li>Resource governance: Azure ARC provides a unified control plane for managing and governing resources across all environments, enabling you to enforce policies and monitor resource health and performance.</li> <li>Application modernization: Azure ARC enables you to manage and govern Kubernetes clusters and data services running on-premises or in other clouds, allowing you to modernize your applications and infrastructure.</li> </ul>","tags":["Azure ARC"]},{"location":"blog/2024/04/06/azure-arc/#getting-started-with-azure-arc","title":"Getting Started with Azure ARC","text":"<p>To get started with Azure ARC, you need to:</p> <ol> <li>Connect your resources: Connect your servers, Kubernetes clusters, or data services to Azure ARC using the Azure ARC agent.</li> <li>Manage your resources: Use Azure management tools like Azure Policy, Azure Monitor, and Microsoft Defender for Cloud to manage and govern your resources consistently across all environments.</li> <li>Enforce security and compliance: Use Azure security features like Microsoft Defender for Cloud to protect your resources and enforce security and compliance policies.</li> </ol> <p>By leveraging Azure ARC, you can manage and govern your resources consistently across on-premises, multi-cloud, and edge environments, providing a unified control plane for your hybrid cloud infrastructure. Azure ARC enables you to enforce security and compliance policies consistently, ensuring that your resources meet regulatory requirements and organizational standards. </p>","tags":["Azure ARC"]},{"location":"blog/2024/04/06/azure-arc/#conclusion","title":"Conclusion","text":"<p>Azure ARC is a powerful service that extends Azure management capabilities to any infrastructure, enabling you to manage and govern resources consistently across on-premises, multi-cloud, and edge environments. By leveraging Azure ARC, you can enforce security and compliance policies consistently, ensuring that your resources meet regulatory requirements and organizational standards. Azure ARC provides a unified control plane for managing and governing resources, enabling you to manage your hybrid cloud infrastructure effectively.</p> <p>For more information on Azure ARC, visit the Azure ARC documentation.</p>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/","title":"How to use Azue ARC-enabled servers with managed identity to access to Azure Storage Account","text":"<p>In this demo we will show how to use Azure ARC-enabled servers with managed identity to access to Azure Storage Account.</p>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#prerequisites","title":"Prerequisites","text":"<ul> <li>An Azure subscription. If you don't have an Azure subscription, create a free account before you begin.</li> </ul>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#required-permissions","title":"Required permissions","text":"<p>You'll need the following Azure built-in roles for different aspects of managing connected machines:</p> <ul> <li>To onboard machines, you must have the\u00a0Azure Connected Machine Onboarding\u00a0or\u00a0Contributor\u00a0role for the resource group where you're managing the servers.</li> <li>To read, modify, and delete a machine, you must have the\u00a0Azure Connected Machine Resource Administrator\u00a0role for the resource group.</li> <li>To select a resource group from the drop-down list when using the\u00a0Generate script\u00a0method, you'll also need the\u00a0Reader\u00a0role for that resource group (or another role that includes\u00a0Reader\u00a0access).</li> </ul>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#register-azure-resource-providers","title":"Register Azure resource providers","text":"<p>To use Azure Arc-enabled servers with managed identity, you need to register the following resource providers:</p> <pre><code>az account set --subscription \"{Your Subscription Name}\"\naz provider register --namespace 'Microsoft.HybridCompute'\naz provider register --namespace 'Microsoft.GuestConfiguration'\naz provider register --namespace 'Microsoft.HybridConnectivity'\naz provider register --namespace 'Microsoft.AzureArcData'\n</code></pre> <p>Info</p> <p>Microsoft.AzureArcData (if you plan to Arc-enable SQL Servers) Microsoft.Compute (for Azure Update Manager and automatic extension upgrades)</p>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#networking-requirements","title":"Networking requirements","text":"<p>The Azure Connected Machine agent for Linux and Windows communicates outbound securely to Azure Arc over TCP port 443. In this demo, we have use Azure Private Link. </p>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#azure-arc-enabled-enabled-server","title":"Azure ARC-enabled enabled server","text":"<p>We use  Use Azure Private Link to securely connect networks to Azure Arc-enabled servers to achieve this.</p> <p>Some tips:</p> <ul> <li> <p>If you have any issue registerin de VM: generate a script to register a machine with Azure Arc following that instructions here</p> </li> <li> <p>If you have an error that says \"Path C:\\ProgramData\\AzureConnectedMachineAgent\\Log\\himds.log is busy. Retrying...\" you can use the following command to resolve it if you know that you are doing:</p> </li> </ul> <p><pre><code> (get-wmiobject -class win32_product | where {$_.name -like \"Azure *\"}).uninstall() \n</code></pre> - Review /etc/hosts file and add the following entries:</p> <pre><code>$Env:PEname = \"myprivatelink\"\n$Env:resourceGroup = \"myResourceGroup\"\n$file = \"C:\\Windows\\System32\\drivers\\etc\\hosts\"\n\n$gisfqdn = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query '[0].privateDnsZoneConfigs[0].recordSets[0].fqdn' -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$gisIP = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[0].recordSets[0].ipAddresses[0] -o json).replace(\"`\"\",\"\")\n$hisfqdn = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[0].recordSets[1].fqdn -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$hisIP = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[0].recordSets[1].ipAddresses[0] -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$agentfqdn = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[1].recordSets[0].fqdn -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$agentIp = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[1].recordSets[0].ipAddresses[0] -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$gasfqdn = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[1].recordSets[1].fqdn -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$gasIp = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[1].recordSets[1].ipAddresses[0] -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$dpfqdn = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[2].recordSets[0].fqdn -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n$dpIp = (az network private-endpoint dns-zone-group list --endpoint-name $Env:PEname --resource-group $Env:resourceGroup -o json --query [0].privateDnsZoneConfigs[2].recordSets[0].ipAddresses[0] -o json).replace('.privatelink','').replace(\"`\"\",\"\")\n\n$hostfile += \"$gisIP $gisfqdn\"\n$hostfile += \"$hisIP $hisfqdn\"\n$hostfile += \"$agentIP $agentfqdn\"\n$hostfile += \"$gasIP $gasfqdn\"\n$hostfile += \"$dpIP $dpfqdn\"\n</code></pre>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#storage-account-configuration","title":"Storage Account configuration","text":"","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#create-a-storage-account-with-static-website-enabled","title":"Create a Storage Account with static website enabled","text":"<pre><code>$resourceGroup = \"myResourceGroup\"\n$location = \"eastus\"\n$storageAccount = \"mystorageaccount\"\n$indexDocument = \"index.html\"\naz group create --name $resourceGroup --location $location\naz storage account create --name $storageAccount --resource-group $resourceGroup --location $location --sku Standard_LRS\naz storage blob service-properties update --account-name $storageAccount --static-website --index-document $indexDocument\n</code></pre>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#add-private-endpoints-to-the-storage-accoun-for-blob-and-static-website","title":"Add private endpoints to the storage accoun for blob and static website","text":"<pre><code>$resourceGroup = \"myResourceGroup\"\n$storageAccount = \"mystorageaccount\"\n$privateEndpointName = \"myprivatelink\"\n$location = \"eastus\"\n$vnetName = \"myVnet\"\n$subnetName = \"mySubnet\"\n$subscriptionId = \"{subscription-id}\"\naz network private-endpoint create --name $privateEndpointName --resource-group $resourceGroup --vnet-name $vnetName --subnet $subnetName --private-connection-resource-id \"/subscriptions/$subscriptionId/resourceGroups/$resourceGroup/providers/Microsoft.Storage/storageAccounts/$storageAccount\" --group-id blob --connection-name $privateEndpointName --location $location\naz network private-endpoint create --name $privateEndpointName --resource-group $resourceGroup --vnet-name $vnetName --subnet $subnetName --private-connection-resource-id \"/subscriptions/$subscriptionId/resourceGroups/$resourceGroup/providers/Microsoft.Storage/storageAccounts/$storageAccount\" --group-id web --connection-name $privateEndpointName --location $location\n</code></pre>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#disable-public-access-to-the-storage-account-except-for-your-ip","title":"Disable public access to the storage account except for your ip","text":"<pre><code>$resourceGroup = \"myResourceGroup\"\n$storageAccount = \"mystorageaccount\"\n$ipAddress = \"myIpAddress\"\naz storage account update --name $storageAccount --resource-group $resourceGroup --bypass \"AzureServices,Logging,Metrics\" --default-action Deny\naz storage account network-rule add --account-name $storageAccount --resource-group $resourceGroup --ip-address $ipAddress\n</code></pre>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#assign-the-storage-blob-data-contributor-role-to-the-managed-identity-of-the-azure-arc-enabled-server","title":"Assign the Storage Blob Data Contributor role to the managed identity of the Azure ARC-enabled server","text":"<pre><code>$resourceGroup = \"myResourceGroup\"\n$storageAccount = \"mystorageaccount\"\n$serverName = \"myserver\"\n$managedIdentity = az resource show --resource-group $resourceGroup --name $serverName --resource-type \"Microsoft.HybridCompute/machines\" --query \"identity.principalId\" --output tsv\naz role assignment create --role \"Storage Blob Data Contributor\" --assignee-object-id $managedIdentity --scope \"/subscriptions/{subscription-id}/resourceGroups/$resourceGroup/providers/Microsoft.Storage/storageAccounts/$storageAccount\"\n</code></pre>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#download-azcopy-install-it-and-copy-something-to-web-in-the-storage-account","title":"Download azcopy,  install it and copy something to $web in the storage account","text":"","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#download-azcopy-in-the-vm","title":"Download azcopy in the vm","text":"<pre><code>Invoke-WebRequest -Uri \"https://aka.ms/downloadazcopy-v10-windows\" -OutFile AzCopy.zip\n\nExpand-Archive AzCopy.zip -DestinationPath $env:ProgramFiles\n\n$env:Path += \";$env:ProgramFiles\\azcopy\"\n</code></pre>","tags":["Azure ARC"]},{"location":"blog/2024/04/07/how-to-use-azue-arc-enabled-servers-with-managed-identity-to-access-to-azure-storage-account/#copy-something-to-web-in-the-storage-account","title":"Copy something to $web in the storage account","text":"<pre><code>$storageAccount = \"mystorageaccount\"\n$source = \"C:\\Users\\Public\\Documents\\myFile.txt\"\n$destination = \"https://$storageAccount.blob.core.windows.net/\\$web/myFile.txt\"\nazcopy login --identity\nazcopy copy $source $destination\n</code></pre> <p>Now you can check the file in the static website of the storage account.</p>","tags":["Azure ARC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/","title":"Using Enterprise Azure Policy as Code (EPAC)","text":"<p>In this blog post, we will show how to use Enterprise Azure Policy as Code (EPAC) to manage your Azure environment.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#use-case","title":"Use case","text":"<ul> <li>Determine desired state strategy.</li> <li>We have some existing Azure Policies that we want to manage as code.</li> <li>For simplicity, we will suppose that we have a unique Centralized Team that manages the policies.</li> <li>We will use a Git repository to store the policies and the CI/CD process to deploy them.</li> <li>We doesn't have any exclude resources in the environment.</li> <li>How to handle Defender for Cloud Policy Assignments:</li> <li>We will use Defender for Cloud to manage the Policy Assignments for Defender Plans when a plan is enabled.</li> <li>EPAC will manage Defender for Cloud Security Policy Assignments at the management group level. This is the default behavior.</li> <li>Design your CI/CD process:</li> <li>We will use Release Flow</li> </ul>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#management-groups-for-enterprise-scale-landing-zone","title":"Management Groups for Enterprise Scale Landing Zone","text":"<p>This is the common structure for the Management Groups in the Enterprise Scale Landing Zone, now Accelerator Landing Zone: </p> <pre><code>    graph TD\n        A[Root Management Group] --&gt; B[Intermediary-Management-Group]\n        B --&gt; C[Decommissioned]\n        B --&gt; D[Landing Zones]\n        B --&gt; E[Platform]\n        B --&gt; F[Sandboxes]\n        D --&gt; G[Corp]\n        D --&gt; H[Online]\n        E --&gt; I[Connectivity]\n        E --&gt; J[Identity]\n        E --&gt; K[Management]\n</code></pre> <p>For this use case, we will use the <code>Landing Zones</code> Management Group for duplicate and old Management Group hierarchy (manage-azure-policy):</p> <pre><code>  graph TD\n      A[Root Management Group] --&gt; B[epac-dev]\n      B --&gt; C[dev-decommissioned]\n      B --&gt; D[dev-landingzones]\n      B --&gt; E[dev-platform]\n      B --&gt; F[dev-sandbox]\n      D --&gt; G[dev-corp]\n      D --&gt; H[dev-online]\n      E --&gt; I[dev-connectivity]\n      E --&gt; J[dev-identity]\n      E --&gt; K[dev-management]\n      A[Root Management Group] --&gt; L[epac-prod]\n      L --&gt; M[prod-decommissioned]\n      L --&gt; N[prod-landingzones]\n      L --&gt; O[prod-platform]\n      L --&gt; P[prod-sandbox]\n      N --&gt; Q[prod-corp]\n      N --&gt; R[prod-online]\n      O --&gt; S[prod-connectivity]\n      O --&gt; T[prod-identity]\n      O --&gt; U[prod-management]\n      A[Root Management Group] --&gt; V[manage-azure-policy]\n\n      classDef dev fill:#f90,stroke:#333,stroke-width:2px;\n      classDef prod fill:#f9f,stroke:#333,stroke-width:2px;\n      class dev A,B,C,D,E,F,G,H,I,J,K;\n      class prod L,M,N,O,P,Q,R,S,T,U;   \n\n</code></pre> <p>Note</p> <p>You could also use two different tenants for the different environments, but this is not the case for this use case.</p> <p>You can create this Management Groups hierarcly using the Azure CLI with the following commands:</p> <pre><code>az account management-group create --name \"MyManagementGroup\"\naz account management-group move --name \"ChildGroup\" --new-parent \"NewParentGroup\"\n</code></pre> <p>For the use case, we will use the following commands:</p> <pre><code>az account management-group create --name \"epac-dev\"\naz account management-group create --name \"dev-decommissioned\" --parent \"epac-dev\"\naz account management-group create --name \"dev-landingzones\" --parent \"epac-dev\"\naz account management-group create --name \"dev-platform\" --parent \"epac-dev\"\naz account management-group create --name \"dev-sandbox\" --parent \"dev-landingzones\"\naz account management-group create --name \"dev-corp\" --parent \"dev-landingzones\"\naz account management-group create --name \"dev-online\" --parent \"dev-landingzones\"\naz account management-group create --name \"dev-connectivity\" --parent \"dev-platform\"\naz account management-group create --name \"dev-identity\" --parent \"dev-platform\"\naz account management-group create --name \"dev-management\" --parent \"dev-platform\"\naz account management-group create --name \"epac-prod\"\naz account management-group create --name \"prod-decommissioned\" --parent \"epac-prod\"\naz account management-group create --name \"prod-landingzones\" --parent \"epac-prod\"\naz account management-group create --name \"prod-platform\" --parent \"epac-prod\"\naz account management-group create --name \"prod-sandbox\" --parent \"prod-landingzones\"\naz account management-group create --name \"prod-corp\" --parent \"prod-landingzones\"\naz account management-group create --name \"prod-online\" --parent \"prod-landingzones\"\naz account management-group create --name \"prod-connectivity\" --parent \"prod-platform\"\naz account management-group create --name \"prod-identity\" --parent \"prod-platform\"\naz account management-group create --name \"prod-management\" --parent \"prod-platform\"\n</code></pre>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#installation","title":"Installation","text":"<p>To install EPAC, follow these steps:</p> <pre><code>    Install-Module Az -Scope CurrentUser\n    Install-Module EnterprisePolicyAsCode -Scope CurrentUser\n</code></pre>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#create-an-empty-repository-in-github-and-clone-it","title":"Create an empty repository in github and clone it","text":"<p>Create a repository in github  and clone it</p> <pre><code>    git clone https://github.com/user/demo-EPAC.git\n</code></pre> <p>Create a branch for the feature/firstcommit</p> <pre><code>    git checkout -b feature/firstcommit\n</code></pre> <p>Note</p> <p>From this moment on, we will execute all commands within the repository directory.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#create-definitions","title":"Create Definitions","text":"<pre><code>New-EPACDefinitionFolder -DefinitionsRootFolder Definitions\n</code></pre> <p>This command creates a folder structure for the definitions. The  <code>Definitions</code>\u00a0folder Structure is as follows:</p> <ul> <li>Define the Azure environment(s) in file\u00a0<code>global-settings.jsonc</code></li> <li>Create custom Policies (optional) in folder\u00a0<code>policyDefinitions</code></li> <li>Create custom Policy Sets (optional) in folder\u00a0<code>policySetDefinitions</code></li> <li>efine the Policy Assignments in folder\u00a0<code>policyAssignments</code></li> <li>Define the Policy Exemptions (optional) in folder\u00a0<code>policyExemptions</code></li> <li>Define Documentation in folder\u00a0<code>policyDocumentations]</code></li> </ul>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#configure-global-settingsjsonc","title":"Configure global-settings.jsonc","text":"<p>global-settings.jsonc is the file where you define the Azure environment(s) that you want to manage with EPAC. The file should be located in the Definitions folder. Here is an example of the content of the file:</p> <pre><code>{\n    \"$schema\": \"https://raw.githubusercontent.com/Azure/enterprise-azure-policy-as-code/main/Schemas/global-settings-schema.json\",\n    \"pacOwnerId\": \"ff2ce5e1-da8a-4cfb-883b-aee9fbfb85d6\",\n    \"pacEnvironments\": [\n        {\n            \"pacSelector\": \"epac-dev\",\n            \"cloud\": \"AzureCloud\",\n            \"tenantId\": \"e18e4e7e-d0cc-40af-9907-84923ca55499\",\n            \"deploymentRootScope\": \"/providers/Microsoft.Management/managementGroups/epac-dev\",\n            \"desiredState\": {\n                \"strategy\": \"full\",\n                \"keepDfcSecurityAssignments\": false\n            },\n            \"managedIdentityLocation\": \"france\"\n        },\n        {\n            \"pacSelector\": \"tenant\",\n            \"cloud\": \"AzureCloud\",\n            \"tenantId\": \"e18e4e7e-d0cc-40af-9907-84923ca55499\",\n            \"deploymentRootScope\": \"/providers/Microsoft.Management/managementGroups/epac-prod\",\n            \"desiredState\": {\n                \"strategy\": \"full\",\n                \"keepDfcSecurityAssignments\": false\n            },\n            \"managedIdentityLocation\": \"france\",\n            \"globalNotScopes\": [\n                \"/providers/Microsoft.Management/managementGroups/mg-Epac-Dev\",\n                \"/providers/Microsoft.Management/managementGroups/manage-azure-policy\"\n            ]\n        },\n        {\n            \"pacSelector\": \"manage-azure-policy\",\n            \"cloud\": \"AzureCloud\",\n            \"tenantId\": \"e18e4e7e-d0cc-40af-9907-84923ca55499\",\n            \"deploymentRootScope\": \"/providers/Microsoft.Management/managementGroups/manage-azure-policy\",\n            \"desiredState\": {\n                \"strategy\": \"full\",\n                \"keepDfcSecurityAssignments\": false\n            },\n            \"managedIdentityLocation\": \"france\"\n        }\n    ]\n\n}\n</code></pre> <p>Info</p> <p>The pacOwner helps to identify who or what owns an Assignment or Policy definition deployment and needs to be unique to your EPAC environment. The pacOwnerId is used to identity policy resources that are deployed by your EPAC repository, or another EPAC isntance, legacy or another solution entirely.</p> <p>You can generate a new id with <code>New-Guid</code></p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#extracting-existing-policy-resources","title":"Extracting existing Policy Resources","text":"<pre><code>Export-AzPolicyResources\n</code></pre> <p>This command extracts all existing Policy Resources in the Azure environment(s) defined in the global-settings.jsonc file. The extracted resources are saved in the Output/Definitions folder. </p> <p>You needs review the extracted resources and move them to the correct folder in the Definitions folder.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#syncing-alz-definitions","title":"Syncing ALZ Definitions","text":"<pre><code>Sync-ALZPolicies -DefinitionsRootFolder .\\Definitions -CloudEnvironment AzureCloud # Also accepts AzureUSGovernment or AzureChinaCloud\n</code></pre> <p>You can sync the ALZ Definitions manually or use a GitHub action creating <code>.github\\workflows\\alz-sync.yaml</code> in your repository with the following content:</p> <pre><code>name: Sync ALZ Policy Objects\n\nenv:\n  REVIEWER: anwather # Change this to your GitHub username\n  DefinitionsRootFolder: Definitions # Change this to the folder where your policy definitions are stored\n\non:\n  workflow_dispatch\n\njobs:\n    sync:\n        runs-on: ubuntu-latest\n        steps:\n        - name: Checkout\n          uses: actions/checkout@v4\n        - shell: pwsh\n          name: Install Required Modules\n          run: |\n            Install-Module EnterprisePolicyAsCode -Force\n            Sync-ALZPolicies -DefinitionsRootFolder $env:DefinitionsRootFolder\n            $branchName = \"caf-sync-$(Get-Date -Format yyyy-MM-dd-HH-mm)\"\n            git config user.name \"GitHub Actions Bot\"\n            git config user.email \"&lt;&gt;\"\n            git checkout -b $branchName\n            git add .\n            git commit -m \"Updated ALZ policy objects\"\n            git push --set-upstream origin $branchName\n            gh pr create -B main -H $branchName --title \"Verify Synced Policies - $branchName\" -b \"Checkout this PR branch and validate changes before merging.\" --reviewer $env:REVIEWER\n        env:\n            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#cicd-with-github-flow","title":"CI/CD with Github Flow","text":"<p>We will use the Github Flow to manage the CI/CD process. We will create a Github Actions to deploy the policies to the Azure environment(s) defined in the global-settings.jsonc file.</p> <p></p> <p>We can open a second terminal and execute the following command to create the Github Actions in one upper level folder of our repository. This command will create the Github Actions in the <code>.github\\workflows</code> folder of the repository. :</p> <pre><code>git clone https://github.com/Azure/enterprise-azure-policy-as-code\ncd enterprise-azure-policy-as-code\nNew-PipelinesFromStarterKit -StarterKitFolder .\\StarterKit -PipelinesFolder ..\\global-azure-2024-demo-EPAC\\.github\\workflows -PipelineType GitHubActions -BranchingFlow github -ScriptType Module \n</code></pre> <p>Now, we need to create some environments with secrets in the repository to use in the Github Actions. We need to create the following environments:</p> Environment Purpose App Registration\u00a0(SPN) EPAC-DEV Plan and deploy to\u00a0<code>epac-dev</code> ci-cd-epac-dev-owner TENANT-PLAN Build deployment plan for\u00a0<code>tenant</code> ci-cd-root-policy-reader TENANT-DEPLOY-POLICY Deploy Policy resources for\u00a0<code>tenant</code> ci-cd-root-policy-contributor TENANT-DEPLOY-ROLES Deploy Roles for\u00a0<code>tenant</code> ci-cd-root-user-assignments TENANT-REMEDIATE-POLICY Remediate Policy resources for\u00a0<code>tenant</code> ci-cd-root-policy-contributor <p>You need  to Configure a federated identity credential on an app too.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#first-commit","title":"First Commit","text":"<p>Now we can commit the changes to the repository and make a pull request to the main branch.</p>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/using-enterprise-azure-policy-as-code-epac/#references","title":"References","text":"<ul> <li>EPAC official documentation.</li> </ul>","tags":["Azure Policy","EPAC"]},{"location":"blog/2024/04/17/cambio-de-nombres-de-los-niveles-de-servicio-de-microsoft-defender-para-cloud/","title":"Cambio de nombres de los niveles de servicio de Microsoft Defender para Cloud","text":"<p>No es nuevo pero me gustar\u00eda recordar que Microsoft ha cambiado los nombres de los niveles de servicio de Microsoft Defender para Cloud. A continuaci\u00f3n, se muestra una tabla con los nombres anteriores y los nuevos nombres de los niveles de servicio de Microsoft Defender para Cloud:</p> Nombre ANTERIOR del nivel de servicio\u00a02 Nombre NUEVO del nivel de servicio\u00a02 Nivel de servicio: nivel de servicio\u00a04 (sin cambios) Advanced Data Security Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para SQL Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para registros de contenedor Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para DNS Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para Key Vault Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para Kubernetes Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para MySQL Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para PostgreSQL Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para Resource Manager Advanced Threat Protection Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para Storage Azure Defender Microsoft\u00a0Defender\u00a0for\u00a0Cloud Administraci\u00f3n de superficie expuesta a ataques externos de Defender Azure Defender Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para Azure Cosmos\u00a0DB Azure Defender Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para contenedores Azure Defender Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender for MariaDB Security Center Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para App Service Security Center Microsoft\u00a0Defender\u00a0for\u00a0Cloud Defender para servidores Security Center Microsoft\u00a0Defender\u00a0for\u00a0Cloud Administraci\u00f3n de la posici\u00f3n de seguridad en la nube de Defender","tags":["Microsoft Defender for Cloud"]},{"location":"blog/2024/04/17/azure-policy-useful-queries/","title":"Azure Policy useful queries","text":"","tags":["Azure Policy"]},{"location":"blog/2024/04/17/azure-policy-useful-queries/#policy-assignments-and-information-about-each-of-its-respective-definitions","title":"Policy assignments and information about each of its respective definitions","text":"<pre><code>// Policy assignments and information about each of its respective definitions\n// Gets policy assignments in your environment with the respective assignment name,definition associated, category of definition (if applicable), as well as whether the definition type is an initiative or a single policy.\n\npolicyResources\n| where type =~'Microsoft.Authorization/PolicyAssignments'\n| project policyAssignmentId = tolower(tostring(id)), policyAssignmentDisplayName = tostring(properties.displayName), policyAssignmentDefinitionId = tolower(properties.policyDefinitionId)\n| join kind=leftouter(\n policyResources\n | where type =~'Microsoft.Authorization/PolicySetDefinitions' or type =~'Microsoft.Authorization/PolicyDefinitions'\n | project definitionId = tolower(id), category = tostring(properties.metadata.category), definitionType = iff(type =~ 'Microsoft.Authorization/PolicysetDefinitions', 'initiative', 'policy')\n) on $left.policyAssignmentDefinitionId == $right.definitionId\n</code></pre> <ul> <li>Original Gist</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/04/17/azure-policy-useful-queries/#list-subscriptionid-and-subscriptionname","title":"List SubscriptionId and SubscriptionName","text":"<pre><code>ResourceContainers\n| where type =~ 'microsoft.resources/subscriptions'\n| project subscriptionId, subscriptionName=name\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/04/17/azure-policy-useful-queries/#list-managementgroupid-and-managementgroupname","title":"List ManagementGroupId and ManagementGroupName","text":"<pre><code>ResourceContainers\n| where type =~ 'microsoft.management/managementgroups'\n| project mgname = name, displayName = properties.displayName\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/04/17/azure-policy-useful-queries/#policy-assignments-and-information-about-each-of-its-respective-definitions-displaying-the-scope-of-the-assignment-the-subscription-display-name-the-management-group-id-the-resource-group-name-the-definition-type-the-assignment-name-the-category-of-the-definition-and-the-policy-assignment-id","title":"Policy assignments and information about each of its respective definitions displaying the scope of the assignment, the subscription display name, the management group id, the resource group name, the definition type, the assignment name, the category of the definition, and the policy assignment ID.","text":"<pre><code>policyResources\n| where type =~'Microsoft.Authorization/PolicyAssignments'\n| project policyAssignmentId = tolower(tostring(id)), policyAssignmentDisplayName = tostring(properties.displayName), policyAssignmentDefinitionId = tolower(properties.policyDefinitionId), subscriptionId = tostring(subscriptionId),resourceGroup=tostring(resourceGroup), AssignmentDefinition=properties\n| join kind=leftouter(\n    policyResources\n    | where type =~'Microsoft.Authorization/PolicySetDefinitions' or type =~'Microsoft.Authorization/PolicyDefinitions'\n    | project definitionId = tolower(id), category = tostring(properties.metadata.category), definitionType = iff(type =~ 'Microsoft.Authorization/PolicysetDefinitions', 'initiative', 'policy'),PolicyDefinition=properties\n) on $left.policyAssignmentDefinitionId == $right.definitionId\n| extend scope = iff(policyAssignmentId contains '/subscriptions/', 'Subscription', iff(policyAssignmentId contains '/providers/microsoft.management/managementgroups', 'Management Group', 'Resource Group'))\n| join kind=leftouter (ResourceContainers\n| where type =~ 'microsoft.resources/subscriptions'\n| project subscriptionId, subscriptionName=name) on $left.subscriptionId == $right.subscriptionId\n| extend SubscriptionDisplayName = iff(isnotempty(subscriptionId), subscriptionName, '')\n| extend ManagementGroupName = iff(policyAssignmentId contains '/providers/microsoft.management/', split(policyAssignmentId, '/')[4],'')\n| extend resourceGroupDisplayName = iff(isnotempty(resourceGroup), resourceGroup, '')\n| project ManagementGroupName,SubscriptionDisplayName,resourceGroupDisplayName, scope,definitionType,policyAssignmentDisplayName, category,policyAssignmentId, AssignmentDefinition, PolicyDefinition\n</code></pre> <ul> <li> Add Management Group Display Name</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/","title":"Kusto Query Language (KQL) for Azure Resource Graph","text":"<p>Azure Graph is a powerful tool provided by Microsoft to query data across all your Azure resources. It uses the Kusto Query Language (KQL), a read-only language similar to SQL, designed to query vast amounts of data in Azure services.</p> <p>Important</p> <p>Only a subset of KQL is supported in Azure Resource Graph. For more information, see the Azure Resource Graph Supported KQL Language Elements.</p>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#what-is-kql","title":"What is KQL?","text":"<p>KQL stands for Kusto Query Language. It's a request to process data and return results. The syntax is easy to read and author, making it ideal for data exploration and ad-hoc data mining tasks.</p>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#using-kql-with-azure-graph","title":"Using KQL with Azure Graph","text":"<p>Azure Graph allows you to use KQL to create complex queries that fetch information from your Azure resources. You can filter, sort, aggregate, and join data from different resources using KQL.</p> <p>Here's an example of how you might use KQL to query Azure Graph:</p> <pre><code>Resources\n| where type =~ 'microsoft.web/sites'\n| project name, location, resourceGroup\n</code></pre> <p>This query retrieves all Azure Web Apps (websites) and projects their <code>name</code>, <code>location</code>, and <code>resourceGroup</code>.</p>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#key-characteristics-of-kql","title":"Key Characteristics of KQL","text":"<ol> <li>Case Sensitivity: Unlike SQL, KQL is case-sensitive. So 'Name' and 'name' would be considered different identifiers.</li> <li>Schema-Free: Kusto (Azure Data Explorer) doesn't require a fixed schema, allowing storage of diverse types of data.</li> <li>Extensibility: While KQL has a wide array of functions, you can also create custom functions as per your needs.</li> </ol>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#common-operators-in-kql","title":"Common Operators in KQL","text":"<ul> <li><code>|</code> : This operator creates a pipeline where the output of one command becomes the input of another.</li> <li><code>where</code> : Filters rows based on specified conditions.</li> <li><code>summarize</code> : Groups rows and calculates aggregate expressions.</li> <li><code>join</code> : Combines rows from two tables based on a common column.</li> <li><code>project</code> : Selects specific columns from the input.</li> <li><code>extend</code> : Adds new columns to the input.</li> <li><code>order by</code> : Sorts rows based on specified columns.</li> </ul>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#kql-query-examples","title":"KQL Query Examples","text":"","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#1-list-all-azure-resources-in-a-subscription","title":"1. List all Azure resources in a subscription","text":"<pre><code>Resources\n</code></pre>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#2-list-all-azure-resources-in-a-resource-group","title":"2. List all Azure resources in a resource group","text":"<pre><code>Resources\n| where resourceGroup == 'myResourceGroup'\n</code></pre>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#3-list-all-azure-resources-of-a-specific-type","title":"3. List all Azure resources of a specific type","text":"<pre><code>Resources\n| where type =~ 'Microsoft.Compute/virtualMachines'\n</code></pre>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#pagination-in-kql","title":"Pagination in KQL","text":"<p>KQL supports pagination using the <code>limit</code> and <code>offset</code> operators. You can use these operators to control the number of rows returned and skip a certain number of rows.</p> <pre><code>Resources\n| limit 10\n| offset 5\n</code></pre> <p>If you exceed payload limits, you can paginate Azure Resource Graph query results with powershell:</p> <pre><code>$kqlQuery = \"policyResources | where type =~'Microsoft.Authorization/PolicySetDefinitions' or type =~'Microsoft.Authorization/PolicyDefinitions' | project definitionId = tolower(id), category = tostring(properties.metadata.category), definitionType = iff(type =~ 'Microsoft.Authorization/PolicysetDefinitions', 'initiative', 'policy'),PolicyDefinition=properties\"\n\n$batchSize = 5\n$skipResult = 0\n\n[System.Collections.Generic.List[string]]$kqlResult\n\nwhile ($true) {\n\n  if ($skipResult -gt 0) {\n    $graphResult = Search-AzGraph -Query $kqlQuery -First $batchSize -SkipToken $graphResult.SkipToken\n  }\n  else {\n    $graphResult = Search-AzGraph -Query $kqlQuery -First $batchSize\n  }\n\n  $kqlResult += $graphResult.data\n\n  if ($graphResult.data.Count -lt $batchSize) {\n    break;\n  }\n  $skipResult += $skipResult + $batchSize\n}\n</code></pre>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#best-practices-for-writing-kql-queries","title":"Best Practices for Writing KQL Queries","text":"<ol> <li>Use <code>project</code> to Select Columns: Only select the columns you need to reduce the amount of data returned.</li> <li>Use <code>where</code> to Filter Rows: Apply filters to reduce the number of rows processed.</li> <li>Use <code>summarize</code> to Aggregate Data: Aggregate data to reduce the number of rows returned.</li> <li>Use <code>join</code> to Combine Data: Combine data from different tables using the <code>join</code> operator.</li> <li>Use <code>order by</code> to Sort Data: Sort data based on specific columns to make it easier to read.</li> </ol>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#limitations-of-kql","title":"Limitations of KQL","text":"<ol> <li>No DDL Operations: KQL doesn't support Data Definition Language (DDL) operations like creating tables or indexes.</li> <li>No DML Operations: KQL doesn't support Data Manipulation Language (DML) operations like inserting, updating, or deleting data.</li> <li>Limited Data Types: KQL has a limited set of data types compared to SQL.</li> <li>No Transactions: KQL doesn't support transactions, so you can't group multiple operations into a single transaction.</li> </ol>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#conclusion","title":"Conclusion","text":"<p>KQL is a potent tool for querying large datasets in Azure. Its SQL-like syntax makes it accessible for anyone familiar with SQL, and its rich set of features makes it a flexible solution for a variety of data processing needs. Practice writing KQL queries to uncover valuable insights from your Azure resources!</p>","tags":["KQL"]},{"location":"blog/2024/04/18/kusto-query-language-kql-for-azure-resource-graph/#references","title":"References","text":"<ul> <li>SQL to Kusto Query Language cheat sheet</li> <li>Demo for play</li> </ul>","tags":["KQL"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/","title":"Azure Network, Hub-and-Spoke Topology","text":"<p>Hub and Spoke is a network topology where a central Hub is connected to multiple Spokes. The Hub acts as a central point of connectivity and control, while the Spokes are isolated networks that connect to the Hub. This topology is common in Azure to simplify the connectivity and management of virtual networks.</p> <pre><code>graph TD\n    HUB((\"Central Hub\"))\n    SPOKE1[Spoke1]\n    SPOKE2[Spoke2]\n    SPOKE3[Spoke3]\n    SPOKEN[Spoke...]\n    HUB --- SPOKE1\n    HUB --- SPOKE2\n    HUB --- SPOKE3\n    HUB --- SPOKEN\n</code></pre>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#key-features-of-the-hub-and-spoke-topology","title":"Key Features of the Hub and Spoke Topology","text":"<ol> <li> <p>Centralized Connectivity: The Hub centralizes the connectivity between the Spoke networks. This simplifies the administration and maintenance of the network.</p> </li> <li> <p>Traffic Control: The Hub acts as a traffic control point between the Spoke networks. This allows for centralized application of security and routing policies.</p> </li> <li> <p>Scalability: The Hub and Spoke topology is highly scalable and can grow to meet the organization's connectivity needs.</p> </li> <li> <p>Resilience: The Hub and Spoke topology provides redundancy and resilience in case of network failures.</p> </li> </ol>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#how-to-use-the-hub-and-spoke-topology-in-azure","title":"How to Use the Hub and Spoke Topology in Azure","text":"<p>To implement the Hub and Spoke topology in Azure, follow these steps:</p> <pre><code># Step 1: Create a virtual network for the Hub\naz network vnet create --name HubVnet --resource-group MyResourceGroup --location eastus --address-prefix\n\n# Step 2: Create virtual networks for the Spokes\naz network vnet create --name Spoke1Vnet --resource-group MyResourceGroup --location eastus --address-prefix\naz network vnet create --name Spoke2Vnet --resource-group MyResourceGroup --location eastus --address-prefix\naz network vnet create --name Spoke3Vnet --resource-group MyResourceGroup --location eastus --address-prefix\n\n# Step 3: Connect the Spokes to the Hub\naz network vnet peering create --name Spoke1ToHub --resource-group MyResourceGroup --vnet-name Spoke1Vnet --remote-vnet HubVnet --allow-vnet-access\naz network vnet peering create --name Spoke2ToHub --resource-group MyResourceGroup --vnet-name Spoke2Vnet --remote-vnet HubVnet --allow-vnet-access\naz network vnet peering create --name Spoke3ToHub --resource-group MyResourceGroup --vnet-name Spoke3Vnet --remote-vnet HubVnet --allow-vnet-access\n\n# Step 4: Configure routing between the Hub and the Spokes\naz network vnet peering update --name Spoke1ToHub --resource-group MyResourceGroup --vnet-name Spoke1Vnet --set virtualNetworkGateway:AllowGatewayTransit=true\naz network vnet peering update --name Spoke2ToHub --resource-group MyResourceGroup --vnet-name Spoke2Vnet --set virtualNetworkGateway:AllowGatewayTransit=true\naz network vnet peering update --name Spoke3ToHub --resource-group MyResourceGroup --vnet-name Spoke3Vnet --set virtualNetworkGateway:AllowGatewayTransit=true\n\n# Step 5: Configure routing in the Hub\naz network vnet peering update --name HubToSpoke1 --resource-group MyResourceGroup --vnet-name HubVnet --set virtualNetworkGateway:UseRemoteGateways=true\naz network vnet peering update --name HubToSpoke2 --resource-group MyResourceGroup --vnet-name HubVnet --set virtualNetworkGateway:UseRemoteGateways=true\naz network vnet peering update --name HubToSpoke3 --resource-group MyResourceGroup --vnet-name HubVnet --set virtualNetworkGateway:UseRemoteGateways=true\n</code></pre>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#variant-of-the-hub-and-spoke-topology","title":"Variant of the Hub and Spoke Topology","text":"<p>A variant of the Hub and Spoke topology is the Hub and Spoke with peering between spokes that is generally used to allow direct connectivity between the Spoke networks without going through the Hub. This can be useful in scenarios where direct connectivity between the Spoke networks is required, such as data replication or application communication.</p> <p><pre><code>graph TD\n    HUB((\"Central Hub\"))\n    SPOKE1[Spoke1]\n    SPOKE2[Spoke2]\n    SPOKE3[Spoke3]\n    SPOKEN[Spoke...]\n    HUB --- SPOKE1\n    HUB --- SPOKE2\n    HUB --- SPOKE3\n    HUB --- SPOKEN\n    SPOKE1 -.- SPOKE2    \n</code></pre> In this case, it would be connecting the Spoke networks to each other via virtual network peering, for example:</p> <pre><code># Connect Spoke1 to Spoke2\naz network vnet peering create --name Spoke1ToSpoke2 --resource-group MyResourceGroup --vnet-name Spoke1Vnet --remote-vnet Spoke2Vnet --allow-vnet-access\n</code></pre>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#scalability-and-performance","title":"Scalability and Performance","text":"<p>The Hub and Spoke topology in Azure is highly scalable and can handle thousands of virtual networks and subnets. In terms of performance, the Hub and Spoke topology provides efficient and low-latency connectivity between the Spoke networks and the Hub.</p>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#security-and-compliance","title":"Security and Compliance","text":"<p>The Hub and Spoke topology in Azure provides centralized control over network security and compliance. Security and routing policies can be applied centrally at the Hub, ensuring consistency and compliance with the organization's network policies.</p>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>Use Network Watcher to monitor and diagnose network problems in the Hub and Spoke topology. Network Watcher provides the following tools: </p> <ul> <li>Monitoring<ul> <li>Topology view shows you the resources in your virtual network and the relationships between them.</li> <li>Connection monitor allows you to monitor connectivity and latency between endpoints within and outside of Azure.</li> </ul> </li> <li>Network diagnostic tools<ul> <li>IP flow verify helps you detect traffic filtering issues at the virtual machine level.</li> <li>NSG diagnostics helps you detect traffic filtering issues at the virtual machine, virtual machine scale set, or application gateway level.</li> <li>Next hop helps you verify traffic routes and detect routing issues.</li> <li>Connection troubleshoot enables a one-time check of connectivity and latency between a virtual machine and the Bastion host, application gateway, or another virtual machine.</li> <li>Packet capture allows you to capture traffic from your virtual machine.</li> <li>VPN troubleshoot runs multiple diagnostic checks on your gateways and VPN connections to help debug issues.</li> </ul> </li> <li>Traffic<ul> <li>Network security group flow logs and virtual network flow logs let you log network traffic passing through your network security groups (NSGs) and virtual networks respectively.</li> <li>Traffic analytics processes data from your network security group flow log allowing you to visualize, query, analyze, and understand your network traffic.</li> </ul> </li> </ul> <p>Virtual network flow logs have recently been released which allows for monitoring network traffic in Azure virtual networks.</p>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#use-cases-and-examples","title":"Use Cases and Examples","text":"<p>The Hub and Spoke topology is ideal for organizations that require centralized connectivity and traffic control between multiple virtual networks in Azure. For example, an organization with multiple branches or departments can use the Hub and Spoke topology to securely and efficiently connect their virtual networks in the cloud.</p>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#best-practices-and-tips","title":"Best Practices and Tips","text":"<p>When implementing the Hub and Spoke topology in Azure, it is recommended to follow these best practices:</p> <ul> <li>Security: Apply consistent security policies at the Hub and Spokes to ensure network protection.</li> <li>Resilience: Configure redundancy and resilience in the topology to ensure network availability in case of failures.</li> <li>Monitoring: Use monitoring tools like Azure Monitor to monitor network traffic and detect potential performance issues.</li> </ul>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#conclusion","title":"Conclusion","text":"<p>The Hub and Spoke topology is an effective way to simplify the connectivity and management of virtual networks in Azure. It provides centralized control over network connectivity and traffic, making it easier to implement security and routing policies consistently across the network. By following the recommended best practices and tips, organizations can make the most of the Hub and Spoke topology to meet their cloud connectivity needs.</p>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-network-hub-and-spoke-topology/#references","title":"References","text":"<ul> <li>Network Watcher frequently asked questions (FAQ)</li> <li>Azure Topology</li> </ul>","tags":["Azure Network","Hub and Spoke"]},{"location":"blog/2024/04/19/azure-role-based-access-control-rbac/","title":"Azure Role-Based Access Control (RBAC)","text":"<p>Azure Role-Based Access Control (RBAC) is a system that provides fine-grained access management of resources in Azure. This allows administrators to grant only the amount of access that users need to perform their jobs.</p>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/19/azure-role-based-access-control-rbac/#overview","title":"Overview","text":"<p>In Azure RBAC, you can assign roles to user accounts, groups, service principals, and managed identities at different scopes. The scope could be a management group, subscription, resource group, or a single resource. </p> <p>Here are some key terms you should know:</p> <ul> <li>Role: A collection of permissions. For example, the \"Virtual Machine Contributor\" role allows the user to create and manage virtual machines.</li> <li>Scope: The set of resources that the access applies to. </li> <li>Assignment: The act of granting a role to a security principal at a particular scope.</li> </ul>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/19/azure-role-based-access-control-rbac/#built-in-roles","title":"Built-in Roles","text":"<p>Azure provides several built-in roles that you can assign to users, groups, service principals, and managed identities. Here are a few examples:</p> <ul> <li>Owner: Has full access to all resources including the right to delegate access to others.</li> <li>Contributor: Can create and manage all types of Azure resources but can\u2019t grant access to others.</li> <li>Reader: Can view existing Azure resources.</li> </ul> <pre><code>{\n  \"Name\": \"Contributor\",\n  \"Id\": \"b24988ac-6180-42a0-ab88-20f7382dd24c\",\n  \"IsCustom\": false,\n  \"Description\": \"Lets you manage everything except access to resources.\",\n  \"Actions\": [\n    \"*\"\n  ],\n  \"NotActions\": [\n    \"Microsoft.Authorization/*/Delete\",\n    \"Microsoft.Authorization/*/Write\",\n    \"Microsoft.Authorization/elevateAccess/Action\"\n  ],\n  \"DataActions\": [],\n  \"NotDataActions\": [],\n  \"AssignableScopes\": [\n    \"/\"\n  ]\n}\n</code></pre>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/19/azure-role-based-access-control-rbac/#custom-roles","title":"Custom Roles","text":"<p>If the built-in roles don't meet your specific needs, you can create your own custom roles. Just like built-in roles, you can assign permissions to custom roles and then assign those roles to users.</p> <p><pre><code>{\n  \"Name\": \"Custom Role\",\n  \"Id\": \"00000000-0000-0000-0000-000000000000\",\n  \"IsCustom\": true,\n  \"Description\": \"Custom role description\",\n  \"Actions\": [\n    \"Microsoft.Compute/virtualMachines/start/action\",\n    \"Microsoft.Compute/virtualMachines/restart/action\"\n  ],\n  \"NotActions\": [],\n  \"DataActions\": [],\n  \"NotDataActions\": [],\n  \"AssignableScopes\": [\n    \"/subscriptions/{subscriptionId}\"\n  ]\n}\n</code></pre> Custom Roles has the same structure as built-in roles:</p> <ul> <li>Name: The name of the custom role.</li> <li>Id: A unique identifier for the custom role.</li> <li>IsCustom: Indicates whether the role is custom or built-in.</li> <li>Description: A description of the custom role.</li> <li>Actions: The list of actions that the role can perform.</li> <li>NotActions: The list of actions that the role cannot perform.</li> <li>DataActions: The list of data actions that the role can perform.</li> <li>NotDataActions: The list of data actions that the role cannot perform.</li> <li>AssignableScopes: The list of scopes where the role can be assigned.</li> </ul> <p>You can check how to create a custom role here and not forget to check limitations here.</p>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/19/azure-role-based-access-control-rbac/#recommendations","title":"Recommendations","text":"<p>Here are some best practices for managing access with Azure RBAC:</p> <ul> <li>Use the principle of least privilege: Only grant the permissions that users need to do their jobs.</li> <li>Use built-in roles when possible: Built-in roles are already defined and tested by Microsoft. Only create custom roles when necessary.</li> <li>Regularly review role assignments: Make sure that users have the appropriate level of access for their job. Remove any unnecessary role assignments.</li> </ul>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/19/azure-role-based-access-control-rbac/#conclusion","title":"Conclusion","text":"<p>Azure RBAC is a powerful tool for managing access to your Azure resources. By understanding its core concepts and how to apply them, you can ensure that users have the appropriate level of access for their job.</p>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/20/how-to-create-assigment-reports-for-azure-rbac/","title":"How to create assigment Reports for Azure RBAC","text":"<p>Role-Based Access Control (RBAC) is a key feature of Azure that allows you to manage access to Azure resources. With RBAC, you can grant permissions to users, groups, and applications at a certain scope, such as a subscription, resource group, or resource. RBAC uses role assignments to determine what actions a user, group, or application can perform on a resource.</p> <p>In this article, we will show you how to create reports for role assignments in Azure using PowerShell and the ImportExcel module. We will generate separate Excel files for role assignments at the subscription and management group levels, including information such as the role, principal, scope, and whether the assignment is inherited.</p>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/20/how-to-create-assigment-reports-for-azure-rbac/#role-assignment-report-in-excel","title":"Role assignment report in Excel","text":"<p>This is the PowerShell script that generates the role assignment reports:</p> <pre><code>&lt;#\n.SYNOPSIS\nA script to get role assignments for Azure subscriptions and management groups.\n\n.DESCRIPTION\nThis script gets role assignments for specified or all Azure subscriptions and management groups,\nand exports them to Excel files. It uses the ImportExcel module to create the Excel files.\n\n.PARAMETER SubscriptionId\nThe ID of the Azure subscription. If not provided, the script gets role assignments for all subscriptions.\n\n.PARAMETER ManagementGroupName\nThe name of the Azure management group. If not provided, the script gets role assignments for all management groups.\n\n.PARAMETER GetSubscriptions\nSpecifies whether to get role assignments for subscriptions. Default is false.\n\n.PARAMETER GetManagementGroups\nSpecifies whether to get role assignments for management groups. Default is true.\n\n.EXAMPLE\n.\\get-azroleassigments.ps1 -SubscriptionId \"sub-id\"\n\nThis example gets role assignments for the specified subscription and management group.\n\n.\\get-azroleassigments.ps1 -ManagementGroupName \"mg-name\" -GetSubscriptions $true -GetManagementGroups $false\n\nThis example gets role assignments for the specified management group.\n\n.\\get-azroleassigments.ps1  -GetSubscriptions $true -GetManagementGroups $true\n\nThis example gets role assignments for all subscriptions and management groups.\n\n.NOTES\nYou can not provide both SubscriptionId and GetSubscriptions parameters at the same time.\nYou can not provide both ManagementGroupName and GetManagementGroups parameters at the same time.\n\n#&gt;\n\n# Parameters setup\nparam (\n    [Parameter(Mandatory=$false)]\n    [string]$SubscriptionId,\n\n    [Parameter(Mandatory=$false)]\n    [string]$ManagementGroupName,\n\n    [Parameter(Mandatory=$false)]\n    [bool]$GetSubscriptions = $false,\n\n    [Parameter(Mandatory=$false)]\n    [bool]$GetManagementGroups = $true\n)\n\n# The rest of your script...\n\n# Parameters setup\nparam (\n    [Parameter(Mandatory=$false)]\n    [string]$SubscriptionId,\n\n    [Parameter(Mandatory=$false)]\n    [string]$ManagementGroupName,\n\n    [Parameter(Mandatory=$false)]\n    [bool]$GetSubscriptions = $false,\n\n    [Parameter(Mandatory=$false)]\n    [bool]$GetManagementGroups = $true\n)\n\n# Install the ImportExcel module if not already installed\nif (!(Get-Module -ListAvailable -Name ImportExcel)) {\n    Install-Module -Name ImportExcel -Scope CurrentUser\n}\n\n# Define the path to your Excel file for Managing Group role assignments\n$managementGroupPath = \".\\AzRoleAssignmentMg.xlsx\"\n# Define the path to your Excel file for Subscription role assignments\n$subscriptionPath = \".\\AzRoleAssignmentSub.xlsx\"\n\n# Initialize an empty array to hold all role assignments\n$subscriptionRoleAssignments = @()\n$managementGroupRoleAssignments = @()\n\nif ($GetManagementGroups) {\n    # Check if ManagementGroupName is provided\n    if ($ManagementGroupName) {\n        # Get role assignments for the specified management group\n        $roleAssignments = Get-AzRoleAssignment -Scope \"/providers/Microsoft.Management/managementGroups/$ManagementGroupName\"\n\n        # Add these role assignments to the management group role assignments array\n        $managementGroupRoleAssignments += $roleAssignments\n\n        # Add 'GroupName' and 'IsInherited' properties to each role assignment object\n        $roleAssignments | ForEach-Object {\n            $_ | Add-Member -NotePropertyName 'GroupDisplayName' -NotePropertyValue (Get-AzManagementGroup -GroupName $ManagementGroupName).DisplayName\n            $_ | Add-Member -NotePropertyName 'GroupName' -NotePropertyValue $ManagementGroupName\n            # If the Scope of the role assignment is equal to the Id of the management group,\n            # then the role assignment is not inherited; otherwise, it is inherited.\n            if ($_.Scope -eq \"/providers/Microsoft.Management/managementGroups/$ManagementGroupName\") {\n                $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $false\n            } else {\n                $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $true\n            }\n        }\n\n        # Export the role assignments to a new sheet in the Excel file\n        $roleAssignments | Export-Excel -Path $managementGroupPath -WorksheetName (Get-AzManagementGroup -GroupName $ManagementGroupName).DisplayName -AutoSize -AutoFilter\n    } else {\n        # Get all management groups\n        $managementGroups = Get-AzManagementGroup\n        # Loop through each management group\n        foreach ($mg in $managementGroups) {\n            # Get role assignments for the current management group\n            $roleAssignments = Get-AzRoleAssignment -Scope \"/providers/Microsoft.Management/managementGroups/$($mg.Name)\"\n\n            # Add these role assignments to the management group role assignments array\n            $managementGroupRoleAssignments += $roleAssignments\n\n            # Add 'GroupName' and 'IsInherited' properties to each role assignment object\n            $roleAssignments | ForEach-Object {\n                $_ | Add-Member -NotePropertyName 'GroupDisplayName' -NotePropertyValue $mg.DisplayName\n                $_ | Add-Member -NotePropertyName 'GroupName' -NotePropertyValue $mg.Name\n                # If the Scope of the role assignment is equal to the Id of the management group,\n                # then the role assignment is not inherited; otherwise, it is inherited.\n                if ($_.Scope -eq $mg.Id) {\n                    $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $false\n                } else {\n                    $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $true\n                }\n            }\n\n            # Export the role assignments to a new sheet in the Excel file\n            $roleAssignments | Export-Excel -Path $managementGroupPath -WorksheetName $mg.DisplayName -AutoSize -AutoFilter\n        }\n    }\n}\n\nif ($GetSubscriptions) {   \n    # Check if SubscriptionId is provided\n    if ($SubscriptionId) {\n        # Get role assignments for the specified subscription\n        $roleAssignments = Get-AzRoleAssignment -Scope \"/subscriptions/$SubscriptionId\"\n\n        # Add these role assignments to the subscription role assignments array\n        $subscriptionRoleAssignments += $roleAssignments\n\n        # Add 'SubscriptionName' and 'IsInherited' properties to each role assignment object\n        $roleAssignments | ForEach-Object { \n            $_ | Add-Member -NotePropertyName 'SubscriptionName' -NotePropertyValue (Get-AzSubscription -SubscriptionId $SubscriptionId).Name \n            $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $false\n        }\n\n        # Export the role assignments to a new sheet in the Excel file\n        $roleAssignments | Export-Excel -Path $subscriptionPath -WorksheetName (Get-AzSubscription -SubscriptionId $SubscriptionId).Name -AutoSize -AutoFilter\n    } else {\n        # Get all subscriptions\n        $subscriptions = Get-AzSubscription\n\n        # Loop through each subscription\n        foreach ($sub in $subscriptions) {\n            # Get role assignments for the current subscription\n            $roleAssignments = Get-AzRoleAssignment -Scope \"/subscriptions/$($sub.SubscriptionId)\"\n\n            # Add these role assignments to the subscription role assignments array\n            $subscriptionRoleAssignments += $roleAssignments\n\n            # Add 'SubscriptionName' and 'IsInherited' properties to each role assignment object\n            $roleAssignments | ForEach-Object { \n                $_ | Add-Member -NotePropertyName 'SubscriptionName' -NotePropertyValue $sub.Name\n                 # If the Scope of the role assignment is equal to the subscription Id,\n                 # then the role assignment is not inherited; otherwise, it is inherited.\n                if ($_.Scope -eq \"/subscriptions/$($sub.SubscriptionId)\") {\n                    $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $false\n                } else {\n                    $_ | Add-Member -NotePropertyName 'IsInherited' -NotePropertyValue $true\n                }\n            }\n\n            # Export the role assignments to a new sheet in the Excel file\n            $roleAssignments | Export-Excel -Path $subscriptionPath -WorksheetName $sub.Name -AutoSize -AutoFilter\n        }\n    }\n}\n</code></pre> <p>This script takes the following parameters:</p> <ul> <li><code>GetSubscriptions</code>: A switch parameter that specifies whether to generate reports for subscriptions. The default value is <code>$false</code>.</li> <li><code>GetManagementGroups</code>: A switch parameter that specifies whether to generate reports for management groups. The default value is <code>$true</code>.</li> <li><code>SubscriptionId</code>: The ID of the subscription for which you want to generate the report. If this parameter is not provided, the script will generate reports for all subscriptions.</li> <li><code>ManagementGroupName</code>: The name of the management group for which you want to generate the report. If this parameter is not provided, the script will generate reports for all management groups.</li> </ul>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/20/how-to-create-assigment-reports-for-azure-rbac/#role-definition-report-in-excel-1","title":"Role definition report in Excel 1","text":"<p>You can also generate a report for role definitions in Azure using the following PowerShell script:</p> <pre><code>param(\n    [Parameter(Mandatory=$false)]\n    [ValidateSet('Console', 'Excel')]\n    [string]$OutputType = 'Console',\n\n    [Parameter(Mandatory=$false)]\n    [string]$ExcelFilePath = \".\\AzRoleDefinition.xlsx\"\n)\n\n# Install the ImportExcel module if not already installed\nif (!(Get-Module -ListAvailable -Name ImportExcel)) {\n    Install-Module -Name ImportExcel -Scope CurrentUser\n}\n\n# Install the  AzureRM module if not already installed\nif (!(Get-Module -ListAvailable -Name  Az)) {\n    Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n    Install-Module -Name  Az -Scope CurrentUser\n}\n\n# Get all role definitions\n$roleDefinitions = Get-AzRoleDefinition | ForEach-Object {\n    # Create a custom object with ordered properties\n    $customObject = New-Object PSObject -Property @{\n        Name = $_.Name\n        Id = $_.Id\n        IsCustom = $_.IsCustom\n        Description = $_.Description\n        Actions = ($_.Actions -join ', ').Replace(',', \",`n\")\n        NotActions = ($_.NotActions -join ', ').Replace(',', \",`n\")\n        DataActions = ($_.DataActions -join ', ').Replace(',', \",`n\")\n        NotDataActions = ($_.NotDataActions -join ', ').Replace(',', \",`n\")\n        AssignableScopes = ($_.AssignableScopes -join ', ').Replace(',', \",`n\")\n    } | Select-Object Name, Id, IsCustom, Description, Actions, NotActions, DataActions, NotDataActions, AssignableScopes\n\n    return $customObject\n}\n\nif ($OutputType -eq 'Console') {\n    # Output to console\n    $roleDefinitions | Format-Table -AutoSize\n} else {\n    # Export to Excel\n    $roleDefinitions | Export-Excel -Path $ExcelFilePath -WorksheetName 'Role Definitions' -AutoSize -AutoFilter    \n}\n</code></pre> <p>This script takes the following parameters:</p> <ul> <li><code>OutputType</code>: A string parameter that specifies the output type. The default value is <code>'Console'</code>. You can also specify <code>'Excel'</code> to export the report to an Excel file.</li> <li><code>ExcelFilePath</code>: The path to the Excel file where you want to export the report. The default value is <code>\".\\AzRoleDefinition.xlsx\"</code>.</li> </ul> <p>In the Excel report, you will see the following columns for each role definition: <code>Name</code>, <code>Id</code>, <code>IsCustom</code>, <code>Description</code>, <code>Actions</code>, <code>NotActions</code>, <code>DataActions</code>, <code>NotDataActions</code>, and <code>AssignableScopes</code>.</p>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/20/how-to-create-assigment-reports-for-azure-rbac/#conclusion","title":"Conclusion","text":"<p>In this article, we have shown you how to create reports for role assignments and role definitions in Azure using PowerShell and the ImportExcel module. These reports can help you better understand the permissions assigned to users, groups, and applications in your Azure environment and ensure that they are configured correctly. You can customize the scripts to include additional information or export the reports in different formats to suit your needs.</p>","tags":["Role-Based Access Control"]},{"location":"blog/2024/04/22/management-groups/","title":"Management Groups","text":"","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#what-are-management-groups","title":"What are Management Groups?","text":"<p>Management Groups are a way to manage access, policies, and compliance for multiple subscriptions. They provide a way to manage access, policies, and compliance for multiple subscriptions. Management groups are containers that help you manage access, policy, and compliance for multiple subscriptions. You organize subscriptions into containers called \"management groups\" and apply your governance conditions to the management groups. All subscriptions within a management group automatically inherit the conditions applied to the management group.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#management-groups-hierarchy","title":"Management Groups Hierarchy","text":"<p>The management group hierarchy is a level of management groups that represent the different levels of your organization. The hierarchy starts with a single root management group, which represents the Microsoft Entra ID tenant. The root management group is the highest level in the hierarchy. All other management groups are subgroups of the root management group.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#management-group-design-considerations","title":"Management group design considerations","text":"<p>When designing your management group hierarchy, consider the following:</p> <ul> <li> <p>How does your organization differentiate services that are managed or run by particular teams?</p> </li> <li> <p>Are there any specific operations that need to be isolated due to business or regulatory compliance requirements?</p> </li> <li> <p>Management groups can be utilized to consolidate policy and initiative assignments through Azure Policy.</p> </li> <li> <p>A management group hierarchy can accommodate up to six nested levels. The tenant root level and the subscription level are not included in this count.</p> </li> <li> <p>Any principal, be it a user or service principal, within a Microsoft Entra tenant has the authority to establish new management groups. This is due to the fact that Azure role-based access control (RBAC) authorization for managing group activities is not activated by default. For additional details, refer to the guide on safeguarding your resource hierarchy.</p> </li> <li> <p>By default, all newly created subscriptions will be assigned to the tenant root management group.</p> </li> </ul>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#management-group-recommendations","title":"Management group recommendations","text":"<ul> <li> <p>Maintain a relatively flat management group hierarchy, ideally with three to four levels maximum. This practice minimizes managerial complexity and overhead.</p> </li> <li> <p>Refrain from mirroring your organizational structure into a deeply nested management group hierarchy. Utilize management groups primarily for policy assignment rather than billing. This strategy aligns with the Azure landing zone conceptual architecture, which applies Azure policies to workloads that need similar security and compliance at the same management group level.</p> </li> <li> <p>Establish management groups under your root-level group representing different types of workloads you will host. These groups should reflect the security, compliance, connectivity, and feature requirements of the workloads. By doing this, you can apply a set of Azure policies at the management group level for all workloads with similar needs.</p> </li> <li> <p>Leverage resource tags for querying and horizontally traversing across the management group hierarchy. Resource tags, enforced or appended via Azure Policy, allow you to group resources for search purposes without relying on a complex management group hierarchy.</p> </li> <li> <p>Set up a top-level sandbox management group. This allows users to immediately experiment with Azure and try out resources not yet permitted in production environments. The sandbox provides isolation from your development, testing, and production settings.</p> </li> <li> <p>Create a platform management group beneath the root management group to support common platform policy and Azure role assignments. This ensures distinct policies can be applied to subscriptions used for your Azure foundation and centralizes billing for common resources in one foundational subscription set.</p> </li> <li> <p>Minimize the number of Azure Policy assignments made at the root management group scope. This reduces the debugging of inherited policies in lower-level management groups.</p> </li> <li> <p>Implement policies to enforce compliance requirements either at the management group or subscription scope to achieve policy-driven governance.</p> </li> <li> <p>Ensure only privileged users have operational access to management groups in the tenant. Enable Azure RBAC authorization in the management group hierarchy settings to fine-tune user privileges. By default, all users are authorized to create their own management groups under the root management group.</p> </li> <li> <p>Set up a default, dedicated management group for new subscriptions. This prevents any subscriptions from being placed under the root management group. This is particularly important if there are users eligible for Microsoft Developer Network (MSDN) or Visual Studio benefits and subscriptions. A sandbox management group could be a suitable candidate for this type of management group. For more information, see Setting - default management group.</p> </li> <li> <p>Avoid creating management groups for production, testing, and development environments. If needed, separate these groups into different subscriptions within the same management group.</p> </li> </ul>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#management-group-structure-in-the-enterprise-scale-landing-zone","title":"Management Group Structure in the Enterprise Scale Landing Zone","text":"<p>This is the common structure for the Management Groups in the Enterprise Scale Landing Zone: </p> <pre><code>    graph TD\n        A[Root Management Group] --&gt; B[Intermediary-Management-Group]\n        B --&gt; C[Decommissioned]\n        B --&gt; D[Landing Zones]\n        B --&gt; E[Platform]\n        B --&gt; F[Sandboxes]\n        D --&gt; G[Corp]\n        D --&gt; H[Online]\n        E --&gt; I[Connectivity]\n        E --&gt; J[Identity]\n        E --&gt; K[Management]\n</code></pre> <ol> <li>Root Management Group<ul> <li>Intermediary-Management-Group<ul> <li>Decommissioned: This could be where resources that are being phased out or decommissioned are managed.</li> <li>Sandboxes: This could be an area where developers can test and experiment without affecting production systems.</li> <li>Landing Zones<ul> <li>Corp: This could represent corporate resources or applications.</li> <li>Online: This could represent online or customer-facing applications.</li> </ul> </li> <li>Platform<ul> <li>Connectivity: This could manage resources related to network connectivity.</li> <li>Identity: This could manage resources related to identity and access management.</li> <li>Management: This could manage resources related to overall platform management.</li> </ul> </li> </ul> </li> </ul> </li> </ol> <p>This structure allows for clear segmentation of resources based on their purpose and lifecycle. For example, decommissioned resources are separated from active ones, like Sandbox, and resources within the 'Platform' are further categorized based on their function (Connectivity, Identity, Management). The 'Landing Zones' group appears to separate resources based on their use case or environment (Corp, Online).</p> <p>The exact interpretation would depend on the specific context and conventions of your organization.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#bad-examples","title":"Bad Examples","text":"","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#example-1-deeply-nested-hierarchy","title":"Example 1: Deeply Nested Hierarchy","text":"<pre><code>graph TD\n    A[Root Management Group] --&gt; B[Group 1]\n    B --&gt; C[Group 2]\n    C --&gt; D[Group 3]\n    D --&gt; E[Group 4]\n    E --&gt; F[Group 5]\n    F --&gt; G[Group 6]\n</code></pre> <p>Why it's bad: This hierarchy is too deep. It becomes difficult to manage and increases complexity. Azure supports up to six levels of nested management groups but it's recommended to keep the hierarchy as flat as possible for simplicity.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#example-2-unorganized-structure","title":"Example 2: Unorganized Structure","text":"<pre><code>graph TD\n    A[Root Management Group] --&gt; B[Group 1]\n    A --&gt; C[Group 2]\n    B --&gt; D[Group 3]\n    C --&gt; E[Group 4]\n    D --&gt; F[Group 5]\n    E --&gt; G[Group 6]\n</code></pre> <p>Why it's bad: The structure is not well-organized and doesn't follow a logical grouping or hierarchy. This can lead to confusion and difficulty in managing resources and policies.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#example-3-single-level-hierarchy","title":"Example 3: Single Level Hierarchy","text":"<pre><code>graph TD\n    A[Root Management Group] --&gt; B[Group 1]\n    A --&gt; C[Group 2]\n    A --&gt; D[Group 3]\n    A --&gt; E[Group 4]\n    A --&gt; F[Group 5]\n    A --&gt; G[Group 6]\n</code></pre> <p>Why it's bad: Although this structure is simple, it lacks the ability to group related subscriptions together under a common management group. This makes it harder to apply consistent policies across related subscriptions.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#example-4-environment-based-hierarchy","title":"Example 4: Environment-Based Hierarchy","text":"<pre><code>\ngraph TD\n    A[Root Management Group] --&gt; B[Production Management Group]\n    A[Root Management Group] --&gt; C[Development Management Group]\n    A[Root Management Group] --&gt; D[Testing Management Group]\n</code></pre> <p>Why it's bad: This structure separates environments into different management groups, which can lead to duplication of policies and increased complexity. It's better to use subscriptions within the same management group to separate environments and apply policies accordingly.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#good-examples","title":"Good examples","text":"<pre><code>    graph TD\n        A[Root Management Group] --&gt; B[Intermediary-Management-Group]\n        B --&gt; C[Decommissioned]\n        B --&gt; D[Landing Zones]\n        B --&gt; E[Platform]\n        B --&gt; F[Sandboxes]\n        D --&gt; G[Corp]\n        D --&gt; H[Online]\n        E --&gt; I[Connectivity]\n        E --&gt; J[Identity]\n        E --&gt; K[Management]\n</code></pre>","tags":["Management Groups"]},{"location":"blog/2024/04/22/management-groups/#references","title":"References","text":"<ul> <li>https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/resource-org-management-groups</li> <li>https://learn.microsoft.com/en-us/azure/governance/management-groups/overview</li> </ul>","tags":["Management Groups"]},{"location":"blog/2024/04/23/moving-management-groups-and-subscriptions/","title":"Moving Management Groups and Subscriptions","text":"<p>Managing your Azure resources efficiently often involves moving management groups and subscriptions. Here's a brief guide on how to do it:</p>","tags":["Management Groups"]},{"location":"blog/2024/04/23/moving-management-groups-and-subscriptions/#moving-management-groups","title":"Moving Management Groups","text":"<p>To move a management group, you need to have the necessary permissions. You must be an owner of the target parent management group and have <code>Management Group Contributor</code> role at the group you want to move.</p> <p>Here's the step-by-step process:</p> <ol> <li>Navigate to the Azure portal.</li> <li>Go to Management groups.</li> <li>Select the management group you want to move.</li> <li>Click Details.</li> <li>Under Parent group, click Change.</li> <li>Choose the new parent group from the list and click Save.</li> </ol> <p>Remember, moving a management group will also move all its child resources including other management groups and subscriptions.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/23/moving-management-groups-and-subscriptions/#moving-subscriptions","title":"Moving Subscriptions","text":"<p>You can move a subscription from one management group to another or within the same management group. To do this, you must have the <code>Owner</code> or <code>Contributor</code> role at the target management group and <code>Owner</code> role at the subscription level.</p> <p>Follow these steps:</p> <ol> <li>Go to the Azure portal.</li> <li>Navigate to Management groups.</li> <li>Select the management group where the subscription currently resides.</li> <li>Click on Subscriptions.</li> <li>Find the subscription you want to move and select ...\" (More options).</li> <li>Click Change parent.</li> <li>In the pop-up window, select the new parent management group and click Save.</li> </ol> <p>Note</p> <p>Moving subscriptions could affect the resources if there are policies or permissions applied at the management group level. It's important to understand the implications before making the move. Also, keep in mind that you cannot move the Root management group or rename it.</p> <p>In conclusion, moving management groups and subscriptions allows for better organization and management of your Azure resources. However, it should be done carefully considering the impact on resources and compliance with assigned policies.</p>","tags":["Management Groups"]},{"location":"blog/2024/04/24/how-to-create-a-management-group-diagram-with-drawio/","title":"How to create a Management Group diagram with draw.io","text":"<p>I nedd to create a diagram of the Management Groups in Azure, and I remembered a project that did something similar but with PowerShell: https://github.com/PowerShellToday/new-mgmgroupdiagram.</p>","tags":["Management Groups","draw.io"]},{"location":"blog/2024/04/24/how-to-create-a-management-group-diagram-with-drawio/#export-your-management-group-structure-from-azure-portal-or-ask-for-it","title":"Export your Management Group structure from Azure Portal or ask for it","text":"<p>If you can access the Azure Portal, you can export the Management Group structure to a CSV file. To do this, follow these steps:</p> <ol> <li>Go to the Azure portal.</li> <li>Navigate to Management groups.</li> <li>Click on Export.</li> <li>Save the CSV file to your local machine.</li> </ol> <p>If you don't have access to the Azure Portal, you can ask your Azure administrator to export the Management Group structure for you.</p> <p>The file has the following columns:</p> <ul> <li>id: The unique identifier of the Management Group or subscription.</li> <li>displayName: The name of the Management Group or subscription.</li> <li>itemType: The type of the item (Management Group or subscription).</li> <li>path: The path to the management or subscription group, its parent.</li> <li>accessLevel: Your access level.</li> <li>childSubscriptionCount: The number of child subscriptions at this level.</li> <li>totalSubscriptionCount: The total number of subscriptions.</li> </ul>","tags":["Management Groups","draw.io"]},{"location":"blog/2024/04/24/how-to-create-a-management-group-diagram-with-drawio/#create-a-csv-to-be-imported-into-drawio","title":"Create a CSV to be imported into draw.io","text":"<ol> <li>Import the CSV file to excel, rename the sheet to \"Export_Portal\"</li> <li>Create a second sheet with the following columns:<ul> <li>id: reference to the id in the first sheet</li> <li>displayName: reference to the displayName in the first sheet</li> <li>itemType: reference to the itemType in the first sheet</li> <li>ParentId: Use the following formula to get the parent of the current item:     <pre><code>=IF(ISERROR(FIND(\",\"; Export_Portal!D2)); Export_Portal!D2; TRIM(RIGHT(SUBSTITUTE(Export_Portal!D2; \",\"; REPT(\" \"; LEN(Export_Portal!D2))); LEN(Export_Portal!D2))))\n</code></pre></li> </ul> </li> <li>Export the second sheet to a CSV file.</li> </ol>","tags":["Management Groups","draw.io"]},{"location":"blog/2024/04/24/how-to-create-a-management-group-diagram-with-drawio/#import-the-csv-file-into-drawio","title":"Import the CSV file into draw.io","text":"<ol> <li>Go to draw.io and create a new diagram.</li> <li>Click on Arrange &gt; Insert &gt; Advanced &gt; CSV.</li> <li> <p>Insert the header for the columns: id, displayName, itemType, Parent:</p> <p><pre><code>    #label: %displayName%\n    #stylename: itemType\n    #styles: {\"Management Group\": \"label;image=img/lib/azure2/general/Management_Groups.svg;whiteSpace=wrap;html=1;rounded=1; fillColor=%fill%;strokeColor=#6c8ebf;fillColor=#dae8fc;points=[[0.5,0,0,0,0],[0.5,1,0,0,0]];\",\\\n    #\"Subscription\": \"label;image=img/lib/azure2/general/Subscriptions.svg;whiteSpace=wrap;html=1;rounded=1; fillColor=%fill%;strokeColor=#d6b656;fillColor=#fff2cc;points=[[0.5,0,0,0,0],[0.5,1,0,0,0]];imageWidth=26;\"}\n    #\n    #\n    #namespace: csvimport-\n    #\n    #connect: {\"from\": \"ParentId\", \"to\": \"displayName\", \"invert\": true, \"style\": \"curved=1;endArrow=blockThin;endFill=1;fontSize=11;edgeStyle=orthogonalEdgeStyle;\"}\n    #\n    ## Node width and height, and padding for autosize\n    #width: auto\n    #height: auto\n    #padding: -12\n    #\n    ## ignore: id,image,fill,stroke,refs,manager\n    #\n    ## Column to be renamed to link attribute (used as link).\n    ## link: url\n    #\n    ## Spacing between nodes, heirarchical levels and parallel connections.\n    #nodespacing: 40\n    #levelspacing: 100\n    #edgespacing: 40\n    #\n    ## layout: auto\n    #layout: verticaltree\n    #\n    ## ---- CSV below this line. First line are column names. ----\n</code></pre> 4. Paste the content of the CSV file and click on Import.</p> </li> </ol> <p>You should see a diagram with the Management Groups and Subscriptions.</p> <p>For example:</p> <p>This is the common structure for the Management Groups in the Enterprise Scale Landing Zone, now Accelerator Landing Zone: </p> <pre><code>    graph TD\n        A[Root Management Group] --&gt; B[Intermediary-Management-Group]\n        B --&gt; C[Decommissioned]\n        B --&gt; D[Landing Zones]\n        B --&gt; E[Platform]\n        B --&gt; F[Sandboxes]\n        D --&gt; G[Corp]\n        D --&gt; H[Online]\n        E --&gt; I[Connectivity]\n        E --&gt; J[Identity]\n        E --&gt; K[Management]        \n</code></pre> <p>And this is the CSV file to import into draw.io:</p> <pre><code>#label: %displayName%\n#stylename: itemType\n#styles: {\"Management Group\": \"label;image=img/lib/azure2/general/Management_Groups.svg;whiteSpace=wrap;html=1;rounded=1; fillColor=%fill%;strokeColor=#6c8ebf;fillColor=#dae8fc;points=[[0.5,0,0,0,0],[0.5,1,0,0,0]];\",\\\n#\"Subscription\": \"label;image=img/lib/azure2/general/Subscriptions.svg;whiteSpace=wrap;html=1;rounded=1; fillColor=%fill%;strokeColor=#d6b656;fillColor=#fff2cc;points=[[0.5,0,0,0,0],[0.5,1,0,0,0]];imageWidth=26;\"}\n#\n#\n#namespace: csvimport-\n#\n#connect: {\"from\": \"ParentId\", \"to\": \"displayName\", \"invert\": true, \"style\": \"curved=1;endArrow=blockThin;endFill=1;fontSize=11;edgeStyle=orthogonalEdgeStyle;\"}\n#\n## Node width and height, and padding for autosize\n#width: auto\n#height: auto\n#padding: -12\n#\n## ignore: id,image,fill,stroke,refs,manager\n#\n## Column to be renamed to link attribute (used as link).\n## link: url\n#\n## Spacing between nodes, heirarchical levels and parallel connections.\n#nodespacing: 40\n#levelspacing: 100\n#edgespacing: 40\n#\n## layout: auto\n#layout: verticaltree\n#\n## ---- CSV below this line. First line are column names. ----\nid,displayName,itemType,ParentId\n1,Tenant Root Group,Management Group,\n2,Intermediary Management Group,Management Group,Tenant Root Group\n3,Decommissioned,Management Group,Intermediary Management Group\n4,Landing Zones,Management Group,Intermediary Management Group\n5,Platform,Management Group,Intermediary Management Group\n6,Sandboxes,Management Group,Landing Zones\n7,Corp,Management Group,Landing Zones\n8,Online,Management Group,Landing Zones\n9,Connectivity,Management Group,Platform\n10,Identity,Management Group,Platform\n11,Management,Management Group,Platform\n12,subcr-1,Subscription,Decommissioned\n13,subcr-2,Subscription,Sandboxes\n14,subcr-3,Subscription,Corp\n15,subcr-4,Subscription,Online\n16,subcr-5,Subscription,Connectivity\n17,subcr-6,Subscription,Identity\n18,subcr-7,Subscription,Management\n</code></pre>","tags":["Management Groups","draw.io"]},{"location":"blog/2024/04/24/how-to-create-a-management-group-diagram-with-drawio/#make-your-diagram-animated-and-interactive","title":"Make your diagram animated and interactive","text":"<p>You can make your diagram animated and interactive by following these steps:</p> <ol> <li>File &gt; Export as &gt; URL</li> <li>Add p=ex&amp; after the first ? in the URL.</li> </ol> <p>For example, the URL should look like this:</p> <pre><code>https://viewer.diagrams.net/?p=ex&amp;tags=%7B%7D&amp;highlight=0000ff&amp;layers=1&amp;nav=1&amp;title=MGs.drawio#R7Zxbc5s4FMc%2FjR%2BbAQkEPK7dJHWn3XbW6exMX3ZkkLFakDxCvvXTr7jFxrZi1k0Wg5lxYnR0QfqfHxqOBB7AUbx5FHgx%2F8wDEg2AEWwG8P0AAGAgQ32llm1uMU0X5pZQ0KCw7QwT%2BosUxqJiuKQBSSoFJeeRpIuq0eeMEV9WbFgIvq4Wm%2FGoetYFDsmRYeLj6Nj6Nw3kvBwG8nYZHwgN58WpXeDkGTEuCxcjSeY44Os9E7wfwJHgXOZH8WZEolS9Upe83oMm97ljgjB5osK3hIgv0x%2BpJsCI8FQ5Jis0AHZAk0WEt3%2FimKhU3k7Z7HBLxq7x42mcwOHy%2B0dn9PCRvIOFz%2FYrZqWfCMMsPcFf6TCA8Sj4clE0KEn8tF0UBT9jpoSKCTso9TXr%2Fjgo%2B5YNKcI%2BmStHEbHvvKoMidyWLioGN6Rx7ksah0qFiE7Vf%2FxrKUgqSkgYEVjVfNh15Z%2BsI8ldsgpV9fVcdXmyUOdWbawVzso2l3Eqm6kOVVEWkKBIpSjRKBrxiIusF3aaTNWEw0QK%2FpPssiDyXTKdqZxqFRhg4s58ZV9wymQ2VnuoPsadcsrIqPzZqsLoOc88zFOftFOpfCsiJNloIdnX8pHwmEixVUWKCpYD7goituU1nCfXO%2FqB4ea2%2BR74dmHDhc%2FC57Z3TKqDwoFlco%2FS16fW0lA7ZpKImAQUZ0PXsXkJwS9cED3WDWINnQOsTegec%2B20g2tbw%2FV74vM4pklCOVMuvRjimtdHD3RzQJezcjlJ2%2BiIZtNrB81IQ%2FMnzALKFCLGd4Vz0uPcYZyhZ57nuSWzs6Ph%2BWuE5YyLuAe5wyB7rn0eZKsdILsakCdqYp7yze9MySfn9p7bBu8nAKxwCx3rmFvUDm49DbcjLn4jsuuRvTJkLWieRxa0AlnL0CD7hUWUkR7azkBre955aGE7oDW182y2FE9XVG4vR7d6u9wz2xyzjuN05d7AAhpmx4ESo%2Be1E7wexmBtnmN1G2%2F7TPbEtp1Y00Q1wq92rH9Zul23ZDn1xTvzFK%2BT5TTxBV1IytkpUk9tbLwxr%2FtdentWAzRFNjpmdTabAf8VWc0GXz7HANAr3dPWmG5bEofpdtZydsEl7B6slvXYXgu2wKrOuZYHWsutbg8t5xZewu1utaxH9lqQPVzyajOyum2yHFnrEmT3V8t6aK8FWmRYnYFWtyWWQ2tfAu3xalmP7rWg63hOZ9DV7Yrl6KJL0K0umvXYXgu2nmd0BVtbtzOWY%2Btcgu3h2lkP7rWAa5qu2yS5Ry9ZnGayGNcKR0tSog2qjPhLsXp2IGHBH%2BmrKCo5jbj%2F82lOWW5%2BSB2ZF5pxJovXX8ysUhCSSdEgF3LOQ85wdL%2BzFoKn5V6WW3WML4VPXhhS%2BYKHxCIk8qWC1mkHChJhdQ9T7cl%2FcEZN5UH3lLfqKm83qjy8YeVRo8pbN6y806jydveUR3WVdxtVHt2w8l6jyju3q3z%2BFF5jyrvdU96pq7wmLPiflPduWHnQpPLlrwPcpPKwUeU7GMPadZVvNIZFHYxh3brKNxrDog7GsF5d5RuNYVH3YtjylY3zyjcaw6LuxbDlewfnlW80hkXdi2HLp%2BfPK99oDIu6F8Naddfn7TeKYVVy90tVWd7eD37B%2B38B#%7B%22pageId%22%3A%22UGUHswWqf16rUITyRAQM%22%7D\n</code></pre> <p>You can check it here</p>","tags":["Management Groups","draw.io"]},{"location":"blog/2024/04/24/how-to-create-a-management-group-diagram-with-drawio/#references","title":"References","text":"<ul> <li>Automatically create draw.io diagrams from CSV files</li> <li>Animation and Automatic Layout: Explore Complex Diagrams</li> </ul>","tags":["Management Groups","draw.io"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/","title":"What you need to think about when starting an IaC project ?","text":"<p>Infrastructure as Code (IaC) is a key practice in modern software development that allows you to manage your infrastructure in a declarative manner. With IaC, you can define your infrastructure using code, which can be version-controlled, tested, and deployed automatically. This approach brings several benefits, such as increased consistency, repeatability, and scalability.</p> <p>When starting an IaC project, there are several key considerations you need to keep in mind to ensure its success. In this article, we will discuss some of the key things you should think about when embarking on an IaC project.</p>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#1-define-your-goals","title":"1. Define Your Goals","text":"<p>Before you start writing any code, it's essential to define your goals for the IaC project. What are you trying to achieve with IaC? Are you looking to automate the provisioning of infrastructure, improve consistency, or increase scalability? By clearly defining your goals, you can ensure that your IaC project is aligned with your organization's objectives.</p> <p>Some examples: </p> <ul> <li>Automate the provisioning of infrastructure</li> <li>Improve consistency and repeatability</li> <li>Increase scalability and reduce manual effort</li> <li>Enhance security and compliance</li> <li>Enable faster development and deployment cycles</li> </ul>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#2-select-the-right-tools","title":"2. Select the Right Tools","text":"<p>Choosing the right tools is crucial for the success of your IaC project. There are several IaC tools available, such as Terraform, Ansible, and AWS CloudFormation, each with its strengths and weaknesses. Consider factors such as ease of use, scalability, and integration with your existing tools when selecting an IaC tool.</p> <p>Some examples:</p> <ul> <li>Terraform: A popular IaC tool that allows you to define your infrastructure using a declarative configuration language.</li> <li>Ansible: A configuration management tool that can also be used for IaC.</li> <li>AWS CloudFormation: A service provided by AWS that allows you to define your infrastructure using JSON or YAML templates.</li> <li>Azure Resource Manager (ARM) templates: A service provided by Azure that allows you to define your infrastructure using JSON templates.</li> <li>Bicep: A domain-specific language for defining Azure resources that compiles to ARM templates.</li> <li>Pulumi: A tool that allows you to define your infrastructure using familiar programming languages such as Python, JavaScript, and Go.</li> <li>Chef: A configuration management tool that can also be used for IaC.</li> </ul>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#3-design-your-infrastructure","title":"3. Design Your Infrastructure","text":"<p>When designing your infrastructure, think about how you want to structure your code. Consider using modular designs that allow you to reuse code across different projects. Define your infrastructure in a way that is easy to understand and maintain, and follow best practices for code organization.</p>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#4-version-control-your-code","title":"4. Version Control Your Code","text":"<p>Version control is a fundamental practice in software development, and it is equally important for IaC projects. By using version control systems such as Git, you can track changes to your infrastructure code, collaborate with team members, and roll back changes if needed. Make sure to follow best practices for version control, such as using descriptive commit messages and branching strategies.</p> <p>Some examples:</p> <ul> <li>Use Git for version control</li> <li>Use branching strategies like Microsoft Flow or GitHub Flow to manage your codebase</li> <li>Use pull requests for code reviews</li> <li>Automate your CI/CD pipelines to run tests and deploy changes</li> <li>Use tags to mark releases or milestones</li> </ul>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#5-automate-testing","title":"5. Automate Testing","text":"<p>Testing is an essential part of any software development project, and IaC is no exception. Automating your tests can help you catch errors early in the development process and ensure that your infrastructure code is working as expected. Consider using tools such as Terraform's built-in testing framework or third-party testing tools to automate your tests.</p> <p>Some examples:</p> <ul> <li>Use Terraform's built-in testing framework to write unit tests for your infrastructure code</li> <li>Use tools like Terratest or Kitchen-Terraform to write integration tests for your infrastructure code</li> <li>Use static code analysis tools to check for common errors and best practices in your infrastructure code, like Terraform's <code>terraform validate</code> command, or tools like <code>tfsec</code> or <code>checkov</code>.</li> <li>Use linting tools to enforce coding standards and style guidelines in your infrastructure code, like Terraform's <code>terraform fmt</code> command, or tools like <code>tflint</code> or <code>checkov</code>.</li> <li>Use security scanning tools to identify potential security vulnerabilities in your infrastructure code.</li> </ul>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#6-implement-continuous-integrationcontinuous-deployment-cicd","title":"6. Implement Continuous Integration/Continuous Deployment (CI/CD)","text":"<p>CI/CD pipelines are a key component of modern software development practices, and they are equally important for IaC projects. By implementing CI/CD pipelines, you can automate the testing, building, and deployment of your infrastructure code, reducing the risk of errors and speeding up the development process. Consider using tools such as Github or Azure DevOps to set up your CI/CD pipelines.</p> <p>Use tools like Terraform Cloud, Azure DevOps, or Github Actions to automate your CI/CD pipelines.</p>","tags":["IaC"]},{"location":"blog/2024/04/26/what-you-need-to-think-about-when-starting-an-iac-project-/#7-monitor-and-maintain-your-infrastructure","title":"7. Monitor and Maintain Your Infrastructure","text":"<p>Once your IaC project is up and running, it's essential to monitor and maintain your infrastructure. Implement monitoring solutions that allow you to track the health and performance of your infrastructure, and set up alerts to notify you of any issues. Regularly review and update your infrastructure code to ensure that it remains up-to-date and secure.</p> <p>By keeping these key considerations in mind when starting an IaC project, you can set yourself up for success and ensure that your infrastructure is managed efficiently and effectively. IaC is a powerful practice that can help you automate and scale your infrastructure, and by following best practices, you can maximize the benefits of this approach.</p>","tags":["IaC"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/","title":"Starting my IaC project with terraform","text":"<p>This is not my first IaC project but I want to share with you some key considerations that I have in mind to start a personal IaC project with Terraform based on post What you need to think about when starting an IaC project ?</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#1-define-your-goals","title":"1. Define Your Goals","text":"<p>These are my goals:</p> <ul> <li>Automate the provisioning of infrastructure</li> <li>Improve consistency and repeatability</li> <li>Reduce manual effort</li> <li>Enable faster deployments</li> </ul>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#2-select-the-right-tools","title":"2. Select the Right Tools","text":"<p>For my project I will use Terraform because I am familiar with it and I like its declarative configuration language.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#3-design-your-infrastructure","title":"3. Design Your Infrastructure","text":"<p>In my project, I will use a modular design that separates my infrastructure into different modules, such as networking, compute, and storage. This will allow me to reuse code across different projects and make my infrastructure more maintainable.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#4-version-control-your-code","title":"4. Version Control Your Code","text":"<p>I will use Git for version control and follow best practices for version control, such as using descriptive commit messages and branching strategies.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#5-automate-testing","title":"5. Automate Testing","text":"<p>Like appear in Implement compliance testing with Terraform and Azure, I'd  like to implement: </p> <ul> <li>Compliance testing</li> <li>End-to-end testing</li> <li>Integration testing</li> </ul>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#6-implement-continuous-integrationcontinuous-deployment-cicd","title":"6. Implement Continuous Integration/Continuous Deployment (CI/CD)","text":"<p>I set up my  CI/CD pipelines with Github Actions.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/27/starting-my-iac-project-with-terraform/#7-monitor-and-maintain-your-infrastructure","title":"7. Monitor and Maintain Your Infrastructure","text":"<p>I will use Azure Monitor to monitor my infrastructure and set up alerts to notify me of any issues. I will also regularly review and update my infrastructure code to ensure that it remains up to date and secure.</p> <p>Of course I don't have all the answers yet, but I will keep you updated on my progress and share my learnings along the way. Stay tuned for more updates on my IaC project with Terraform!</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/04/28/terraform-configuration-language/","title":"Terraform: Configuration Language","text":"<p>After deciding to use Terraform for my Infrastructure as Code (IaC) project,  Terraform configuration language must be understanded to define the desired state of my infrastructure.</p> <p>Info</p> <p>I will update this post with more information about Terraform configuration language in the future.</p> <p>Terraform uses a declarative configuration language to define the desired state of your infrastructure. This configuration language is designed to be human-readable and easy to understand, making it accessible to both developers and operations teams.</p>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#declarative-vs-imperative","title":"Declarative vs. Imperative","text":"<p>Terraform's configuration language is declarative, meaning that you define the desired state of your infrastructure without specifying the exact steps needed to achieve that state. This is in contrast to imperative languages, where you specify the exact sequence of steps needed to achieve a desired outcome.</p> <p>For example, in an imperative language, you might write a script that creates a virtual machine by executing a series of commands to provision the necessary resources. In a declarative language like Terraform, you would simply define the desired state of the virtual machine (e.g., its size, image, and network configuration) and let Terraform figure out the steps needed to achieve that state.</p>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#configuration-blocks","title":"Configuration Blocks","text":"<p>Terraform uses configuration blocks to define different aspects of your infrastructure. Each block has a specific purpose and contains configuration settings that define how that aspect of your infrastructure should be provisioned.</p> <p>For example, you might use a <code>provider</code> block to define the cloud provider you want to use, a <code>resource</code> block to define a specific resource (e.g., a virtual machine or storage account), or a <code>variable</code> block to define input variables that can be passed to your configuration.</p> <pre><code>provider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"example-resources\"\n  location = \"East US\"\n}\n\nvariable \"location\" {\n  type    = string\n  default = \"East US\"\n}\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#variables","title":"Variables","text":"<p>Terraform allows you to define variables that can be used to parameterize your configuration. Variables can be used to pass values into your configuration, making it easier to reuse and customize your infrastructure definitions.</p> <pre><code>variable \"location\" {\n  type    = string\n  default = \"East US\"\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = \"example-resources\"\n  location = var.location\n}\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#locals","title":"locals","text":"<p>Terraform allows you to define local values that can be used within your configuration. Locals are similar to variables but are only available within the current module or configuration block.</p> <pre><code>variable \"location\" {\n  type    = string\n  default = \"East US\"\n}\n\nlocals {\n  resource_group_name = \"example-resources\"\n}\n\nresource \"azurerm_resource_group\" \"example\" {\n  name     = local.resource_group_name\n  location = var.location\n}\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#data-sources","title":"Data Sources","text":"<p>Terraform allows you to define data sources that can be used to query external resources and retrieve information that can be used in your configuration. Data sources are read-only and can be used to fetch information about existing resources, such as virtual networks, storage accounts, or database instances.</p> <pre><code>data \"azurerm_resource_group\" \"example\" {\n  name = \"example-resources\"\n}\n\nresource \"azurerm_virtual_network\" \"example\" {\n  name                = \"example-network\"\n  location            = data.azurerm_resource_group.example.location\n  resource_group_name = data.azurerm_resource_group.example.name\n}\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#functions","title":"Functions","text":"","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#try","title":"try","text":"<p>The <code>try</code> function allows you to provide a default value in case an expression returns an error. This can be useful when working with optional values that may or may not be present.</p> <pre><code>variable \"optional_value\" {\n  type    = string\n  default = null\n}\n\nlocals {\n  value = try(var.optional_value, \"default_value\")\n}\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#debugging-terraform","title":"Debugging Terraform","text":"<p>You can use the <code>TF_LOG</code> environment variable to enable debug logging in Terraform. This can be useful when troubleshooting issues with your infrastructure or understanding how Terraform is executing your configuration.</p> <pre><code>export TF_LOG=DEBUG\nterraform plan\n</code></pre> <p>TOu can use the following decreasing verbosity levels log:  TRACE, DEBUG, INFO, WARN or ERROR</p> <p>To persist logged output logs in a file:</p> <pre><code>export TF_LOG_PATH=\"terraform.log\"\n</code></pre> <p>To separare logs for Terraform and provider, you can use the following environment variables TF_LOG_CORE and TF_LOG_PROVIDER respectively. For example, to enable debug logging for both Terraform and the Azure provider, you can use the following environment variables:</p> <pre><code>export TF_LOG_CORE=DEBUG\nexport TF_LOG_PATH=\"terraform.log\"\n</code></pre> <p>or </p> <pre><code>export TF_LOG_PROVIDER=DEBUG\nexport TF_LOG_PATH=\"provider.log\"\n</code></pre> <p>To disable debug logging, you can unset the <code>TF_LOG</code> environment variable:</p> <pre><code>unset TF_LOG\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-configuration-language/#references","title":"References","text":"<ul> <li>Terraform Configuration Language</li> <li>Terraform Functions</li> <li>Terraform Debugging</li> </ul>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/","title":"Terraform: Set your local environment developer","text":"<p>I wil use Ubuntu in WSL v2 as my local environment for my IaC project with Terraform. I will install the following tools:</p> <ul> <li>vscode</li> <li>Trunk</li> <li>tenv</li> <li>az cli</li> </ul>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/#az-cli","title":"az cli","text":"<p>I will use the Azure CLI to interact with Azure resources from the command line. I will install the Azure CLI using the following commands:</p> <pre><code>curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/#vscode","title":"vscode","text":"<p>I will use Visual Studio Code as my code editor for my IaC project with Terraform. I will install the following extensions:</p> <ul> <li>Terraform</li> <li>Azure Terraform</li> <li>Azure Account</li> <li>Trunk</li> </ul>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/#tenv","title":"tenv","text":"<p><code>tenv</code> is a tool that allows you to manage multiple Terraform environments with ease. It provides a simple way to switch between different environments, such as development, staging, and production, by managing environment variables and state files for each environment.</p>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/#installation","title":"Installation","text":"<p>You can install <code>tenv</code> using <code>go get</code>:</p> <pre><code>LATEST_VERSION=$(curl --silent https://api.github.com/repos/tofuutils/tenv/releases/latest | jq -r .tag_name)\ncurl -O -L \"https://github.com/tofuutils/tenv/releases/latest/download/tenv_${LATEST_VERSION}_amd64.deb\"\nsudo dpkg -i \"tenv_${LATEST_VERSION}_amd64.deb\"\n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/#usage","title":"Usage","text":"<p>To create a new environment, you can use the <code>tenv create</code> command:</p> <pre><code># to install the latest version of Terraform\ntenv tf install \n</code></pre>","tags":["Terraform"]},{"location":"blog/2024/04/28/terraform-set-your-local-environment-developer/#references","title":"References","text":"<ul> <li>tenv</li> </ul>","tags":["Terraform"]},{"location":"blog/2024/04/29/repository-strategy-monorepo-vs-multi-repo/","title":"Repository Strategy: Monorepo vs Multi-repo","text":"<p>In this post, I will explain the repository strategy that I will use for my Infrastructure as Code (IaC) project with Terraform. </p>","tags":["git"]},{"location":"blog/2024/04/29/repository-strategy-monorepo-vs-multi-repo/#monorepo","title":"Monorepo","text":"<p>A monorepo is a single repository that contains all the code for a project. </p> <p>The benefits of using a monorepo include:</p> <ul> <li>Simplicity: All the code is in one place, making it easier to manage and maintain.</li> <li>Consistency: Developers can easily see all the code related to a project and ensure that it follows the same standards and conventions.</li> <li>Reusability: Code can be shared across different parts of the project, reducing duplication and improving consistency.</li> <li>Versioning: All the code is versioned together, making it easier to track changes and roll back if necessary.</li> </ul> <p>The challenges of using a monorepo include:</p> <ul> <li>Complexity: A monorepo can become large and complex, making it harder to navigate and understand.</li> <li>Build times: Building and testing a monorepo can take longer than building and testing smaller repositories.</li> <li>Conflicts: Multiple developers working on the same codebase can lead to conflicts and merge issues.</li> </ul>","tags":["git"]},{"location":"blog/2024/04/29/repository-strategy-monorepo-vs-multi-repo/#multi-repo","title":"Multi-repo","text":"<p>A multi-repo is a set of separate repositories that contain the code for different parts of a project.</p> <p>The benefits of using a multi-repo include:</p> <ul> <li>Isolation: Each repository is independent, making it easier to manage and maintain.</li> <li>Flexibility: Developers can work on different parts of the project without affecting each other.</li> <li>Scalability: As the project grows, new repositories can be added to manage the code more effectively.</li> </ul> <p>The challenges of using a multi-repo include:</p> <ul> <li>Complexity: Managing multiple repositories can be more challenging than managing a single repository.</li> <li>Consistency: Ensuring that all the repositories follow the same standards and conventions can be difficult.</li> <li>Versioning: Each repository is versioned separately, making it harder to track changes across the project.</li> </ul>","tags":["git"]},{"location":"blog/2024/04/29/repository-strategy-monorepo-vs-multi-repo/#conclusion","title":"Conclusion","text":"<p>For my IaC project with Terraform, I will use a monorepo approach to manage all the Terraform modules and configurations for my project.</p>","tags":["git"]},{"location":"blog/2024/04/30/repository-strategy-fork-vs-branch/","title":"Repository Strategy: Fork vs Branch","text":"<p>In this post, I will explain the different ways to contribute to a Git repository: Fork vs Branch.</p>","tags":["git"]},{"location":"blog/2024/04/30/repository-strategy-fork-vs-branch/#fork","title":"Fork","text":"<p>A fork is a copy of a repository that you can make changes to without affecting the original repository. When you fork a repository, you create a new repository in your GitHub account that is a copy of the original repository.</p> <p>The benefits of forking a repository include:</p> <ul> <li>Isolation: You can work on your changes without affecting the original repository.</li> <li>Collaboration: You can make changes to the forked repository and submit a pull request to the original repository to merge your changes.  </li> <li>Ownership: You have full control over the forked repository and can manage it as you see fit.</li> </ul> <p>The challenges of forking a repository include:</p> <ul> <li>Synchronization: Keeping the forked repository up to date with the original repository can be challenging.</li> <li>Conflicts: Multiple contributors working on the same codebase can lead to conflicts and merge issues.</li> <li>Visibility: Changes made to the forked repository are not visible in the original repository until they are merged.</li> </ul>","tags":["git"]},{"location":"blog/2024/04/30/repository-strategy-fork-vs-branch/#branch","title":"Branch","text":"<p>A branch is a parallel version of a repository that allows you to work on changes without affecting the main codebase. When you create a branch, you can make changes to the code and submit a pull request to merge the changes back into the main branch.</p> <p>The benefits of using branches include:</p> <ul> <li>Flexibility: You can work on different features or bug fixes in separate branches without affecting each other.</li> <li>Collaboration: You can work with other developers on the same codebase by creating branches and submitting pull requests.</li> <li>Visibility: Changes made in branches are visible to other developers, making it easier to review and merge changes.</li> </ul> <p>The challenges of using branches include:</p> <ul> <li>Conflicts: Multiple developers working on the same branch can lead to conflicts and merge issues.</li> <li>Complexity: Managing multiple branches can be challenging, especially in large projects.</li> <li>Versioning: Branches are versioned separately, making it harder to track changes across the project.</li> </ul>","tags":["git"]},{"location":"blog/2024/04/30/repository-strategy-fork-vs-branch/#fork-vs-branch","title":"Fork vs Branch","text":"<p>The decision to fork or branch a repository depends on the project's requirements and the collaboration model.</p> <ul> <li> <p>Fork: Use a fork when you want to work on changes independently of the original repository or when you want to contribute to a project that you do not have write access to.</p> </li> <li> <p>Branch: Use a branch when you want to work on changes that will be merged back into the main codebase or when you want to collaborate with other developers on the same codebase.</p> </li> </ul> <p>For my IaC project with Terraform, I will use branches to work on different features and bug fixes and submit pull requests to merge the changes back into the main branch. This approach will allow me to collaborate with other developers and keep the codebase clean and organized.</p>","tags":["git"]},{"location":"blog/2024/05/01/repository-strategy-branching-strategy/","title":"Repository Strategy: Branching Strategy","text":"<p>Once we have decided that we will use branches, it is time to define a strategy, so that all developers can work in a coordinated way.</p> <p>Some of the best known strategies are:</p> <ul> <li>Gitflow: It is a branching model designed around the project release. It is a strict branching model that assigns very specific roles to different branches.</li> <li>Feature Branch: It is a strategy where each feature is developed in a separate branch. This strategy is simple and easy to understand.</li> <li>Trunk-Based Development: It is a strategy where all developers work on a single branch. This strategy is simple and easy to understand.</li> <li>GitHub Flow: It is a strategy where all developers work on a single branch. This strategy is simple and easy to understand.</li> <li>GitLab Flow: It is a strategy where all developers work on a single branch. This strategy is simple and easy to understand.</li> <li>Microsoft Flow: It is a strategy where all developers work on a single branch. This strategy is simple and easy to understand.</li> </ul>","tags":["git"]},{"location":"blog/2024/05/01/repository-strategy-branching-strategy/#gitflow","title":"Gitflow","text":"<p>Gitflow is a branching model designed around the project release. It is a strict branching model that assigns very specific roles to different branches.</p> <p>The Gitflow strategy is based on the following branches:</p> <ul> <li>main: It is the main branch of the project. It contains the code that is in production.</li> <li>develop: It is the branch where the code is integrated before being released to production.</li> </ul> <p>The Gitflow strategy is based on the following types of branches:</p> <ul> <li>feature: It is the branch where the code for a new feature is developed.</li> <li>release: It is the branch where the code is prepared for release.</li> <li>hotfix: It is the branch where the code is developed to fix a bug in production.</li> </ul> <p>The Gitflow strategy is based on the following rules:</p> <ul> <li>Feature branches are created from the develop branch.</li> <li>Feature branches are merged into the develop branch.</li> <li>Release branches are created from the develop branch.</li> <li>Release branches are merged into the main and develop branches.</li> <li>Hotfix branches are created from the main branch.</li> <li>Hotfix branches are merged into the main and develop branches.</li> </ul> <p>The Gitflow strategy is based on the following workflow:</p> <ol> <li>Developers create a feature branch from the develop branch.</li> <li>Developers develop the code for the new feature in the feature branch.</li> <li>Developers merge the feature branch into the develop branch.</li> <li>Developers create a release branch from the develop branch.</li> <li>Developers prepare the code for release in the release branch.</li> <li>Developers merge the release branch into the main and develop branches.</li> <li>Developers create a hotfix branch from the main branch.</li> <li>Developers fix the bug in the hotfix branch.</li> <li>Developers merge the hotfix branch into the main and develop branches.</li> </ol> <pre><code>gitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\nbranch develop\ncheckout develop\ncommit\ncommit\nbranch feature_branch\ncheckout feature_branch\ncommit\ncommit\ncheckout develop\nmerge feature_branch\ncommit\nbranch release_branch\ncheckout release_branch\ncommit\ncommit\ncheckout develop\nmerge release_branch\ncheckout main\nmerge release_branch\ncommit\nbranch hotfix_branch\ncheckout hotfix_branch\ncommit\ncommit\ncheckout develop\nmerge hotfix_branch\ncheckout main\nmerge hotfix_branch\n</code></pre> <p>The Gitflow strategy have the following advantages:</p> <ul> <li>Isolation: Each feature is developed in a separate branch, isolating it from other features.</li> <li>Collaboration: Developers can work on different features at the same time without affecting each other.</li> <li>Stability: The main branch contains the code that is in production, ensuring that it is stable and reliable.</li> </ul> <p>The Gitflow strategy is based on the following disadvantages:</p> <ul> <li>Complexity: The Gitflow strategy is complex and can be difficult to understand for new developers.</li> <li>Overhead: The Gitflow strategy requires developers to create and manage multiple branches, which can be time-consuming.</li> </ul>","tags":["git"]},{"location":"blog/2024/05/01/repository-strategy-branching-strategy/#feature-branch-workflow","title":"Feature Branch Workflow","text":"<p>Feature Branch is a strategy where each feature is developed in a separate branch. This strategy is simple and easy to understand.</p> <p>The Feature Branch strategy is based on the following rules:</p> <ul> <li>Developers create a feature branch from the main branch.</li> <li>Developers develop the code for the new feature in the feature branch.</li> <li>Developers merge the feature branch into the main branch.</li> </ul> <p>The Feature Branch strategy is based on the following workflow:</p> <ol> <li>Developers create a feature branch from the main branch.</li> <li>Developers develop the code for the new feature in the feature branch.</li> <li>Developers merge the feature branch into the main branch.</li> </ol> <pre><code>gitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\ncheckout main\ncommit\ncommit\nbranch feature_branch\ncheckout feature_branch\ncommit\ncommit\ncheckout main\nmerge feature_branch\n</code></pre> <p>The Feature Branch strategy is based on the following advantages:</p> <ul> <li>Simplicity: The Feature Branch strategy is simple and easy to understand.</li> <li>Flexibility: Developers can work on different features at the same time without affecting each other.</li> <li>Visibility: Changes made in feature branches are visible to other developers, making it easier to review and merge changes.</li> </ul> <p>The Feature Branch strategy is based on the following disadvantages:</p> <ul> <li>Conflicts: Multiple developers working on the same feature can lead to conflicts and merge issues.</li> <li>Complexity: Managing multiple feature branches can be challenging, especially in large projects.</li> </ul>","tags":["git"]},{"location":"blog/2024/05/01/repository-strategy-branching-strategy/#trunk-based-development","title":"Trunk-Based Development","text":"<p>The Trunk-Based Development strategy is based on the following rules:</p> <ul> <li>Developers work on a single branch.</li> <li>Developers create feature flags to hide unfinished features.</li> <li>Developers merge the code into the main branch when it is ready.</li> </ul> <p>The Trunk-Based Development strategy is based on the following workflow:</p> <ol> <li>Developers work on a single branch.</li> <li>Developers create feature flags to hide unfinished features.</li> <li>Developers merge the code into the main branch when it is ready.</li> </ol> <pre><code>gitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\ncheckout main\ncommit\ncommit tag:\"v1.0.0\"\ncommit\ncommit\ncommit tag:\"v2.0.0\"\n</code></pre> <p>The Trunk-Based Development strategy is based on the following advantages:</p> <ul> <li>Simplicity: The Trunk-Based Development strategy is simple and easy to understand.</li> <li>Flexibility: Developers can work on different features at the same time without affecting each other.</li> <li>Visibility: Changes made in the main branch are visible to other developers, making it easier to review and merge changes.</li> </ul> <p>The Trunk-Based Development strategy is based on the following disadvantages:</p> <ul> <li>Conflicts: Multiple developers working on the same codebase can lead to conflicts and merge issues.</li> <li>Complexity: Managing feature flags can be challenging, especially in large projects.</li> </ul>","tags":["git"]},{"location":"blog/2024/05/01/repository-strategy-branching-strategy/#github-flow","title":"GitHub Flow","text":"<p>GitHub Flow is a strategy where all developers work on a single branch. This strategy is simple and easy to understand.</p> <p>The GitHub Flow strategy is based on the following rules:</p> <ul> <li>Developers work on a single branch.</li> <li>Developers create feature branches to work on new features.</li> <li>Developers merge the feature branches into the main branch when they are ready.</li> </ul> <p>The GitHub Flow strategy is based on the following workflow:</p> <ol> <li>Developers work on a single branch.</li> <li>Developers create a feature branch from the main branch.</li> <li>Developers develop the code for the new feature in the feature branch.</li> <li>Developers merge the feature branch into the main branch.</li> </ol> <pre><code>gitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\ncheckout main\ncommit\ncommit\nbranch feature_branch\ncheckout feature_branch\ncommit\ncommit\ncheckout main\nmerge feature_branch\n</code></pre>","tags":["git"]},{"location":"blog/2024/05/01/repository-strategy-branching-strategy/#gitlab-flow","title":"GitLab Flow","text":"<p>GitLab Flow is a strategy where all developers work on a single branch. This strategy is simple and easy to understand. GitLab Flow is often used with release branches.</p> <p>The GitLab Flow strategy is based on the following rules:</p> <ul> <li>Developers work on a single branch.</li> <li>Developers create feature branches to work on new features.</li> <li>Developers merge the feature branches into the main branch when they are ready.</li> <li>Developers create a pre-production branch to make bug fixes before merging changes back to the main branch.</li> <li>Developers merge the pre-production branch into the main branch before going to production.</li> <li>Developers can add as many pre-production branches as needed.</li> <li>Developers can maintain different versions of the production branch.</li> </ul> <p>The GitLab Flow strategy is based on the following workflow:</p> <ol> <li>Developers work on a single branch.</li> <li>Developers create a feature branch from the main branch.</li> <li>Developers develop the code for the new feature in the feature branch.</li> <li>Developers merge the feature branch into the main branch.</li> <li>Developers create a pre-production branch from the main branch.</li> <li>Developers make bug fixes in the pre-production branch.</li> <li>Developers merge the pre-production branch into the main branch.</li> <li>Developers create a production branch from the main branch.</li> <li>Developers merge the production branch into the main branch.</li> </ol> <pre><code>gitGraph:\noptions\n{\n    \"nodeSpacing\": 150,\n    \"nodeRadius\": 10\n}\nend\ncommit\ncheckout main\ncommit\ncommit\nbranch feature_branch\ncheckout feature_branch\ncommit\ncommit\ncheckout main\nmerge feature_branch\ncommit\nbranch pre-production\ncheckout pre-production\ncommit\ncommit\ncheckout main\nmerge pre-production\ncommit\nbranch production\ncheckout production\ncommit\ncommit\ncheckout main\nmerge production\n</code></pre>","tags":["git"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/","title":"Azure Container Registry: Artifact Cache","text":"<p>Azure Container Registry is a managed, private Docker registry service provided by Microsoft. It allows you to build, store, and manage container images and artifacts in a secure environment. </p>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#what-is-artifact-caching","title":"What is Artifact Caching?","text":"<p>Artifact Cache is a feature in Azure Container Registry that allows users to cache container images in a private container registry. It is available in Basic, Standard, and Premium service tiers.</p>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#benefits-of-artifact-cache","title":"Benefits of Artifact Cache","text":"<ul> <li>Reliable pull operations: Faster pulls of container images are achievable by caching the container images in ACR.</li> <li>Private networks: Cached registries are available on private networks.</li> <li>Ensuring upstream content is delivered: Artifact Cache allows users to pull images from the local ACR instead of the upstream registry.</li> </ul>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#limitations","title":"Limitations","text":"<p>Cache will only occur after at least one image pull is complete on the available container image</p>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#how-to-use-artifact-cache-in-azure-container-registry-without-credential","title":"How to Use Artifact Cache in Azure Container Registry without credential?","text":"<p>Let's take a look at how you can implement artifact caching in Azure Container Registry.</p>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#step-1-create-a-cache-rule","title":"Step 1: Create a Cache Rule","text":"<p>The first step is to create a cache rule in your Azure Container Registry. This rule specifies the source image that should be cached and the target image that will be stored in the cache.</p> <pre><code>az acr cache create -r MyRegistry -n MyRule -s docker.io/library/ubuntu -t ubuntu\n</code></pre> <p>Check the cache rule:</p> <pre><code>az acr cache show -r MyRegistry -n MyRule\n</code></pre>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#step-2-pull-the-image","title":"Step 2: Pull the Image","text":"<p>Next, you need to pull the image from the source registry to the cache. This will download the image and store it in the cache for future use.</p> <pre><code>docker pull myregistry.azurecr.io/hello-world:latest\n</code></pre>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#step-3-clean-up-the-resources","title":"Step 3: Clean up the resources","text":"<p>Finally, you can clean up the resources by deleting the cache rule.</p> <pre><code>az acr cache delete -r MyRegistry -n MyRule\n</code></pre> <p>If you need to check other rules, you can use the following command:</p> <pre><code>az acr cache list -r MyRegistry\n</code></pre>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#conclusion","title":"Conclusion","text":"<p>Azure Container Registry's Artifact Cache feature provides a convenient way to cache container images in a private registry, improving pull performance and reducing network traffic. By following the steps outlined in this article, you can easily set up and use artifact caching in your Azure Container Registry.</p> <p>If you need to use the cache with authentication, you can use the following article: Enable Artifact Cache with authentication.</p> <p>For more detailed information, please visit the official tutorial on the Microsoft Azure website.</p>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/02/azure-container-registry-artifact-cache/#references","title":"References","text":"<ul> <li>Azure Container Registry Documentation</li> <li>Azure Container Artifact Cache Overview</li> </ul>","tags":["Azure Container Registry"]},{"location":"blog/2024/05/03/nested-structures-with-optional-attributes-and-dynamic-blocks/","title":"Nested Structures with Optional Attributes and Dynamic Blocks","text":"<p>In this post, I will explain how to define nested structures with optional attributes and it's use dynamic blocks in Terraform.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/05/03/nested-structures-with-optional-attributes-and-dynamic-blocks/#nested-structures","title":"Nested Structures","text":"<p>Terraform allows you to define nested structures to represent complex data types in your configuration. Nested structures are useful when you need to group related attributes together or define a data structure that contains multiple fields.</p> <p>For example, you might define a nested structure to represent a virtual machine with multiple attributes, such as size, image, and network configuration:</p> <pre><code>variable \"vm\" {\n  type = object({\n    size     = string\n    image    = string\n    network  = object({\n      subnet = string\n      security_group = string\n    })\n  })\n}\n\nresource \"azurerm_virtual_machine\" \"example\" {\n  name     = \"example-vm\"\n  size     = var.vm.size\n  image    = var.vm.image\n  subnet   = var.vm.network.subnet\n  security_group = var.vm.network.security_group\n}\n</code></pre> <p>In this example, the <code>vm</code> variable defines a nested structure with three attributes: <code>size</code>, <code>image</code>, and <code>network</code>. The <code>network</code> attribute is itself a nested structure with two attributes: <code>subnet</code> and <code>security_group</code>.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/05/03/nested-structures-with-optional-attributes-and-dynamic-blocks/#optional-attributes","title":"Optional Attributes","text":"<p>If you have an attribute that is optional, you can define it as an optional attribute in your configuration. Optional attributes are useful when you want to provide a default value for an attribute but allow users to override it if needed.</p> <p>If optional doesn't works,  Terraform allows you to define your variables as <code>any</code> type, but it's not recommended because it can lead to errors and make your configuration less maintainable. It's better to define your variables with the correct type and use optional attributes when needed, but some cases it's necessary to use <code>any</code> and <code>null</code> values, you can minimize the risk of errors by providing a good description of the variable and its expected values.</p> <p>For example, you might define an optional attribute for the <code>security_group</code> in the <code>network</code> structure:</p> <pre><code>variable \"vm\" {\n  description = &lt;&lt;DESCRIPTION\n  Virtual machine configuration.\n  The following attributes are required:\n  - size: The size of the virtual machine.\n  - image: The image for the virtual machine.\n  - network: The network configuration for the virtual machine.\n  The network configuration should have the following attributes:\n  - subnet: The subnet for the virtual machine.\n  - security_group: The security group for the virtual machine.\n  DESCRIPTION\n  type = any\n  default = null\n}\n\nresource \"azurerm_virtual_machine\" \"example\" {\n  name     = \"example-vm\"\n  size     = var.vm.size\n  image    = var.vm.image\n  subnet   = var.vm.network.subnet\n  security_group = var.vm.network.security_group\n}\n</code></pre> <pre><code>variable \"vm\" {\n  type = object({\n    size     = string\n    image    = string\n    network  = object({\n      subnet = string\n      security_group = optional(string)\n    })\n  })\n}\n\n\nresource \"azurerm_virtual_machine\" \"example\" {\n  name     = \"example-vm\"\n  size     = var.vm.size\n  image    = var.vm.image\n  subnet   = var.vm.network.subnet\n  security_group = var.vm.network.security_group\n}\n</code></pre> <p>In this example, the <code>security_group</code> attribute in the <code>network</code> structure is defined as an optional attribute with a default value of <code>null</code>. This allows users to provide a custom security group if needed, or use the default value if no value is provided.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/05/03/nested-structures-with-optional-attributes-and-dynamic-blocks/#dynamic-blocks","title":"Dynamic Blocks","text":"<p>Terraform allows you to use dynamic blocks to define multiple instances of a block within a resource or module. Dynamic blocks are useful when you need to create multiple instances of a block based on a list or map of values.</p> <p>For example, you might use a dynamic block to define multiple network interfaces for a virtual machine:</p> <pre><code>variable \"network_interfaces\" {\n  type = list(object({\n    name    = string\n    subnet  = string\n    security_group = string\n  }))\n}\n\nresource \"azurerm_virtual_machine\" \"example\" {\n  name     = \"example-vm\"\n  size     = \"Standard_DS1_v2\"\n  image    = \"UbuntuServer\"\n\n  dynamic \"network_interface\" {\n    for_each = var.network_interfaces\n    content {\n      name            = network_interface.value.name\n      subnet          = network_interface.value.subnet\n      security_group  = network_interface.value.security_group\n    }\n  }\n}\n</code></pre> <p>In this example, the <code>network_interfaces</code> variable defines a list of objects representing network interfaces with three attributes: <code>name</code>, <code>subnet</code>, and <code>security_group</code>. The dynamic block iterates over the list of network interfaces and creates a network interface block for each object in the list.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/05/03/nested-structures-with-optional-attributes-and-dynamic-blocks/#conclusion","title":"Conclusion","text":"<p>In this post, I explained how to define nested structures with optional attributes and use dynamic blocks in Terraform. Nested structures are useful for representing complex data types, while optional attributes allow you to provide default values for attributes that can be overridden by users. Dynamic blocks are useful for creating multiple instances of a block based on a list or map of values. By combining these features, you can create flexible and reusable configurations in Terraform.</p>","tags":["IaC","Terraform","OpenTofu"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/","title":"Reduce your attack surface in Snowflake when using from Azure","text":"<p>When it comes to data security, reducing your attack surface is a crucial step. This post will guide you on how to minimize your attack surface when using Snowflake with Azure or Power BI.</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#what-is-snowflake","title":"What is Snowflake?","text":"<p>Snowflake is a cloud-based data warehousing platform that allows you to store and analyze large amounts of data. It is known for its scalability, performance, and ease of use. Snowflake is popular among organizations that need to process large volumes of data quickly and efficiently.</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#what-is-an-attack-surface","title":"What is an Attack Surface?","text":"<p>An attack surface refers to the number of possible ways an attacker can get into a system and potentially extract data. The larger the attack surface, the more opportunities there are for attackers. Therefore, reducing the attack surface is a key aspect of securing your systems.</p> <p>How to Reduce Your Attack Surface in Snowflake:</p> <ol> <li> <p>Use Azure Private Link Azure Private Link provides private connectivity from a virtual network to Snowflake, isolating your traffic from the public internet. It significantly reduces the attack surface by ensuring that traffic between Azure and Snowflake doesn't traverse over the public internet.</p> </li> <li> <p>Implement Network Policies Snowflake allows you to define network policies that restrict access based on IP addresses. By limiting access to trusted IP ranges, you can reduce the potential points of entry for an attacker.</p> </li> <li> <p>Enable Multi-Factor Authentication (MFA) MFA adds an extra layer of security by requiring users to provide at least two forms of identification before accessing the Snowflake account. This makes it harder for attackers to gain unauthorized access, even if they have your password.</p> </li> </ol> <p>In this blog post, we will show you how to reduce your attack surface when using Snowflake from Azure or Power BI by using Azure Private Link</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#default-snowflake-architecture","title":"Default Snowflake architecture","text":"<p>By default, Snowflake is accessible from the public internet. This means that anyone with the right credentials can access your Snowflake account from anywhere in the world, you can limit access to specific IP addresses, but this still exposes your Snowflake account to potential attackers. </p> <p>This is a security risk because it exposes your Snowflake account to potential attackers.</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#using-azure-private-link-with-snowflake","title":"Using Azure Private Link with Snowflake","text":"","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#simple-architecture-diagram-of-azure-private-link-with-snowflake","title":"Simple Architecture Diagram of Azure Private Link with Snowflake","text":"<p>The architecture of using Azure Private Link with Snowflake is as follows:</p> <pre><code>    graph TD\n    A[Virtual Network] --&gt;|Private Endpoint| B[Snowflake]\n    B --&gt;|Private Link Service| C[Private Link Resource]\n    C --&gt;|Private Connection| D[Virtual Network]\n    D --&gt;|Subnet| E[Private Endpoint]    \n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#architecture-components","title":"Architecture Components","text":"","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#requirements","title":"Requirements","text":"<p>Before you can use Azure Private Link with Snowflake, you need to have the following requirements in place:</p> <ul> <li>A Snowflake account with ACCOUNTADMIN privileges</li> <li>Business Critical or higher Snowflake edition</li> <li>An Azure subscription with a Resource Group  and privileges to create:<ul> <li>Virtual Network</li> <li>Subnet</li> <li>Private Endpoint</li> </ul> </li> </ul>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-by-step-guide","title":"Step-by-Step Guide","text":"<p>Note</p> <p>Replace the placeholders with your actual values, that is a orientation guide.</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-1-retrieve-dedailts-of-your-snowflake-account","title":"Step 1: Retrieve Dedailts of your Snowflake Account","text":"<pre><code>USE ROLE ACCOUNTADMIN;\nselect select SYSTEM$GET_PRIVATELINK_CONFIG();\n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-2-create-a-virtual-network","title":"Step 2: Create a Virtual Network","text":"<p>A virtual network is a private network that allows you to securely connect your resources in Azure. To create a virtual network with azcli, follow these steps:</p> <pre><code>az network vnet create \\\n  --name myVnet \\\n  --resource-group myResourceGroup \\\n  --address-prefix\n  --subnet-name mySubnet \\\n  --subnet-prefix\n  --enable-private-endpoint-network-policies true\n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-3-create-a-private-endpoint","title":"Step 3: Create a Private Endpoint","text":"<p>The first step is to create a private endpoint in Azure. A private endpoint is a network interface that connects your virtual network to the Snowflake service. This allows you to access Snowflake using a private IP address, rather than a public one.</p> <p>To create a private endpoint with azcli, follow these steps:</p> <pre><code>az network private-endpoint create \\\n  --name mySnowflakeEndpoint \\\n  --resource-group myResourceGroup \\\n  --vnet-name myVnet \\\n  --subnet mySubnet \\\n  --private-connection-resource-id /subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;resource-group&gt;/providers/Microsoft.Network/privateLinkServices/&lt;Snowflake-service-name&gt; \\\n  --connection-name mySnowflakeConnection\n</code></pre> <p>Check the status of the private endpoint:</p> <pre><code>az network private-endpoint show \\\n  --name mySnowflakeEndpoint \\\n  --resource-group myResourceGroup\n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-4-authorize-the-private-endpoint","title":"Step 4: Authorize the Private Endpoint","text":"<p>The next step is to authorize the private endpoint to access the Snowflake service. </p> <p>Retrieve the Resource ID of the private endpoint:</p> <pre><code>az network private-endpoint show \\\n  --name mySnowflakeEndpoint \\\n  --resource-group myResourceGroup\n</code></pre> <p>Create a temporary access token that Snowflake can use to authorize the private endpoint:</p> <pre><code>az account get-access-token --subscription &lt;subscription-id&gt;\n</code></pre> <p>Authorize the private endpoint in Snowflake:</p> <pre><code>USE ROLE ACCOUNTADMIN;\nselect SYSTEM$AUTHORIZE_PRIVATELINK('&lt;resource-id&gt;', '&lt;access-token&gt;');\n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-5-block-public-access","title":"Step 5: Block Public Access","text":"<p>To further reduce your attack surface, you can block public access to your Snowflake account. This ensures that all traffic to and from Snowflake goes through the private endpoint, reducing the risk of unauthorized access.</p> <p>To block public access to your Snowflake account, you need to use Network Policy, follow these steps:</p> <pre><code>USE ROLE ACCOUNTADMIN;\nCREATE NETWORK RULE allow_access_rule\n  MODE = INGRESS\n  TYPE = IPV4\n  VALUE_LIST = ('192.168.1.99/24');\n\nCREATE NETWORK RULE block_access_rule\n  MODE = INGRESS\n  TYPE = IPV4\n  VALUE_LIST = ('0.0.0.0/0');\n\nCREATE NETWORK POLICY public_network_policy\n  ALLOWED_NETWORK_RULE_LIST = ('allow_access_rule')\n  BLOCKED_NETWORK_RULE_LIST=('block_access_rule');\n</code></pre> <p>It's highly recommended to follow the best practices for network policies in Snowflake. You can find more information here:  https://docs.snowflake.com/en/user-guide/network-policies#best-practices</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#step-6-test-the-connection","title":"Step 6: Test the Connection","text":"<p>To test the connection between your virtual network and Snowflake, you can use the SnowSQL client. </p> <pre><code>snowsql -a &lt;account_name&gt; -u &lt;username&gt; -r &lt;role&gt; -w &lt;warehouse&gt; -d &lt;database&gt; -s &lt;schema&gt;\n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#internal-stages-with-azure-blob-private-endpoints","title":"Internal Stages with Azure Blob Private Endpoints","text":"<p>If you are using Azure Blob Storage as an internal stage in Snowflake, you can also use Azure Private Link to secure the connection between Snowflake and Azure Blob Storage.</p> <p>It's recommended to use Azure Blob Storage with Private Endpoints to ensure that your data is secure and that you are reducing your attack surface, you can check the following documentation for more information: Azure Private Endpoints for Internal Stages to learn how to configure Azure Blob Storage with Private Endpoints in Snowflake.</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#conclusion","title":"Conclusion","text":"<p>Reducing your attack surface is a critical aspect of securing your systems. By using Azure Private Link with Snowflake, you can significantly reduce the risk of unauthorized access and data breaches. Follow the steps outlined in this blog post to set up Azure Private Link with Snowflake and start securing your data today.</p>","tags":["Azure Private Link"]},{"location":"blog/2024/05/04/reduce-your-attack-surface-in-snowflake-when-using-from-azure/#references","title":"References","text":"<ul> <li>Azure Private Link documentation</li> <li>Snowflake Editions</li> <li>$GET_PRIVATELINK_CONFIG();</li> <li>Snowflake Network Policies</li> <li>Azure Private Endpoints for Internal Stages</li> </ul>","tags":["Azure Private Link"]},{"location":"blog/2024/05/06/configure-your-teams-meetings-options-to-improve-your-collaboration-experience/","title":"Configure your Teams meetings options to improve your collaboration experience","text":"<p>Microsoft Teams is a powerful collaboration tool that allows you to communicate and work with your team members from anywhere in the world. One of the key features of Teams is the ability to schedule and host meetings with your colleagues, clients, or partners.</p> <p>In this blog post, we will show you how to configure your Teams meetings options to improve your collaboration experience and make your meetings more productive.</p>","tags":["Teams"]},{"location":"blog/2024/05/06/configure-your-teams-meetings-options-to-improve-your-collaboration-experience/#what-are-teams-meetings-options","title":"What are Teams meetings options?","text":"<p>Teams meetings options are settings that allow you to control various aspects of your meetings, such as who can bypass the lobby, who can present, and who can record the meeting. By configuring these options, you can ensure that your meetings run smoothly and securely.</p>","tags":["Teams"]},{"location":"blog/2024/05/06/configure-your-teams-meetings-options-to-improve-your-collaboration-experience/#how-to-configure-your-teams-meetings-options","title":"How to configure your Teams meetings options","text":"<p>To configure your Teams meetings options, follow these steps:</p> <ol> <li>Open the Teams app on your computer or mobile device.</li> <li>Click on the calendar icon in the left-hand menu to view your calendar.</li> <li>Click on the \"Meetings\" tab at the top of the screen to view your upcoming meetings.</li> <li>Click on the meeting you want to configure to open the meeting details.</li> <li>Click on the \"Meeting options\" link at the bottom of the meeting details window.</li> <li>Configure the meeting options according to your preferences. You can control who can bypass the lobby, who can present, who can record the meeting, and other settings.</li> </ol>","tags":["Teams"]},{"location":"blog/2024/05/06/configure-your-teams-meetings-options-to-improve-your-collaboration-experience/#key-settings-to-configure","title":"Key settings to configure","text":"<p>Here are some key settings that you may want to configure in your Teams meetings options:</p> <ul> <li> <p>Who can bypass the lobby: By default, all participants are sent to the lobby when they join a meeting. You can configure this setting to allow participants to bypass the lobby and join the meeting directly.</p> </li> <li> <p>Who can present: By default, only the meeting organizer can present in a meeting. You can configure this setting to allow other participants to present as well.</p> </li> <li> <p>Who can record the meeting: By default, only the meeting organizer can record a meeting. You can configure this setting to allow other participants to record the meeting as well.</p> </li> <li> <p>Automatically admit people: By default, participants need to be admitted to the meeting by the organizer or a presenter. You can configure this setting to automatically admit people to the meeting.</p> </li> <li> <p>Allow attendees to unmute: By default, attendees are muted when they join a meeting. You can configure this setting to allow attendees to unmute themselves.</p> </li> </ul>","tags":["Teams"]},{"location":"blog/2024/05/06/configure-your-teams-meetings-options-to-improve-your-collaboration-experience/#conclusion","title":"Conclusion","text":"<p>Configuring your Teams meetings options is a great way to improve your collaboration experience and make your meetings more productive. By configuring these settings, you can ensure that your meetings run smoothly and securely, allowing you to focus on the task at hand.</p>","tags":["Teams"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/","title":"Repository Strategy: How to test Branching Strategy in local repository","text":"<p>If you don't want to test in github, gitlab, or azure devops, you can test in your local desktop.</p>","tags":["git"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/#step-1-create-a-new-local-bare-repository","title":"Step 1: Create a new local bare repository","text":"<p>To create a new local bare repository, open a terminal window and run the following command:</p> <pre><code>mkdir localrepo\ncd localrepo\ngit init --bare my-repo.git\n</code></pre> <p>This command creates a new directory called <code>localrepo</code> and initializes a new bare repository called <code>my-repo.git</code> inside it.</p>","tags":["git"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/#step-2-create-a-local-repository","title":"Step 2: Create a local repository","text":"<p>To create a new local repository, open a terminal window and run the following command:</p> <pre><code>mkdir my-repo\ncd my-repo\ngit init\n</code></pre> <p>This command creates a new directory called <code>my-repo</code> and initializes a new repository inside it.</p>","tags":["git"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/#step-3-add-the-remote-repository","title":"Step 3: Add the remote repository","text":"<p>To add the remote repository to your local repository, run the following command:</p> <pre><code>git remote add origin ../my-repo.git\n</code></pre> <p>In mi case, I have used absolute path, c:\\users\\myuser\\localrepo\\my-repo.git:</p> <pre><code>git remote add origin c:\\users\\myuser\\localrepo\\my-repo.git\n</code></pre> <p>This command adds the remote repository as the <code>origin</code> remote.</p>","tags":["git"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/#step-4-create-a-new-file-make-first-commit-and-push","title":"*Step 4: Create a new file, make first commit and push","text":"<p>To create a new file in your local repository, run the following command:</p> <pre><code>echo \"Hello, World!\" &gt; hello.txt\n</code></pre> <p>This command creates a new file called <code>hello.txt</code> with the content <code>Hello, World!</code>.</p> <p>To make the first commit to your local repository, run the following command:</p> <pre><code>git add hello.txt\ngit commit -m \"Initial commit\"\n</code></pre> <p>This command stages the <code>hello.txt</code> file and commits it to the repository with the message <code>Initial commit</code>.</p> <p>To push the changes to the remote repository, run the following command:</p> <pre><code>git push -u origin master\n</code></pre> <p>This command pushes the changes to the <code>master</code> branch of the remote repository.</p>","tags":["git"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/#step-5-create-a-new-branch-and-push-it-to-the-remote-repository","title":"Step 5: Create a new branch and push it to the remote repository","text":"<p>To create a new branch in your local repository, run the following command:</p> <pre><code>git checkout -b feature-branch\n</code></pre> <p>This command creates a new branch called <code>feature-branch</code> and switches to it.</p>","tags":["git"]},{"location":"blog/2024/05/07/repository-strategy-how-to-test-branching-strategy-in-local-repository/#conclusion","title":"Conclusion","text":"<p>By following these steps, you can test your branching strategy in a local repository before pushing changes to a remote repository. This allows you to experiment with different branching strategies and workflows without affecting your production codebase.</p>","tags":["git"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/","title":"FinOps for Azure: Optimizing Your Cloud Spend","text":"<p>In the cloud era, optimizing cloud spend has become a critical aspect of financial management. FinOps, a set of financial operations practices, empowers organizations to get the most out of their Azure investment. This blog post dives into the core principles of FinOps, explores the benefits it offers, and outlines practical strategies for implementing FinOps in your Azure environment.</p>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#understanding-the-cloud-cost-challenge","title":"Understanding the Cloud Cost Challenge","text":"<p>Traditional IT expenditure followed a capital expenditure (capex) model, where businesses purchased hardware and software upfront. Cloud computing introduces a paradigm shift with the operational expenditure (opex) model. Here, businesses pay for resources as they consume them, leading to variable and unpredictable costs.</p> <p>FinOps tackles this challenge by providing a framework for managing cloud finances. It encompasses three key pillars:</p> <ul> <li>People: Establish a FinOps team or designate individuals responsible for overseeing cloud costs. This team should possess a blend of cloud technical expertise, financial acumen, and business process knowledge.</li> <li>Process:  Define processes for budgeting, forecasting, and monitoring cloud expenses. This involves setting spending limits, creating chargeback models for different departments, and regularly reviewing cost reports.</li> <li>Tools: Leverage Azure Cost Management, a suite of tools that provides granular insights into your Azure spending. It enables cost allocation by resource, service, department, or any other relevant dimension.</li> </ul> <p>It's essential to adopt a FinOps mindset that encourages collaboration between finance, IT, and business teams to drive cost efficiency and value realization in the cloud.</p> <p>It's important to note that FinOps is not just about cost-cutting; it's about optimizing cloud spending to align with business objectives and maximize ROI.</p>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#azure-cost-management-optimizing-your-azure-spending","title":"Azure Cost Management: Optimizing Your Azure Spending","text":"<p>Azure Cost Management empowers you to analyze your Azure spending patterns and identify cost-saving opportunities. Here's a glimpse into its key functionalities:</p> <ul> <li>Cost Views: Generate comprehensive reports that categorize your Azure spending by various attributes like resource group, service, or department.</li> <li>Cost Alerts: Set up proactive alerts to notify you when your spending exceeds predefined thresholds.</li> <li>Reservations: Purchase reserved instances of frequently used Azure resources for significant upfront discounts.</li> <li>Recommendations: Azure Cost Management analyzes your usage patterns and recommends potential cost-saving measures, such as rightsizing resources or leveraging spot instances.</li> </ul>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#the-power-of-tags-and-azure-policy","title":"The Power of Tags and Azure Policy","text":"<p>Tags are metadata labels that you can attach to your Azure resources to categorize and track them effectively. They play a pivotal role in FinOps by enabling you to:</p> <ul> <li>Associate costs with specific departments, projects, or applications.</li> <li>Identify unused or underutilized resources for potential cost savings.</li> <li>Simplify cost allocation and chargeback processes.</li> </ul> <p>Azure Policy helps enforce tagging standards and governance rules across your Azure environment. You can define policies that mandate specific tags for all resources, ensuring consistent cost allocation and data accuracy.</p>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#benefits-of-implementing-finops","title":"Benefits of Implementing FinOps","text":"<p>A well-defined FinOps strategy empowers you to:</p> <ul> <li>Gain Visibility into Cloud Spending:  Obtain a clear picture of your Azure expenditures, enabling informed budgeting and cost control decisions.</li> <li>Optimize Cloud Costs: Identify and eliminate wasteful spending through cost-saving recommendations and proactive measures.</li> <li>Improve Cloud Governance:  Enforce tagging policies and spending limits to ensure responsible cloud resource utilization.</li> <li>Align Cloud Spending with Business Value:  Make data-driven decisions about cloud investments that support your business objectives.</li> </ul>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#getting-started-with-finops-in-azure","title":"Getting Started with FinOps in Azure","text":"<p>Implementing FinOps doesn't necessitate a complex overhaul. Here's a recommended approach:</p> <ol> <li>Establish a FinOps Team:  Assemble a cross-functional team comprising representatives from finance, IT, and business departments.</li> <li>Set Clear Goals and Objectives:  Define your FinOps goals, whether it's reducing costs by a specific percentage or improving budget forecasting accuracy.</li> <li>Leverage Azure Cost Management:  Start by exploring Azure Cost Management to understand your current spending patterns.</li> <li>Implement Basic Tagging Standards:  Enforce basic tagging policies to categorize your Azure resources for cost allocation purposes.</li> <li>Continuously Monitor and Refine:  Regularly review your cloud cost reports and identify areas for further optimization.</li> </ol> <p>By following these steps and embracing a FinOps culture, you can effectively manage your Azure expenses and derive maximum value from your cloud investment.</p>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#toolchain-for-finops-in-azure","title":"Toolchain for FinOps in Azure","text":"<p>To streamline your FinOps practices in Azure, consider leveraging the following tools:</p> <pre><code>graph LR\nA[Financial Operations Practices] --&gt; B{Cloud Spend Optimization}\nB --&gt; C{Cost Visibility}\nB --&gt; D{Cost Optimization}\nB --&gt; E{Governance}\nC --&gt; F{Azure Cost Management}\nD --&gt; G{Azure Advisor}\nE --&gt; H{Azure Policy}\nF --&gt; I{Cost Views}\nF --&gt; J{Cost Alerts}\nG --&gt; K{Cost Recommendations}\nH --&gt; L{Tag Enforcement}\n</code></pre> <p>This toolchain combines Azure Cost Management, Azure Advisor, and Azure Policy to provide a comprehensive suite of capabilities for managing your Azure spending effectively.</p> <p>Highly recommended, you can check FinOps toolkit, it's a set of tools and best practices to help you implement FinOps in your organization, it includes tools for cost allocation, budgeting, and forecasting, as well as best practices for FinOps implementation.</p>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#conclusion","title":"Conclusion","text":"<p>FinOps is an essential practice for organizations leveraging Azure. It empowers you to make informed decisions about your cloud finances, optimize spending, and achieve your business goals. As an Azure Solutions Architect, I recommend that you establish a FinOps practice within your organization to unlock the full potential of Azure and achieve financial efficiency in the cloud.</p> <p>This blog post provides a foundational understanding of FinOps in Azure. </p> <p>By embracing FinOps, you can transform your cloud cost management practices and drive business success in the cloud era.</p>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/09/finops-for-azure-optimizing-your-cloud-spend/#references","title":"References","text":"<ul> <li>Thanks John Savill</li> <li>FinOps toolkit</li> </ul>","tags":["Azure Cost Management","Azure tags"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/","title":"Implementing policy as code with Open Policy Agent","text":"<p>In this post, I will show you how to implement policy as code with Open Policy Agent (OPA) and Azure.</p>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#what-is-open-policy-agent","title":"What is Open Policy Agent?","text":"<p>Open Policy Agent (OPA) is an open-source, general-purpose policy engine that enables you to define and enforce policies across your cloud-native stack. OPA provides a high-level declarative language called Rego that you can use to write policies that are easy to understand and maintain.</p>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#why-use-open-policy-agent","title":"Why use Open Policy Agent?","text":"<p>There are several reasons to use OPA:</p> <ul> <li>Consistency: OPA allows you to define policies in a single place and enforce them consistently across your cloud-native stack.</li> <li>Flexibility: OPA provides a flexible policy language that allows you to define policies that are tailored to your specific requirements.</li> <li>Auditability: OPA provides a transparent and auditable way to enforce policies, making it easy to understand why a policy decision was made.</li> <li>Integration: OPA integrates with a wide range of cloud-native tools and platforms, making it easy to enforce policies across your entire stack.</li> </ul>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#getting-started-with-open-policy-agent","title":"Getting started with Open Policy Agent","text":"<p>To get started with OPA, you need to install the OPA CLI and write some policies in Rego.</p> <p>You can install the OPA CLI by downloading the binary from the OPA GitHub releases page, you can check the installation guide for more details.</p> <p>Once you have installed the OPA CLI, you can write policies in Rego. Rego is a high-level declarative language that allows you to define policies in a clear and concise way.</p> <p>Here's a simple example of a policy that enforces a naming convention for Azure resources:</p> <pre><code>package azure.resources\n\ndefault allow = false\n\nallow {\n    input.resource.type == \"Microsoft.Compute/virtualMachines\"\n    input.resource.name == \"my-vm\"\n}\n</code></pre> <p>This policy allows resources of type <code>Microsoft.Compute/virtualMachines</code> with the name <code>my-vm</code>. You can write more complex policies that enforce a wide range of requirements, such as resource tagging, network security, and access control.</p>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#integrating-open-policy-agent-with-azure","title":"Integrating Open Policy Agent with Azure","text":"<p>To integrate OPA with Azure, you can use the Azure Policy service, which allows you to define and enforce policies across your Azure resources. You can use OPA to define custom policies that are not supported by Azure Policy out of the box, or to enforce policies across multiple cloud providers.</p>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#conclusion","title":"Conclusion","text":"<p>Open Policy Agent is a powerful tool that allows you to define and enforce policies across your cloud-native stack. By using OPA, you can ensure that your infrastructure is secure, compliant, and consistent, and that your policies are easy to understand and maintain. I hope this post has given you a good introduction to OPA and how you can use it to implement policy as code in your cloud-native environment.</p>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#additional-resources","title":"Additional resources","text":"<p>I have created a GitHub repository with some examples of policies written in Rego that you can use as a starting point for your own policies.</p>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/10/implementing-policy-as-code-with-open-policy-agent/#references","title":"References","text":"<ul> <li>Open Policy Agent</li> <li>Azure Policy</li> <li>Rego language</li> </ul>","tags":["Open Policy Agent"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/","title":"Securely connect Power BI to data sources with a VNet data gateway","text":"<p>In this post, I will show you how to securely connect Power BI to your Azure data services using a Virtual Network (VNet) data gateway.</p>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#what-is-a-virtual-network-vnet-data-gateway","title":"What is a Virtual Network (VNet) data gateway?","text":"<p>The virtual network (VNet) data gateway helps you to connect from Microsoft Cloud services to your Azure data services within a VNet without the need of an on-premises data gateway. The VNet data gateway securely communicates with the data source, executes queries, and transmits results back to the service.</p>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#the-role-of-a-vnet-data-gateway","title":"The Role of a VNet Data Gateway","text":"<p>A VNet data gateway acts as a bridge that allows for the secure flow of data between the Power Platform and external data sources that reside within a virtual network. This includes services such as SQL databases, file storage solutions, and other cloud-based resources. The gateway ensures that data can be transferred securely and reliably, without exposing the network to potential threats or breaches.</p>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#how-it-works","title":"How It Works","text":"<pre><code>graph LR\n    User([User]) --&gt;|Semantic Models| SM[Semantic Models]\n    User --&gt;|\"Dataflows (Gen2)\"| DF[\"Dataflows (Gen2)\"]\n    User --&gt;|Paginated Reports| PR[Paginated Reports]\n    SM --&gt; PPVS[Power Platform VNET Service]\n    DF --&gt; PPVS\n    PR --&gt; PPVS\n    PPVS --&gt; MCVG[Managed Containerfor VNet Gateway]\n    MCVG --&gt;|Interfaces with| SQLDB[(SQL Databases)]\n    MCVG --&gt;|Interfaces with| FS[(File Storage)]\n    MCVG --&gt;|Interfaces with| CS[(Cloud Services)]\n    MCVG -.-&gt;|Secured by| SEC{{Security Features}}\n\n    subgraph VNET_123\n    SQLDB\n    FS\n    CS\n    SEC\n    end\n\n    classDef filled fill:#f96,stroke:#333,stroke-width:2px;\n    classDef user fill:#bbf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5;\n    class User user\n    class SM,DF,PR,PPVS,MCVG,SQLDB,FS,CS,SEC filled\n</code></pre> <p>The process begins with a user leveraging Power Platform services like Semantic Models, Dataflows (Gen2), and Paginated Reports. These services are designed to handle various data-related tasks, from analysis to visualization. They connect to the Power Platform VNET Service, which is the heart of the operation, orchestrating the flow of data through the managed container for the VNet gateway.</p> <p>This managed container is a secure environment specifically designed for the VNet gateway\u2019s operations. It\u2019s isolated from the public internet, ensuring that the data remains protected within the confines of the virtual network. Within this secure environment, the VNet gateway interfaces with the necessary external resources, such as SQL databases and cloud storage, all while maintaining strict security protocols symbolized by the padlock icon in our diagram.</p> <p>If you need to connect to services on others VNets, you can use VNet peering to connect the VNets, and maybe access to on-premises resources using ExpressRoute or other VPN solutions.</p>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#the-benefits","title":"The Benefits","text":"<p>By utilizing a VNet data gateway, organizations can enjoy several benefits:</p> <ul> <li>Enhanced Security: The gateway provides a secure path for data, safeguarding sensitive information and complying with organizational security policies.</li> <li>Network Isolation: The managed container and the virtual network setup ensure that the data does not traverse public internet spaces, reducing exposure to vulnerabilities.</li> <li>Seamless Integration: The gateway facilitates smooth integration between Power Platform services and external data sources, enabling efficient data processing and analysis.</li> </ul>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#getting-started","title":"Getting Started","text":"<p>To set up a VNet data gateway, follow these steps:</p>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#register-microsoftpowerplatform-as-a-resource-provider","title":"Register Microsoft.PowerPlatform as a resource provider","text":"<p>Before you can create a VNet data gateway, you need to register the Microsoft.PowerPlatform resource provider. This can be done using the Azure portal or the Azure CLI.</p> <pre><code>az provider register --namespace Microsoft.PowerPlatform\n</code></pre>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#associate-the-subnet-to-microsoft-power-platform","title":"Associate the subnet to Microsoft Power Platform","text":"<p>Create a VNet in your Azure subscription and a subnet where the VNet data gateway will be deployed. Next, you need to delegate subnet to service Microsoft.PowerPlatform/vnetaccesslinks. </p> <p>Note</p> <ul> <li>This subnet can't be shared with other services.</li> <li>Five IP addresses are reserved in the subnet for basic functionality. You need to reserve additional IP addresses for the VNet data gateway, add more IPs for future gateways.</li> <li>You need a role with the Microsoft.Network/virtualNetworks/subnets/join/action permission</li> </ul> <p>This can be done using the Azure portal or the Azure CLI.</p> <pre><code># Create a VNet and address prefix 10.0.0.0/24\naz network vnet create --name MyVNet --resource-group MyResourceGroup --location eastus --address-prefixes 10.0.0.0/24\n\n\n# Create a Netwrok Security Group\naz network nsg create --name MyNsg --resource-group MyResourceGroup --location eastus\n\n# Create a subnet with delegation to Microsoft.PowerPlatform/vnetaccesslinks and associate the NSG\naz network vnet subnet create --name MySubnet --vnet-name MyVNet --resource-group MyResourceGroup --address-prefixes 10.0.0.1/27 --network-security-group MyNsg --delegations Microsoft.PowerPlatform/vnetaccesslinks\n</code></pre>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#create-a-vnet-data-gateway","title":"Create a VNet data gateway","text":"<p>Note</p> <p>A Microsoft Power Platform User with with Microsoft.Network/virtualNetworks/subnets/join/action permission on the VNet is required. Network Contributor role is not necessary.</p> <ol> <li>Sign in to the Power BI homepage.</li> <li>In the top navigation bar, select the settings gear icon on the right.</li> <li>From the drop down, select the Manage connections and gateways page, in Resources and extensions.</li> <li>Select Create a virtual network data gateway..</li> <li>Select the license capacity, subscription, resource group, VNet and the Subnet. Only subnets that are delegated to Microsoft Power Platform are displayed in the drop-down list. VNET data gateways require a Power BI Premium capacity license (A4 SKU or higher or any P SKU) or Fabric license to be used (any SKU).</li> <li>By default, we provide a unique name for this data gateway, but you could optionally update it.</li> <li>Select Save. This VNet data gateway is now displayed in your Virtual network data gateways tab. A VNet data gateway is a managed gateway that could be used for controlling access to this resource for Power platform users.</li> </ol>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/11/securely-connect-power-bi-to-data-sources-with-a-vnet-data-gateway/#conclusion","title":"Conclusion","text":"<p>The VNet data gateway is a powerful tool that enables secure data transfer between the Power Platform and external data sources residing within a virtual network. By leveraging this gateway, organizations can ensure that their data remains protected and compliant with security standards, all while facilitating seamless integration and analysis of data. If you are looking to enhance the security and reliability of your data connections, consider implementing a VNet data gateway in your environment.</p>","tags":["Virtual network (VNet) data gateway"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/","title":"Microsoft Entra ID Privileged Identity Management","text":"<p>In this post, I will show you how to use Microsoft Entra ID Privileged Identity Management (PIM) to manage and monitor access to privileged roles in your organization.</p>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#what-is-microsoft-entra-id-privileged-identity-management","title":"What is Microsoft Entra ID Privileged Identity Management?","text":"<p>Microsoft Entra ID Privileged Identity Management (PIM) is a service that helps you manage, control, and monitor access within your organization. It provides just-in-time privileged access to Azure AD and Azure resources, along with access reviews and monitoring capabilities.</p>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#reasons-to-use-microsoft-entra-id-pim","title":"Reasons to Use Microsoft Entra ID PIM","text":"<p>There are several reasons to use Microsoft Entra ID PIM:</p> <ul> <li>Security: Microsoft Entra ID PIM helps you reduce the risk of unauthorized access to privileged roles.</li> <li>Compliance: Microsoft Entra ID PIM helps you meet compliance requirements by providing access reviews and monitoring capabilities.</li> <li>Efficiency: Microsoft Entra ID PIM provides just-in-time access to privileged roles, reducing the risk of unauthorized access.</li> <li>Monitoring: Microsoft Entra ID PIM provides monitoring and alerts that help you detect and respond to suspicious activities.</li> <li>Traceability: Microsoft Entra ID PIM provides an audit trail of all access requests and approvals, helping you track who has access to privileged roles.</li> </ul> <p>Maybe you can't use Microsoft Entra ID PIM to log all changess that the users do in the system, but you can use Actor Change for that.</p>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#key-features-of-microsoft-entra-id-pim","title":"Key Features of Microsoft Entra ID PIM","text":"<p>Microsoft Entra ID PIM offers several key features that help you manage and monitor access to privileged roles:</p> <ul> <li>Provide just-in-time privileged access to Microsoft Entra ID and Azure resources.</li> <li>Assign time-bound access to resources using start and end dates.</li> <li>Require approval to activate privileged roles.</li> <li>Enforce multifactor authentication to activate any role.</li> <li>Use justification to understand why users activate.</li> <li>Get notifications when users activate privileged roles.</li> <li>Conduct access reviews to ensure users still need roles.</li> <li>Download audit history for internal or external audit.</li> <li>Prevent removal of the last active Global Administrator and Privileged Role Administrator role assignments.</li> </ul>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#how-to-use-microsoft-entra-id-pim","title":"How to Use Microsoft Entra ID PIM","text":"<p>We can manage three types of \"things\" in Microsoft Entra ID PIM:</p> <ul> <li>Microsoft Entra roles. Microsoft Entra roles are also referred to as directory roles. They include built-in and custom roles to manage Microsoft Entra ID and other Microsoft 365 online services.</li> <li>PIM for Groups. To set up just-in-time access to the member and owner role of a Microsoft Entra security group. PIM for Groups provides an alternative way to set up PIM for Microsoft Entra roles and Azure roles. It also allows you to set up PIM for other permissions across Microsoft online services like Intune, Azure Key Vaults, and Microsoft Entra ID Protection.</li> <li>Azure roles. Azure's role-based access control roles that grant access to management groups, subscriptions, resource groups, and resources.</li> </ul>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#microsoft-entra-id-roles","title":"Microsoft Entra ID roles","text":"<p>Note</p> <p>If you want to use groups, you need create eligible groups, for now the maximum number of eligible groups is 500.</p> <p>In the Microsoft Entra ID portal, you can manage Microsoft Entra ID roles by selecting the \"Roles\" tab. Here you can see all the roles that are available to you, as well as the roles that you have activated.</p> <p>You can made the following actions:</p> <ul> <li>Assign: Create assignments for Microsoft Entra ID roles, update existing assignments to ensure that users have just-in-time access to privileged roles.</li> <li>Activate: Activate your eligible assignments to get just-in-time access to privileged roles. </li> <li>Approve: List, approve, or deny activation requests for Microsoft Entra ID roles.</li> <li>Audit: View and export a history of all assignments and activations done in PIM so you can identify attacks and stay compliant.</li> </ul> <p>Ok, let's see how to assign a role to a group.</p> <p>In the \"Roles\" tab, click on the role that you want to assign. </p> <p>In Role settings, edit the settings for the role, modify Activation, Assignment, and Notification settings and then click \"Update. These are the default settings:</p> <p>Activation</p> Setting State Activation maximum duration (hours) 8 hour(s) On activation, require None Require justification on activation Yes Require ticket information on activation No Require approval to activate No Approvers None <p>Assignment</p> Setting State Allow permanent eligible assignment Yes Expire eligible assignments after - Allow permanent active assignment Yes Expire active assignments after - Require Azure Multi-Factor Authentication on active assignment No Require justification on active assignment Yes <p>Send notifications when members are assigned as eligible to this role:</p> Type Default recipients Additional recipients Critical emails only Role assignment alert Admin None False Notification to the assigned user (assignee) Assignee None False Request to approve a role assignment renewal/extension Approver None False <p>Send notifications when members are assigned as active to this role:</p> Type Default recipients Additional recipients Critical emails only Role assignment alert Admin None False Notification to the assigned user (assignee) Assignee None False Request to approve a role assignment renewal/extension Approver None False <p>Send notifications when eligible members activate this role:</p> Type Default recipients Additional recipients Critical emails only Role activation alert Admin None False Notification to activated user (requestor) Requestor None False Request to approve an activation Approver None False <p>In the \"Assignments\" tab, click on \"Add assignments\". In Membership, select the scope type: Application, Device, Directory, Group, Service Principal or User (It's dependes of each role)  and select the identity related that you want to assign the role to. We are going to select Directory and a eligible group,  and then click \"Next\". </p> <p>Info</p> <p>App registrations are supported in PIM for Microsoft Entra ID roles but only in active assignments. </p> <p>In the \"Settings\" tab, you can set the Assigment type: Eligible or I need to do something to activate and Active or I don't need to do nothing to activate my role. You can configure too if you want that the duration of the assignment is permanent or if you want to expire the assignment after a certain period of time. Once you're done, click \"Assign\".</p> <p>You can set the activation settings, assignment settings, and notification settings for the assignment. Once you're done, click \"Assign\".</p>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#pim-for-groups","title":"PIM for Groups","text":"<p>In the Microsoft Entra ID portal, you can manage PIM for Groups by selecting the \"Groups\" tab. </p> <p>First you need to discover the groups that you want to manage. In the \"Groups\" tab, click on \"Discover groups\". In the \"Discover groups\" pane, you can search for groups by name. Once you've found the group you want to manage, click on \"Add to PIM\".</p> <p>Info</p> <p>You must be an owner of the group or have Microsoft Entra role that allows to discover and manage group in PIM.</p> <p>Now, in the \"Groups\" tab, you can see all the groups that you have discovered.</p> <p>In the \"Groups\" tab, click on the group that you want to manage. You can made the following actions under manage:</p> <ul> <li>Assign: Create assignments for the member and owner role of the group, update existing assignments to ensure that users have just-in-time access to privileged roles.</li> <li>Activate: Activate your eligible assignments to get just-in-time access to privileged roles.</li> <li>Approve: List, approve, or deny activation requests for the member and owner role of the group.</li> <li>Audit: View and export a history of all assignments and activations done in PIM so you can identify attacks and stay compliant.</li> </ul> <p>Ok, let's see how to assign a role to a group.</p> <p>In the \"Groups\" tab, click on the group that you want to assign a role to. </p> <p>In Role settings, edit the settings for the role, modify Activation, Assignment, and Notification settings for members or users, these settings are the same that we saw in the Microsoft Entra ID roles section.</p> <p>In the \"Assignments\" tab, click on \"Add assignments\". In Select role, select the scope type: Member or Owner and in Select members select the identity related that you want to assign the role to or groupm, if you select a group, you doesn't need a eligible group,  and then click \"Next\".</p> <p>In the \"Settings\" tab, you can set the Assigment type: Eligible or I need to do something to activate and Active or I don't need to do nothing to activate my role. You can configure too if you want that the duration of the assignment is permanent or if you want to expire the assignment after a certain period of time. Once you're done, click \"Assign\".</p> <p>Info</p> <p>App registrations are supported in PIM for Groups but only in active assignments. I think that this is very useful for IaC for example because you can assign a role to a service principal and you can activate the role when you need it.</p> <p>Example of a sequence diagram of the activation process for a group:</p> <pre><code>sequenceDiagram\n    participant User\n    participant PIM\n    participant Approver\n    participant MFA\n    participant Group\n\n    User-&gt;&gt;PIM: Logs in\n    User-&gt;&gt;PIM: Navigates to PIM and selects \"My roles\"\n    User-&gt;&gt;PIM: Selects eligible group\n    User-&gt;&gt;PIM: Requests activation\n    PIM-&gt;&gt;MFA: Requests multi-factor authentication\n    MFA--&gt;&gt;User: MFA request\n    User-&gt;&gt;MFA: Provides MFA credentials\n    MFA--&gt;&gt;PIM: MFA confirmation\n    PIM-&gt;&gt;User: Requests justification\n    User-&gt;&gt;PIM: Provides justification\n    PIM-&gt;&gt;Approver: Sends approval request\n    Approver--&gt;&gt;PIM: Approval\n    PIM--&gt;&gt;User: Activation confirmation\n    PIM-&gt;&gt;Group: Activates temporary membership\n    Group--&gt;&gt;PIM: Activation confirmation\n    PIM--&gt;&gt;User: Access granted\n</code></pre>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#azure-roles","title":"Azure roles","text":"<p>In the Microsoft Entra ID portal, you can manage Azure roles by selecting the \"Azure resources\" tab. Here you can see all the Azure roles that are available to you by scope, as well as the roles that you have activated.</p> <p>First you need to select the Azure resource that you want to manage: Management groups, Subscriptions, Resource groups or Resources and follow Manage Resource.</p> <p>Once here, same as the other sections, you can made the following actions for this scope:</p> <ul> <li>Assign: Create assignments for the member and owner role of the group, update existing assignments to ensure that users have just-in-time access to privileged roles.</li> <li>Activate: Activate your eligible assignments to get just-in-time access to privileged roles.</li> <li>Approve: List, approve, or deny activation requests for the member and owner role of the group.</li> <li>Audit: View and export a history of all assignments and activations done in PIM so you can identify attacks and stay compliant.</li> </ul> <p>Ok, let's see how to assign a role to a identity in a scope.</p> <p>Info</p> <p>We already have a scope selected</p> <p>In the \"Assignments\" tab, click on \"Add assignments\". In Select role, select the role that you want to assign and in Select members select the identity related that you want to assign the role to or group, if you select a group, you doesn't need a eligible group,  and then click \"Next\".</p> <p>In the \"Settings\" tab, you can set the Assigment type: Eligible or I need to do something to activate and Active or I don't need to do nothing to activate my role. You can configure too if you want that the duration of the assignment is permanent or if you want to expire the assignment after a certain period of time. Once you're done, click \"Assign\".</p> <p>Info</p> <p>App registrations are supported in PIM for Azure roles but only in active assignments. I think that this is very useful for IaC for example because you can assign a role to a service principal and you can activate the role when you need it.</p> <p>Don't forget review settings for the role, modify Activation, Assignment, and Notification settings for members or users, these settings are the same that we saw in the Microsoft Entra ID roles section.</p>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/12/microsoft-entra-id-privileged-identity-management/#conclusion","title":"Conclusion","text":"<p>Microsoft Entra ID Privileged Identity Management (PIM) is a powerful service that helps you manage and monitor access to privileged roles in your organization. By using Microsoft Entra ID PIM, you can reduce the risk of unauthorized access, meet compliance requirements, and improve the efficiency of your organization. I hope this post has helped you understand how to use Microsoft Entra ID PIM and how it can benefit your organization.</p> <p>If you want to play with Microsoft Enter ID PIM, you can use a test on a new tenant or the current one if you haven't used it before.</p>","tags":["Microsoft Entra ID Privileged Identity Management"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/","title":"Restrict managed disks from being imported or exported","text":"<p>In this post, I will show you how to restrict managed disks from being imported or exported in Azure.</p>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#what-are-managed-disks","title":"What are managed disks?","text":"<p>Azure Managed Disks are block-level storage volumes that are managed by Azure and used with Azure Virtual Machines. Managed Disks are designed for high availability and durability, and they provide a simple and scalable way to manage your storage.</p> <p>If you don't know anything about Azue Managed Disks, grab a cup of coffee( it will take you a while), you can read the official documentation to learn more about them.</p>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#why-restrict-managed-disks-from-being-imported-or-exported","title":"Why restrict managed disks from being imported or exported?","text":"<p>There are several reasons to restrict managed disks from being imported or exported:</p> <ul> <li>Security: By restricting managed disks from being imported or exported, you can reduce the risk of unauthorized access to your data.</li> <li>Compliance: By restricting managed disks from being imported or exported, you can help ensure that your organization complies with data protection regulations.</li> </ul>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#how-to-restrict-managed-disks-from-being-imported-or-exported","title":"How to restrict managed disks from being imported or exported","text":"","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#at-deployment-time","title":"At deployment time","text":"<p>An example with azcli:</p>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#create-a-managed-disk-with-public-network-access-disabled","title":"Create a managed disk with public network access disabled","text":"<pre><code>## Create a managed disk with public network access disabled\naz disk create --resource-group myResourceGroup --name myDisk --size-gb 128 --location eastus --sku Standard_LRS --no-wait --public-network-access disabled \n</code></pre>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#create-a-managed-disk-with-public-network-access-disabled-and-private-endpoint-enabled","title":"Create a managed disk with public network access disabled and private endpoint enabled","text":"<p>Follow Azure CLI - Restrict import/export access for managed disks with Private Links</p>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#at-scale","title":"At Scale","text":"<p>If you want to restrict managed disks from being imported or exported, you can use Azure Policy to enforce this restriction. Azure Policy is a service in Azure that you can use to create, assign, and manage policies that enforce rules and effects over your resources. By using Azure Policy, you can ensure that your resources comply with your organization's standards and service-level agreements.</p> <p>To restrict managed disks from being imported or exported using Azure Policy, you can use or create a policy definition that specifies the conditions under which managed disks can be imported or exported. You can then assign this policy definition to a scope, such as a management group, subscription, or resource group, to enforce the restriction across your resources.</p> <p>In this case we have a Built-in policy definition that restricts managed disks from being imported or exported Configure disk access resources with private endpoints</p>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/13/restrict-managed-disks-from-being-imported-or-exported/#conclusion","title":"Conclusion","text":"<p>In this post, I showed you how to restrict managed disks from being imported or exported in Azure. By restricting managed disks from being imported or exported, you can reduce the risk of unauthorized access to your data and help ensure that your organization complies with data protection regulations. </p> <p>Curiosly, restrict managed disks from being imported or exported, it's not a compliance check in the Microsoft cloud security benchmark but it's a good practice to follow.</p>","tags":["Azure Managed Disks"]},{"location":"blog/2024/06/15/tagging-best-practices-in-azure/","title":"Tagging best practices in Azure","text":"<p>In this post, I will show you some best practices for tagging resources in Azure.</p>","tags":["Azure Tags"]},{"location":"blog/2024/06/15/tagging-best-practices-in-azure/#what-are-tags","title":"What are tags?","text":"<p>Tags are key-value pairs that you can assign to your Azure resources to organize and manage them more effectively. Tags allow you to categorize resources in different ways, such as by environment, owner, or cost center, and to apply policies and automation based on these categories.</p> <p>If you don't know anything about tags, you can read the official documentation to learn more about them.</p>","tags":["Azure Tags"]},{"location":"blog/2024/06/15/tagging-best-practices-in-azure/#why-use-tags","title":"Why use tags?","text":"<p>There are several reasons to use tags:</p> <ul> <li> <p>Organization: Tags allow you to organize your resources in a way that makes sense for your organization. You can use tags to group resources by environment, project, or department, making it easier to manage and monitor them.</p> </li> <li> <p>Cost management: Tags allow you to track and manage costs more effectively. You can use tags to identify resources that are part of a specific project or department, and to allocate costs accordingly.</p> </li> <li> <p>Automation: Tags allow you to automate tasks based on resource categories. You can use tags to apply policies, trigger alerts, or enforce naming conventions, making it easier to manage your resources at scale.</p> </li> </ul>","tags":["Azure Tags"]},{"location":"blog/2024/06/15/tagging-best-practices-in-azure/#best-practices-for-tagging-resources-in-azure","title":"Best practices for tagging resources in Azure","text":"<p>Here are some best practices for tagging resources in Azure:</p> <ul> <li> <p>Use consistent naming conventions: Define a set of standard tags that you will use across all your resources. This will make it easier to search for and manage resources, and to apply policies and automation consistently.</p> </li> <li> <p>Apply tags at resource creation: Apply tags to resources when you create them, rather than adding them later. This will ensure that all resources are tagged correctly from the start, and will help you avoid missing or incorrect tags.</p> </li> <li> <p>Use tags to track costs: Use tags to track costs by project, department, or environment. This will help you allocate costs more effectively, and will make it easier to identify resources that are not being used or are costing more than expected.</p> </li> <li> <p>Define tags by hierarchy: Define tags in a hierarchy that makes sense for your organization, from more general at level subscription to more specific at resource group level. </p> </li> <li> <p>Use inherited tags: Use inherited tags to apply tags to resources automatically based on their parent resources. This will help you ensure that all resources are tagged consistently, and will reduce the risk of missing or incorrect tags. Exist Azure Policy to enforce inherited tags for example, you can check all in   Assign policy definitions for tag compliance</p> </li> <li> <p>Don't use tags for policy filtering: If you use Azure Policy, it's highly recommended not to use tag filtering in your policy rules when the policy relates to security setting, when you use tags to filter, resources without tag appear Compliance. Azure Policy exemptions or Azure Policy exclusions are recommended.</p> </li> <li> <p>Don't use tags for replace naming convention gaps: Tags are not a replacement for naming conventions. Use tags to categorize resources, and use naming conventions to identify resources uniquely.</p> </li> <li> <p>Use tags for automation: Use tags to trigger automation tasks, such as scaling, backup, or monitoring. You can use tags to define policies that enforce specific actions based on resource categories.</p> </li> <li> <p>Don't go crazy adding tags: Don't add too many tags to your resources. Keep it simple and use tags that are meaningful and useful. Too many tags can make it difficult to manage. You can begin with a small set of tags and expand as needed, for example: Minimum Suggested Tags</p> </li> <li> <p>Not all Azure services support tags: Keep in mind that not all Azure services support tags. You can check in the Tag support for Azure resources to see which services support tags.</p> </li> </ul>","tags":["Azure Tags"]},{"location":"blog/2024/06/15/tagging-best-practices-in-azure/#conclusion","title":"Conclusion","text":"<p>By using tags, you can organize and manage your resources more effectively, track and manage costs more efficiently, and automate tasks based on resource categories. I hope this post has given you a good introduction to tagging best practices in Azure and how you can use tags to optimize your cloud environment.</p>","tags":["Azure Tags"]},{"location":"blog/2024/06/17/microsoft-entra-conditional-access/","title":"Microsoft Entra Conditional Access","text":"<p>In this post, I will show you how to configure Conditional Access in Microsoft Entra.</p>","tags":["Microsoft Entra Conditional Access"]},{"location":"blog/2024/06/17/microsoft-entra-conditional-access/#what-is-conditional-access","title":"What is Conditional Access?","text":"<p>Conditional Access is a feature of Microsoft Entra that allows you to control access to your organization's resources based on specific conditions. With Conditional Access, you can enforce policies that require users to meet certain criteria before they can access resources, such as multi-factor authentication, device compliance, or location-based restrictions.</p> <p>You have three main components in Conditional Access:</p> <ul> <li>Signals: These are the conditions that trigger a policy. Signals can include user sign-in, device state, location, and more.</li> <li>Decisions: These are the actions that are taken when a policy is triggered. Decisions can include requiring multi-factor authentication, blocking access, or granting access with conditions.</li> <li>Enforcement: This is the mechanism that enforces the policy. Enforcement can be done at the application level, the network level, or the device level.</li> </ul> <p>Really, all the Conditional Access policies are based on the following flow:</p> <ol> <li>Assignments: Define who and where the policy applies to.</li> <li>Access Controls: Define what to do when the the who and where are met.</li> </ol> <p>For that reason, we can define the followin phases:</p> <ul> <li>Phase 1: Collect session details</li> <li> <p>Assignments: Define who and where the policy applies to.    </p> <ul> <li>users: users and groups selected and excluded</li> <li>Target resources: Control access base on Cloud apps, actions, and authentication context.</li> <li>Cloud apps: Include and exclude. Many of the existing Microsoft cloud applications are included in the list of applications that can be targeted by Conditional Access policies:  Office 365, Windows Azure Service Management API, Microsoft Admin Portals and Others</li> <li>User actions: Tasks that a user performs: Register security information and Register or join devices</li> <li>Global Secure Access: Targeting members in your tenant with Global Secure Access (GSA) as a resource,enable administrators to define and control how traffic is routed through Microsoft Entra Internet Access and Microsoft Entra Private Access.</li> <li>Authentication context: With this option you can define a authentication context for the policy, for example, you can define that the policy is applied only when the user is accessing to Higly Confidential information. You can create labels with ID c1 to c99 and tag your information with these labels. Not all apps support authentication contexts, you can check the official documentation to see which apps support it.</li> <li>Network: Include and Exclude. Control user access based on their network location or physical location.<ul> <li>Any network or location: This option allows you to apply the policy to all network locations.</li> <li>All trusted locations: This option allows you to apply the policy to all trusted locations.</li> <li>All Compliant Network locations: This option allows you to apply the policy to all compliant network locations.</li> <li>Selected network or location: This option allows you to apply the policy to selected network locations: Countries(GPS),Countries(IP) and IP ranges.</li> </ul> </li> <li>Conditions: Control access based in signals from conditions.<ul> <li>User risk: Control access based on the user risk level calculated by Microsoft Entra Identity Protection. User risk represents the probability that a given identity or account is compromised, for example: Published credentials in Dark Web.</li> <li>Sign-in risk: Control access based on the sign-in risk level calculated by Microsoft Entra Identity Protection. Sign-in risk represents the probability that a given authentication request wasn't made by the identity owner. For example, sign-in from a new location or new device.</li> <li>Insider risk: Control access for users who are assigned specific risk levels from Adaptive Protection, a Microsoft Purview Insider Risk Management feature. Insider risk represents the probability that a given user is engaged in risky data-related activities.</li> <li>Device Platform: Include and Exclude. Control access based on the platform of the device used to sign in.</li> <li>Client apps: Include and Exclude. Control access based on the client apps used to sign in.</li> <li>Filters for devices: Include and Exclude. Control access based on configured filters to apply policy to specific devices</li> <li>Authentication flows: Control access based on the authentication flow used to sign in: </li> <li>Device code flow: Device code flow is a method of authentication that allows users to sign in to a device using a code displayed on the device. This flow is used for devices that don't have a browser or can't use a browser to sign in.</li> <li>Authentication transfer: Authentication transfer is a new flow that offers a seamless way to transfer authenticated state from one device to another.</li> </ul> </li> </ul> </li> <li> <p>Phase 2: Enforcement</p> </li> <li>Access controls: Define what to do when the the who and where are met.<ul> <li>Grant: Control access enforcement to block or grant access.</li> <li>Block: Block access to the resource.</li> <li>Grant: Grant access to the resource. You can also define the following options:<ul> <li>Require multi-factor authentication: Require users to perform multi-factor authentication.</li> <li>Require authentication strength:  Require a combination of authentication methods to access the resource.</li> <li>Require device to be marked as compliant: Require the device to be marked as compliant by Microsoft Entra Intune.</li> <li>Require Hybrid Azure AD joined device: Require the device to be Hybrid Azure AD joined.</li> <li>Require approved client app: Require the use of an approved client app.</li> <li>Require app protection policy: Require that an Intune app protection policy is present on the client app before access is available to the selected applications</li> <li>Require password change: Require the user to change their password.</li> </ul> </li> <li>For multiple controls, you can define the following options:<ul> <li>Require all the selected controls: Require all the selected controls to be met.</li> <li>Require one of the selected controls: Require one of the selected controls to be met.</li> </ul> </li> </ul> </li> <li>Session: Control access based on session controls to enable limited experiences within specific cloud applications.<ul> <li>Use app enforced restrictions: Enforce app restrictions to control access based on the app's own restrictions. When selected, the cloud app uses the device information to provide users with a limited or full experience. Limited when the device isn't managed or compliant and full when the device is managed and compliant.</li> <li>Use Conditional Access App Control: Enforce real-time monitoring and control of user sessions. Conditional Access App Control enables user app access and sessions to be monitored and controlled in real time based on access and session policies. Access and session policies are used within the Defender for Cloud Apps portal to refine filters and set actions to take.</li> <li>Sign-in frequency: Enforce sign-in frequency to control how often users are prompted to sign in. Sign-in frequency setting works with apps that implement OAUTH2 or OIDC protocols according to the standards.</li> <li>Persistent browser session: Enforce persistent browser session to control users can remain signed in after closing and reopening their browser window.</li> <li>Customize continuous access evaluation: Enable custom continuous access evaluation to revoke access tokens based on critical events and policy evaluation in real time.Continuous Access Evaluation (CAE) allows access tokens to be revoked based on critical events and policy evaluation in real time rather than relying on token expiration based on lifetime.</li> </ul> </li> </ul> <p>Example of Conditional Access policy configuration:</p> <ol> <li>Block access to all users from all locations except for a specific group of users from a specific location:</li> <li>Assignments:<ul> <li>users: </li> <li>Include:All users</li> <li>Exclude: Group_of_excluded_users</li> <li>Target resources:</li> <li>Cloud apps: All cloud apps</li> <li>Network: All trusted locations</li> </ul> </li> <li>Access controls:<ul> <li>Grant: Block</li> </ul> </li> </ol> <p>Mindmaps of the Conditional Access policies flow:</p> # Conditional Access Policy ## Phase 1: Collect session details ### Assignments #### users ##### Include ###### None ###### All users ###### Select users and groups ##### Exclude ###### Guest or external users ###### Directory roles ###### Users and groups #### Target resources ##### Cloud apps ###### Include  - None  - All cloud apps  - Select apps ###### Exclude   - Edit Filter   - Select excluded cloud apps ##### User actions   - Register security information   - Register or join devices ##### Global Secure Access   - Microsoft 365 traffic   - Internet traffic   - Private traffic ##### Authentication context ##### Network ###### Any network or location ###### All trusted locations ###### All Compliant Network locations ###### Selected network or location #### Conditions ##### User risk ##### Sign-in risk ##### Insider risk ##### Device Platform ##### Client apps ##### Filters for devices ##### Authentication flows ###### Device code flow ###### Authentication transfer ## Phase 2: Enforcement ### Access controls #### Grant ##### Block ##### Grant ###### Require multi-factor authentication ###### Require authentication strength ###### Require device to be marked as compliant ###### Require Hybrid Azure AD joined device ###### Require approved client app ###### Require app protection policy ###### Require password change ##### For multiple controls ###### Require all the selected controls ###### Require one of the selected controls #### Session ##### Use app enforced restrictions ##### Use Conditional Access App Control ##### Sign-in frequency ##### Persistent browser session ##### Customize continuous access evaluation <pre><code>mindmap\n    root((Conditional Access Policy))\n      (Phase 1: Collect session details)\n        (Assignments)        \n          [users]\n            {{Include}}\n              None\n              All users\n              Select users and groups\n            {{Exclude}}\n              Guest or external users\n              Directory roles\n              Users and groups\n          [Target resources]\n            {{Cloud apps}}\n              Include\n                None\n                All cloud apps\n                Select apps\n              Exclude\n                Edit Filter\n                Select excluded cloud apps\n            {{User actions}}\n              Register security information\n              Register or join devices\n            {{Global Secure Access}}\n              Microsoft 365 traffic\n              Internet traffic\n              Private traffic\n            {{Authentication context}}\n            {{Network}}\n              Any network or location\n              All trusted locations\n              All Compliant Network locations\n              Selected network or location\n          [Conditions]\n            {{User risk}}\n            {{Sign-in risk}}\n            {{Insider risk}}\n            {{Device Platform}}\n            {{Client apps}}\n            {{Filters for devices}}\n            {{Authentication flows}}\n              Device code flow\n              Authentication transfer\n      (Phase 2: Enforcement)\n        (Access controls)\n          [Grant]\n            {{Block}}\n            {{Grant}}\n              Require multi-factor authentication\n              Require authentication strength\n              Require device to be marked as compliant\n              Require Hybrid Azure AD joined device\n              Require approved client app\n              Require app protection policy\n              Require password change\n            {{For multiple controls}}\n              Require all the selected controls\n              Require one of the selected controls\n          [Session]\n            {{Use app enforced restrictions}}\n            {{Use Conditional Access App Control}}\n            {{Sign-in frequency}}\n            {{Persistent browser session}}\n            {{Customize continuous access evaluation}}\n</code></pre>","tags":["Microsoft Entra Conditional Access"]},{"location":"blog/2024/06/17/microsoft-entra-conditional-access/#resources","title":"Resources","text":"<ul> <li>Conditional Access documentation</li> </ul>","tags":["Microsoft Entra Conditional Access"]},{"location":"blog/2024/06/18/when-to-use-service-principals/","title":"When to use service principals","text":"<p>In Azure, there are two ways to authenticate your applications and services: service principals and managed identities. </p> <p>Basically, don't use service principals if you can use managed identities. Managed identities are a more secure way to authenticate your applications and services in Azure. However, there are some scenarios where you need to use service principals instead of managed identities. Here are some scenarios where you should use service principals:</p> <pre><code>flowchart TD\n    A[When to use service principals] --&gt; B{Is your application or service running on-premises?}\n    B --&gt; |Yes| C{Is Azure Arc supported?}\n    C --&gt; |Yes| D[Use Managed Identity]\n    C --&gt; |No| E[Use Service Principal]\n    B --&gt; |No| F{Do the resources or applications support managed identities?}\n    F --&gt; |No| G[Use Service Principal]\n    F --&gt; |Yes| H[Use Managed Identity]\n</code></pre>","tags":["Service Principal","Managed Identity"]},{"location":"blog/2024/06/18/when-to-use-service-principals/#conclusion","title":"Conclusion","text":"<p>In conclusion, you should use managed identities whenever possible. However, if your application or service is running on-premises or if the resources or applications do not support managed identities, you should use service principals instead.</p>","tags":["Service Principal","Managed Identity"]},{"location":"blog/2024/09/09/markmap/","title":"markmap","text":"<p>markmap is a visualisation tool that allows you to create mindmaps from markdown files. It is based on the mermaid library and can be used to create a visual representation of a markdown file.</p>","tags":["markmap"]},{"location":"blog/2024/09/09/markmap/#installation-in-mkdocs","title":"Installation in mkdocs","text":"<p>To install markmap in mkdocs, you need install the plugin using pip:</p> <pre><code>pip install mkdocs-markmap\n</code></pre> <p>Then, you need to add the following lines to your <code>mkdocs.yml</code> file:</p> <pre><code>plugins:\n  - markmap\n</code></pre>","tags":["markmap"]},{"location":"blog/2024/09/09/markmap/#usage","title":"Usage","text":"<p>To use markmap, you need to add the following code block to your markdown file:</p> <pre><code>```markmap  \n# Root\n\n## Branch 1\n\n* Branchlet 1a\n* Branchlet 1b\n\n## Branch 2\n\n* Branchlet 2a\n* Branchlet 2b\n```\n</code></pre> <p>And this will generate the following mindmap:</p> <p></p> <p>That is for the future, because in my mkdocs not work as expected:</p> # Root  ## Branch 1  * Branchlet 1a * Branchlet 1b  ## Branch 2  * Branchlet 2a * Branchlet 2b","tags":["markmap"]},{"location":"blog/2024/09/09/markmap/#visual-studio-code-extension","title":"Visual Studio Code Extension","text":"<p>There is also a Visual Studio Code extension that allows you to create mindmaps from markdown files. You can install it from the Visual Studio Code marketplace.</p> <p><pre><code>    Name: Markdown Preview Markmap Support\n    Id: phoihos.markdown-markmap\n    Description: Visualize Markdown as Mindmap (A.K.A Markmap) to VS Code's built-in markdown preview\n    Version: 1.4.6\n    Publisher: phoihos\n    VS Marketplace Link: https://marketplace.visualstudio.com/items?itemName=phoihos.markdown-markmap\n</code></pre> VS Marketplace Link</p>","tags":["markmap"]},{"location":"blog/2024/09/09/markmap/#conclusion","title":"Conclusion","text":"<p>I don't like too much this plugin because it not work as expected in my mkdocs but it's a good tool for documentation.</p>","tags":["markmap"]},{"location":"blog/2024/09/09/markmap/#references","title":"References","text":"<ul> <li>markmap</li> <li>mkdocs-markmap</li> </ul>","tags":["markmap"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/","title":"Data threat modeling in Azure storage accounts","text":"<p>Info</p> <p>I apologize in advance if this is a crazy idea and there is some mistake!! I am just trying to learn and share knowledge.</p> <p>Azure Storage Account is a service that provides scalable, secure, and reliable storage for data. It is used to store data such as blobs, files, tables, and queues. However, it is important to ensure that the data stored in Azure Storage Account is secure and protected from security threats. In this article, we will discuss how to perform data threat modeling in Azure storage accounts.</p>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#what-is-data-threat-modeling","title":"What is data threat modeling?","text":"<p>Data threat modeling is a process of identifying and analyzing potential threats to data security. It helps organizations understand the risks to their data and develop strategies to mitigate those risks. Data threat modeling involves the following steps:</p> <ol> <li>Identify assets: Identify the data assets stored in Azure storage accounts, such as blobs, files, tables, and queues.</li> <li>Identify threats: Identify potential threats to the data assets, such as unauthorized access, data breaches, data leakage, malware, phishing attacks, insider threats, and data loss.</li> <li>Assess risks: Assess the risks associated with each threat, such as the likelihood of the threat occurring and the impact of the threat on the data assets.</li> <li>Develop mitigation strategies: Develop strategies to mitigate the risks, such as implementing security controls, access controls, encryption, monitoring, and auditing.</li> </ol> <p>By performing data threat modeling, organizations can identify and address security vulnerabilities in Azure storage accounts and protect their data from security threats.</p>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#identify-assets-in-azure-storage-accounts","title":"Identify assets in Azure storage accounts","text":"<p>Azure storage accounts can store various types of data assets, including:</p> <ul> <li>Blobs: Binary large objects (blobs) are used to store unstructured data, such as images, videos, and documents.</li> <li>Files: Files are used to store structured data, such as text files, configuration files, and log files.</li> <li>Tables: Tables are used to store structured data in a tabular format, such as customer information, product information, and transaction data.</li> <li>Queues: Queues are used to store messages for communication between applications, such as task messages, notification messages, and status messages.</li> <li>Disks: Disks are used to store virtual machine disks, such as operating system disks and data disks.</li> </ul> <p>Identifying the data assets stored in Azure storage accounts is the first step in data threat modeling. It helps organizations understand the types of data stored in Azure storage accounts and the potential risks to those data assets.</p>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#identify-threats-to-data-in-azure-storage-accounts","title":"Identify threats to data in Azure storage accounts","text":"<p>There are several threats to data stored in Azure storage accounts, including:</p> <ul> <li>Unauthorized access: Unauthorized users gaining access to Azure storage accounts and stealing data.</li> <li>Data breaches: Data breaches can expose sensitive data stored in Azure storage accounts.</li> <li>Data leakage: Data leakage can occur due to misconfigured access controls or insecure data transfer protocols.</li> <li>Data loss: Data loss can occur due to accidental deletion, corruption, or hardware failure.</li> <li>Ransomware: Ransomware can encrypt data stored in Azure storage accounts and demand a ransom for decryption.</li> <li>DDoS attacks: DDoS attacks can disrupt access to data stored in Azure storage accounts.</li> <li>Phishing attacks: Phishing attacks can trick users into providing their login credentials, which can be used to access and steal data.</li> <li>Malware: Malware can be used to steal data from Azure storage accounts and transfer it to external servers.</li> <li>Insider threats: Employees or contractors with access to sensitive data may intentionally or unintentionally exfiltrate data.</li> <li>Data exfiltration: Unauthorized transfer of data from Azure storage accounts to external servers.</li> </ul> <p>For example, the flow of data exfiltration in Azure storage accounts can be summarized as follows:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Azure Storage Account\n    participant External Server\n\n    User-&gt;&gt;Azure Storage Account: Upload data\n    Azure Storage Account-&gt;&gt;External Server: Unauthorized transfer of data\n</code></pre> <p>In this flow, the user uploads data to the Azure Storage Account, and the data is then transferred to an external server without authorization. This unauthorized transfer of data is known as data exfiltration.</p>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#assess-risks-to-data-in-azure-storage-accounts","title":"Assess risks to data in Azure storage accounts","text":"<p>Assessing the risks associated with threats to data in Azure storage accounts is an important step in data threat modeling. Risks can be assessed based on the likelihood of the threat occurring and the impact of the threat on the data assets. Risks can be categorized as low, medium, or high based on the likelihood and impact of the threat.</p> <p>For example, the risk of unauthorized access to Azure storage accounts may be categorized as high if the likelihood of unauthorized access is high and the impact of unauthorized access on the data assets is high. Similarly, the risk of data leakage may be categorized as medium if the likelihood of data leakage is medium and the impact of data leakage on the data assets is medium.</p> <p>By assessing risks to data in Azure storage accounts, organizations can prioritize security measures and develop strategies to mitigate the risks.</p> <p>For example, the risk of data exfiltration in Azure storage accounts can be assessed as follows:</p> <pre><code>pie\n    title Data Exfiltration Risk Assessment\n    \"Unauthorized Access\" : 30\n    \"Data Breaches\" : 20\n    \"Data Leakage\" : 15\n    \"Malware\" : 10\n    \"Phishing Attacks\" : 10\n    \"Insider Threats\" : 15\n</code></pre>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#develop-mitigation-strategies-for-data-in-azure-storage-accounts","title":"Develop mitigation strategies for data in Azure storage accounts","text":"<p>Developing mitigation strategies is an essential step in data threat modeling. Mitigation strategies help organizations protect their data assets from security threats and reduce the risks associated with those threats. Mitigation strategies could include the following:</p> <ol> <li>Implement access controls: Implement access controls to restrict access to Azure storage accounts based on user roles and permissions.</li> <li>Encrypt data: Encrypt data stored in Azure storage accounts to protect it from unauthorized access.</li> <li>Monitor and audit access: Monitor and audit access to Azure storage accounts to detect unauthorized access and data exfiltration.</li> <li>Implement security controls: Implement security controls, such as firewalls, network security groups, and intrusion detection systems, to protect data in Azure storage accounts.</li> <li>Use secure transfer protocols: Use secure transfer protocols, such as HTTPS, to transfer data to and from Azure storage accounts.</li> <li>Implement multi-factor authentication: Implement multi-factor authentication to protect user accounts from unauthorized access.</li> <li>Train employees: Train employees on data security best practices to prevent data exfiltration and other security threats.</li> <li>Backup data: Backup data stored in Azure storage accounts to prevent data loss due to accidental deletion or corruption.</li> <li>Update software: Keep software and applications up to date to protect data stored in Azure storage accounts from security vulnerabilities.</li> <li>Implement data loss prevention (DLP) policies: Implement DLP policies to prevent data leakage and unauthorized transfer of data from Azure storage accounts.</li> </ol> <p>As it is not an easy task, Microsoft provides us with tools for this, in the case of using a security framework we can always use the MCSB (Microsoft Cloud Security Baseline) which is a set of guidelines and best practices for securing Azure services, including Azure storage accounts. The MCSB provides recommendations for securing Azure storage accounts, such as enabling encryption, implementing access controls, monitoring access, and auditing activities:</p> Control Domain ASB Control ID ASB Control Title Responsibility Feature Name Asset Management AM-2 Use only approved services Customer Azure Policy Support Backup and recovery BR-1 Ensure regular automated backups Customer Azure Backup Backup and recovery BR-1 Ensure regular automated backups Customer Service Native Backup Capability Data Protection DP-1 Discover, classify, and label sensitive data Customer Sensitive Data Discovery and Classification Data Protection DP-2 Monitor anomalies and threats targeting sensitive data Customer Data Leakage/Loss Prevention Data Protection DP-3 Encrypt sensitive data in transit Microsoft Data in Transit Encryption Data Protection DP-4 Enable data at rest encryption by default Microsoft Data at Rest Encryption Using Platform Keys Data Protection DP-5 Use customer-managed key option in data at rest encryption when required Customer Data at Rest Encryption Using CMK Data Protection DP-6 Use a secure key management process Customer Key Management in Azure Key Vault Identity Management IM-1 Use centralized identity and authentication system Microsoft Azure AD Authentication Required for Data Plane Access Identity Management IM-1 Use centralized identity and authentication system Customer Local Authentication Methods for Data Plane Access Identity Management IM-3 Manage application identities securely and automatically Customer Managed Identities Identity Management IM-3 Manage application identities securely and automatically Customer Service Principals Identity Management IM-7 Restrict resource access based on conditions Customer Conditional Access for Data Plane Identity Management IM-8 Restrict the exposure of credential and secrets Customer Service Credential and Secrets Support Integration and Storage in Azure Key Vault Logging and threat detection LT-1 Enable threat detection capabilities Customer Microsoft Defender for Service / Product Offering Logging and threat detection LT-4 Enable network logging for security investigation Customer Azure Resource Logs Network Security NS-2 Secure cloud services with network controls Customer Disable Public Network Access Network Security NS-2 Secure cloud services with network controls Customer Azure Private Link Privileged Access PA-7 Follow just enough administration(least privilege) principle Customer Azure RBAC for Data Plane Privileged Access PA-8 Choose approval process for third-party support Customer Customer Lockbox <p>And part of MCSB can be complemented with Azure Well Architected Framework, which provides guidance on best practices for designing and implementing secure, scalable, and reliable cloud solutions. The Well Architected Framework includes security best practices for Azure storage accounts, such as implementing security controls, access controls, encryption, monitoring, and auditing:</p> <ol> <li>Enable Azure Defender for all your storage accounts: Azure Defender for Storage provides advanced threat protection for Azure storage accounts. It helps detect and respond to security threats in real-time.</li> <li>Turn on soft delete for blob data: Soft delete helps protect your blob data from accidental deletion. It allows you to recover deleted data within a specified retention period.</li> <li>Use Microsoft Entitlement Management to authorize access to blob data: Microsoft Entitlement Management provides fine-grained access control for Azure storage accounts. It allows you to define and enforce access policies based on user roles and permissions.</li> <li>Consider the principle of least privilege: When assigning permissions to a Microsoft Entitlement security principal through Azure RBAC, follow the principle of least privilege. Only grant the minimum permissions required to perform the necessary tasks.</li> <li>Use managed identities to access blob and queue data: Managed identities provide a secure way to access Azure storage accounts without storing credentials in your code.</li> <li>Use blob versioning or immutable blobs: Blob versioning and immutable blobs help protect your business-critical data from accidental deletion or modification.</li> <li>Restrict default internet access for storage accounts: Limit default internet access to Azure storage accounts to prevent unauthorized access.</li> <li>Enable firewall rules: Use firewall rules to restrict network access to Azure storage accounts. Only allow trusted IP addresses to access the storage account.</li> <li>Limit network access to specific networks: Limit network access to specific networks or IP ranges to prevent unauthorized access.</li> <li>Allow trusted Microsoft services to access the storage account: Allow only trusted Microsoft services to access the storage account to prevent unauthorized access.</li> <li>Enable the Secure transfer required option: Enable the Secure transfer required option on all your storage accounts to enforce secure connections.</li> <li>Limit shared access signature (SAS) tokens to HTTPS connections only: Limit shared access signature (SAS) tokens to HTTPS connections only to prevent unauthorized access.</li> <li>Avoid using Shared Key authorization: Avoid using Shared Key authorization to access storage accounts. Use Azure AD or SAS tokens instead.</li> <li>Regenerate your account keys periodically: Regenerate your account keys periodically to prevent unauthorized access.</li> <li>Create a revocation plan for SAS tokens: Create a revocation plan and have it in place for any SAS tokens that you issue to clients. This will help you revoke access to the storage account if necessary.</li> <li>Use near-term expiration times on SAS tokens: Use near-term expiration times on impromptu SAS, service SAS, or account SAS to limit the exposure of the token.</li> </ol>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#mixed-strategies-for-data-protection-in-azure-storage-accounts","title":"Mixed strategies for data protection in Azure storage accounts","text":"<p>Diagram of the mixed strategies for data protection in Azure storage accounts:</p> <pre><code>graph LR\n    A[Asset Management] --&gt;B(AM-2)\n    B --&gt; C[Use only approved services]\n    C --&gt; D[Azure Policy] \n    E[Backup and recovery] --&gt;F(BR-1)\n    F --&gt; G[Ensure regular automated backups]\n    G --&gt; H[Azure Backup]\n    G --&gt; I[Service Native Backup Capability]\n    I --&gt; I1[\"Azure Storage Account Configuration\"]\n    I1 --&gt; I11[\"Turn on soft delete for blob data\"]\n    I1 --&gt; I12[\"Use blob versioning or immutable blobs\"]\n</code></pre> <pre><code>graph LR\n    J[Data Protection] --&gt;K(DP-1)\n    K --&gt; L[Discover, classify, and label sensitive data]    \n    L --&gt; M[Sensitive Data Discovery and Classification]\n    M --&gt; M1[\"Microsoft Pureview\"]       \n    J --&gt; N(DP-2)\n    N --&gt; O[Monitor anomalies and threats targeting sensitive data]\n    O --&gt; P[Data Leakage/Loss Prevention]\n    P --&gt; P1[\"Microsoft Defender for Storage\"]\n    J --&gt; Q(DP-3)\n    Q --&gt; R[Encrypt sensitive data in transit]\n    R --&gt; S[Data in Transit Encryption]\n    S --&gt; S1[\"Azure Storage Account Configuration\"]\n    S1 --&gt; S2[\"Enforce minimum TLS version\"]\n    J --&gt; T(DP-4)\n    T --&gt; U[Enable data at rest encryption by default]\n    U --&gt; V[Data at Rest Encryption Using Platform Keys]\n    V --&gt; WW[\"Azure Storage Account Configuration\"]    \n    J --&gt; W(DP-5)\n    W --&gt; X[Use customer-managed key option in data at rest encryption when required]\n    X --&gt; Y[Data at Rest Encryption Using CMK]\n    Y --&gt; WW[\"Azure Storage Account Configuration\"]    \n    J --&gt; Z(DP-6)\n    Z --&gt; AA[Use a secure key management process]\n    AA --&gt; AB[Key Management in Azure Key Vault]\n    AB --&gt; AC[\"DEPRECATED\"]\n</code></pre> <pre><code>graph LR  \n    AC[Identity Management] --&gt;AD(IM-1)\n    AD --&gt; AE[Use centralized identity and authentication system]\n    AE --&gt; AE1[\"Microsoft Entra ID\"]\n    AE --&gt; AF[Microsoft Entra ID Authentication Required for Data Plane Access]\n    AF --&gt; AF1[\"Azure Storage Account Configuration\"]\n    AF1 --&gt; AF2[\"Disable Allow Shared Key authorization\"]\n    AD --&gt; AG[Local Authentication Methods for Data Plane Access]\n    AG --&gt; AG1[\"Azure Storage Account Configuration\"]\n    AG1 --&gt; AG2[\"Don't use SFTP if you don't need it\"]\n    AC --&gt; AH(IM-3)\n    AH --&gt; AI[Manage application identities securely and automatically]\n    AI --&gt; AJ[Managed Identities]\n    AI --&gt; AK[Service Principals]\n    AK --&gt; AK1[\"Rotate or regenerate service principal credentials\"]\n    AC --&gt; AL(IM-7)\n    AL --&gt; AM[Restrict resource access based on conditions]\n    AM --&gt; AN[Microsoft Entra Conditional Access for Data Plane]\n    AC --&gt; AO(IM-8)\n    AO --&gt; AP[Restrict the exposure of credential and secrets]    \n    AP --&gt; AQ[Service Credential and Secrets Support Integration and Storage in Azure Key Vault]    \n    AQ --&gt; AK1\n    click AK1 \"https://github.com/Azure-Samples/KeyVault-Rotation-StorageAccountKey-PowerShell\" \"Open this in a new tab\" _blank\n</code></pre> <p><pre><code>graph LR\nAR[Logging and threat detection] --&gt;AS(LT-1)\n    AS --&gt; AT[Enable threat detection capabilities]\n    AT --&gt; AU[Microsoft Defender for Service / Product Offering]\n    AU --&gt; AU1[\"Microsoft Defender for Storage\"]\n    AR --&gt; AV(LT-4)\n    AV --&gt; AW[Enable network logging for security investigation]\n    AW --&gt; AX[Azure Resource Logs]\n    AX --&gt; AX1[\"Azure Monitor\"]\n    AX --&gt; AX2[\"Azure Activity Log\"]\n    click AU1 \"https://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-storage-introduction\" \"Open this in a new tab\" _blank\n</code></pre> <pre><code>graph LR\n    AY[Network Security] --&gt;AZ(NS-2)\n    AZ --&gt; BA[Secure cloud services with network controls]\n    BA --&gt; BB[\"Azure Storage Account Configuration\"]\n    BB --&gt; BB1[Disable Public Network Access]\n    BB --&gt; BB2[Allow trusted Microsoft services to access the storage account]\n    BA --&gt; BC[Azure Private Link]\n    BC --&gt; BC1[\"Azure Private Endpoint\"]\n    BA --&gt; BD[Azure Network]\n    BD --&gt; BD1[\"Azure Service Endpoint\"]\n    BA --&gt; BE[\"Network Security Perimeter\"]\n</code></pre></p> <pre><code>graph LR\n    BD[Privileged Access] --&gt;BE(PA-7)\n    BE --&gt; BF[\"Follow just enough administration(least privilege) principle\"]\n    BF --&gt; BG[Azure RBAC for Data Plane]\n    BG --&gt; BG1[\"Azure RBAC\"]\n    BG1 --&gt; BG2[\"Azure RBAC Roles\"]\n    BD --&gt; BH(PA-8)\n    BH --&gt; BI[Choose approval process for third-party support]\n    BI --&gt; BJ[Customer Lockbox]\nclick BG2 \"https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/storage\" \"Open this in a new tab\" _blank\n</code></pre>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#example-of-mixed-strategies-for-data-protection-in-azure-storage-accounts","title":"Example of mixed strategies for data protection in Azure storage accounts","text":"<p>The following example illustrates how to implement mixed strategies for data protection in Azure storage accounts:</p>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#conclusion","title":"Conclusion","text":"<p>In conclusion, data threat modeling is an important process for identifying and addressing security vulnerabilities in Azure storage accounts. By identifying assets, threats, risks, and developing mitigation strategies, organizations can protect their data from security threats and ensure the security and integrity of their data assets. By following best practices and implementing security measures, organizations can prevent and detect data threats in Azure storage accounts and protect their data from security threats.</p>","tags":["Azure Storage Account"]},{"location":"blog/2024/06/16/data-threat-modeling-in-azure-storage-accounts/#references","title":"References","text":"<ul> <li>Azure Storage Account Documentation</li> <li>Azure security baseline for Storage</li> <li>Well Architected Framework - Storage Accounts and security</li> <li>Microsoft Defender for Storage</li> <li>Azure MAPPINGS</li> </ul>","tags":["Azure Storage Account"]},{"location":"blog/2024/09/17/security-score-system/","title":"Security Score System","text":"<p>The Common Vulnerability Scoring System (CVSS) is a framework for scoring the severity of security vulnerabilities. It provides a standardized method for assessing the impact of vulnerabilities and helps organizations prioritize their response to security threats. In this article, we will discuss the CVSS and how it can be used to calculate the severity of security vulnerabilities.</p>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#what-is-cvss","title":"What is CVSS?","text":"<p>The Common Vulnerability Scoring System (CVSS) is an open framework for scoring the severity of security vulnerabilities. It was developed by the Forum of Incident Response and Security Teams (FIRST) to provide a standardized method for assessing the impact of vulnerabilities. CVSS assigns a numerical score to vulnerabilities based on their characteristics, such as the impact on confidentiality, integrity, and availability, and the complexity of the attack vector.</p> <p>CVSS is widely used by security researchers, vendors, and organizations to prioritize their response to security threats. It helps organizations understand the severity of vulnerabilities and allocate resources to address the most critical issues first.</p>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#how-is-cvss-calculated","title":"How is CVSS calculated?","text":"<p>In CVSS Version 4.0, vulnerabilities are scored on a scale of 0.0 to 10.0, with 10.0 being the most severe. The CVSS score is calculated based on several metrics groups, including:</p> <ul> <li> <p>Base Metric: The Base metric group represents the intrinsic characteristics of a vulnerability that are constant over time and across user environments. It is composed of two sets of metrics: the Exploitability metrics and the Impact metrics.</p> </li> <li> <p>Threat metric group: The Threat metric group reflects the characteristics of a vulnerability related to threat that may change over time but not necessarily across user environments. </p> </li> <li> <p>Environmental metric group: The Environmental metric group represents the characteristics of a vulnerability that are relevant and unique to a particular user's environment.</p> </li> <li> <p>The Supplementary metric group: The Supplemental metric group includes metrics that provide context as well as describe and measure additional extrinsic attributes of a vulnerability. </p> </li> </ul>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#cvss-version-40-metrics","title":"CVSS Version 4.0 Metrics","text":"","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#base-metrics","title":"Base Metrics","text":"<p>The Base metric group includes the following metrics:</p> <ul> <li>Exploitability Metrics: These metrics describe the characteristics of the vulnerability that affect how easy it is to exploit. They include the Attack Vector (AV), Attack Complexity (AC), Privileges Required (PR), and User Interaction (UI).</li> <li>Vulnerable System Impact Metrics: These metrics describe the impact on the system if the vulnerability is exploited. They include the Confidentiality(VC), Integrity (VI), and Availability (VA) impacts.</li> <li>Subsequent System Impact Metrics: These metrics describe the impact on the system if the vulnerability is exploited. They include the Confidentiality(SC), Integrity (II), and Availability (SA) impacts.</li> </ul>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#exploitability-metrics","title":"Exploitability Metrics","text":"<ul> <li>Attack Vector (AV): This metric describes the context where vulnerability is exploited. It can be either Local (L), Adjacent Network (A), Network (N), or Physical (P).</li> <li>Attack Complexity (AC): This metric describes the complexity of the attack required to exploit the vulnerability. It can be either Low (L), High (H).</li> <li>Privileges Required (PR): This metric describes the level of privileges required to exploit the vulnerability. It can be either None (N), Low (L), or High (H).</li> <li>User Interaction (UI): This metric describes whether user interaction is required to exploit the vulnerability. It can be either None (N), Required (R).</li> </ul>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#vulnerable-system-impact-metrics","title":"Vulnerable System Impact Metrics","text":"<ul> <li> <p>Confidentiality Impact (VC): This metric measures the impact on the confidentiality of the information managed by the vulnerable system due to a successful exploit of the vulnerability. It can be either Low (L), High (H), or None (N).</p> </li> <li> <p>Integrity Impact (VI): This metric measures the impact on the integrity of the information managed by the vulnerable system due to a successful exploit of the vulnerability. It can be either Low (L), High (H), or None (N).</p> </li> <li> <p>Availability Impact (VA): This metric measures the impact on the availability of the services of the vulnerable system due to a successful exploit of the vulnerability. It can be either Low (L), High (H), or None (N).</p> </li> </ul>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#subsequent-system-impact-metrics","title":"Subsequent System Impact Metrics","text":"<ul> <li>Confidentiality Impact (SC): This metric measures the impact to the confidentiality of the information managed by the Subsequent System due to a successful exploit of the vulnerability. It can be either Low (L), High (H), or None (N).</li> </ul>","tags":["CVSS"]},{"location":"blog/2024/09/17/security-score-system/#references","title":"References","text":"<ul> <li>Common Vulnerability Scoring System version 4.0: Specification Document</li> <li>CVSS Version 4.0 Calculator</li> <li>CVSS Version 4.0 User Guide</li> </ul>","tags":["CVSS"]},{"location":"blog/2024/04/18/azure-role-assignment-conditions/","title":"Azure role assignment conditions","text":"<p>First of all, let's understand what is ABAc (Attribute-Based Access Control) and how it can be used in Azure.</p>","tags":["Attribute-Based Access Control","Azure RBAC","Azure role assignment conditions"]},{"location":"blog/2024/04/18/azure-role-assignment-conditions/#what-is-abac","title":"What is ABAC?","text":"<p>Attribute-Based Access Control (ABAC) is an access control model that uses attributes to determine access rights. In ABAC, access decisions are based on the attributes of the user, the resource, and the environment. This allows for fine-grained access control based on a wide range of attributes, such as user roles, resource types, and time of day.</p> <p>ABAC is a flexible and scalable access control model that can be used to enforce complex access policies. It allows organizations to define access control rules based on a wide range of attributes and to adapt those rules as their needs change.</p> <p>ABAC is build on Azure RBAC.</p>","tags":["Attribute-Based Access Control","Azure RBAC","Azure role assignment conditions"]},{"location":"blog/2024/04/18/azure-role-assignment-conditions/#what-is-azure-role-assignment-conditions","title":"What is Azure role assignment conditions?","text":"<p>Azure role assignment conditions allow you to define conditions that must be met for a role assignment to be effective. </p>","tags":["Attribute-Based Access Control","Azure RBAC","Azure role assignment conditions"]},{"location":"blog/2024/04/18/azure-role-assignment-conditions/#how-to-configure-azure-role-assignment-conditions","title":"How to configure Azure role assignment conditions?","text":"<p>To configure Azure role assignment conditions, configure the role assignment as usual, and then click on the \"Conditions\" tab. Here you can define the conditions that must be met for the role assignment to be effective.</p> <p></p> <p>Options for configuring Conditions:</p> <ul> <li>Allow user to only assign selected roles to selected principals (fewer privileges)</li> <li>Allow user to assign all roles except privileged administrator roles Owner, UAA, RBAC (Recommended)</li> <li>Allow user to assign all roles (highly privileged)</li> </ul> <p>The first one is the most restrictive, for example, allowing the user to only assign selected roles to selected principals. This is useful when you want to limit the privileges of a user to only a subset of roles and principals.</p> <p>These are the options available for \"Allow user to only assign selected roles to selected principals (fewer privileges)\":</p> <p></p> <ul> <li>Constrain roles:<ul> <li>Allow user to only assign roles you select</li> </ul> </li> <li>Constrain roles and principal types:<ul> <li>Allow user to only assign roles you select</li> <li>Allow user to only assign these roles to principal types you select (users, groups, or service principals)</li> </ul> </li> <li>Constrain roles and principals<ul> <li>Allow user to only assign roles you select</li> <li>Allow user to only assign these roles to principals you select</li> <li>Allow all except specific roles</li> <li>Allow user to assign all roles except the roles you select</li> </ul> </li> </ul>","tags":["Attribute-Based Access Control","Azure RBAC","Azure role assignment conditions"]},{"location":"blog/2024/04/18/azure-role-assignment-conditions/#conclusion","title":"Conclusion","text":"<p>Azure role assignment conditions provide a flexible and powerful way to control access to Azure resources. By defining conditions that must be met for a role assignment to be effective, you can enforce fine-grained access control policies that meet the specific needs of your organization. This allows you to limit the privileges of users, assign roles to specific principals, and control access to sensitive resources. Azure role assignment conditions are a valuable tool for organizations that need to enforce strict access control policies and protect their critical resources.</p>","tags":["Attribute-Based Access Control","Azure RBAC","Azure role assignment conditions"]},{"location":"blog/2024/04/18/azure-role-assignment-conditions/#references","title":"References","text":"<ul> <li>What is Azure attribute-based access control (Azure ABAC)?</li> <li>Azure role assignment condition format and syntax</li> <li>Examples to delegate Azure role assignment management with conditions</li> </ul>","tags":["Attribute-Based Access Control","Azure RBAC","Azure role assignment conditions"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/","title":"Microsoft Defender for Storage","text":"<p>Microsoft Defender for Storage is part of the Microsoft Defender for Cloud suite of security solutions.</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#introduction","title":"Introduction","text":"<p>Microsoft Defender for Storage is a cloud-native security solution that provides advanced threat protection for your Azure Storage accounts. </p> <p>Microsoft Defender for Storage provides comprehensive security by analyzing the data plane and control plane telemetry generated by\u202fAzure Blob Storage,\u202fAzure Files, and\u202fAzure Data Lake Storage\u202fservices. It uses advanced threat detection capabilities powered by\u202fMicrosoft Threat Intelligence,\u202fMicrosoft Defender Antivirus, and Sensitive Data Discovery to help you discover and mitigate potential threats.</p> <p>Defender for Storage includes:</p> <ul> <li>Activity Monitoring</li> <li>Sensitive data threat detection (new plan only)</li> <li>Malware Scanning (new plan only)</li> </ul>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#how-it-works","title":"How it works","text":"<p>Microsoft Defender for Storage uses advanced threat detection capabilities powered by Microsoft Threat Intelligence, Microsoft Defender Antivirus, and Sensitive Data Discovery to help you discover and mitigate potential threats.</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#activity-monitoring","title":"Activity Monitoring","text":"<p>Activity Monitoring provides insights into the operations performed on your storage accounts. It helps you understand the access patterns and operations performed on your storage accounts, and provides insights into the data plane and control plane activities.</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#sensitive-data-threat-detection","title":"Sensitive data threat detection","text":"<p>Sensitive data threat detection helps you discover and protect sensitive data stored in your storage accounts. It uses advanced machine learning models to detect sensitive data patterns and provides recommendations to help you protect your sensitive data.</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#malware-scanning","title":"Malware Scanning","text":"<p>Malware Scanning helps you detect and mitigate malware threats in your storage accounts. It uses advanced threat detection capabilities powered by Microsoft Defender Antivirus to scan your storage accounts for malware threats and provides recommendations to help you mitigate these threats.</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#pricing","title":"Pricing","text":"<p>The pricing for Microsoft Defender for Storage is as follows:</p> Resource Type Resource Price Storage Microsoft Defender for Storage \u20ac9 per storage account/month6 Storage Malware Scanning (add-on to Defender for Storage) \u20ac0.135/GB of data scanned <p>For more information about pricing, see the Microsoft Defender for Cloud pricing.</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/20/microsoft-defender-for-storage/#conclusion","title":"Conclusion","text":"<p>Microsoft Defender for Storage is a cloud-native security solution that provides advanced threat protection for your Azure Storage accounts. It uses advanced threat detection capabilities powered by Microsoft Threat Intelligence, Microsoft Defender Antivirus, and Sensitive Data Discovery to help you discover and mitigate potential threats. </p> <p>For more information about Microsoft Defender for Storage, see the Overview of Microsoft Defender for Storage</p>","tags":["Microsoft Defender for Storage"]},{"location":"blog/2024/09/21/differences-between-b2b-direct-connect-and-b2b-collaboration-in-microsoft-entra/","title":"Differences between B2B Direct Connect and B2B Collaboration in Microsoft Entra","text":"<p>Microsoft Entra offers two ways to collaborate with external users: B2B Direct Connect and B2B Collaboration. Both features allow organizations to share resources with external users while maintaining control over access and security. However, they differ in functionality, access, and integration. Here is a comparison between B2B Direct Connect and B2B Collaboration:</p> Feature B2B Direct Connect B2B Collaboration Definition Mutual trust relationship between two Microsoft Entra organizations Invite external users to access resources using their own credentials Functionality Seamless collaboration using origin credentials and shared channels in Teams External users receive an invitation and access resources after authentication Applications Shared channels in Microsoft Teams Wide range of applications and services within the Microsoft ecosystem Access Single sign-on (SSO) with origin credentials Authentication each time resources are accessed, unless direct federation is set up Integration Deep and continuous integration between two organizations Flexible way to invite and manage external users <p>I hope this helps! </p>","tags":["External ID B2B","B2B","B2B Direct Connect","B2B Collaboration"]},{"location":"blog/2024/09/22/microsoft-entra-id-protection/","title":"Microsoft Entra ID Protection","text":"<p>Microsoft Entra offers a comprehensive set of security features to protect your organization's data and resources. One of these features is ID Protection, which helps you secure your users' identities and prevent unauthorized access to your organization's data. Here are some key benefits of using ID Protection in Microsoft Entra:</p> <ul> <li> <p>Multi-factor authentication (MFA): ID Protection enables you to enforce multi-factor authentication for all users in your organization. This adds an extra layer of security to your users' accounts and helps prevent unauthorized access.</p> </li> <li> <p>Conditional access policies: With ID Protection, you can create conditional access policies that define the conditions under which users can access your organization's resources. For example, you can require users to use multi-factor authentication when accessing sensitive data or restrict access to certain applications based on the user's location.</p> </li> <li> <p>Risk-based policies: ID Protection uses advanced machine learning algorithms to detect suspicious activities and risky sign-in attempts. You can create risk-based policies that automatically block or allow access based on the risk level associated with the sign-in attempt.</p> </li> <li> <p>Identity protection reports: ID Protection provides detailed reports and insights into your organization's identity security posture. You can use these reports to identify security risks, monitor user activity, and take proactive measures to protect your organization's data.</p> </li> </ul> <p>By using ID Protection in Microsoft Entra, you can enhance the security of your organization's data and resources and protect your users' identities from cyber threats. If you want to learn more about ID Protection and other security features in Microsoft Entra, contact us today! </p> <p>I hope this helps!</p>","tags":["ID Protection","Multi-factor authentication","Conditional access policies","Risk-based policies","Identity protection reports"]},{"location":"blog/2024/09/22/microsoft-entra-attribute-duplicate-attribute-resiliency/","title":"Microsoft Entra Attribute Duplicate Attribute Resiliency","text":"<p>Microsoft Entra Attribute Duplicate Attribute Resiliency feature is also being rolled out as the default behavior of Microsoft Entra ID. This will reduce the number of synchronization errors seen by Microsoft Entra Connect (as well as other sync clients) by making Microsoft Entra ID more resilient in the way it handles duplicated ProxyAddresses and UserPrincipalName attributes present in on premises AD environments. This feature does not fix the duplication errors. So the data still needs to be fixed. But it allows provisioning of new objects which are otherwise blocked from being provisioned due to duplicated values in Microsoft Entra ID. This will also reduce the number of synchronization errors returned to the synchronization client. If this feature is enabled for your Tenant, you will not see the InvalidSoftMatch synchronization errors seen during provisioning of new objects.</p>","tags":["Microsoft Entra Attribute Duplicate Attribute Resiliency","Microsoft Entra Connec"]},{"location":"blog/2024/09/22/microsoft-entra-attribute-duplicate-attribute-resiliency/#behavior-with-duplicate-attribute-resiliency","title":"Behavior with Duplicate Attribute Resiliency","text":"<pre><code>graph TD\n    A[Start] --&gt; B[Provision or Update Object]\n    B --&gt; C{Duplicate Attribute?}\n    C -- Yes --&gt; D[Quarantine Duplicate Attribute]\n    D --&gt; E{Is Attribute Required?}\n    E -- Yes --&gt; F[Assign Placeholder Value]\n    F --&gt; G[Send Error Report Email]\n    E -- No --&gt; H[Proceed with Object Creation/Update]\n    H --&gt; G\n    G --&gt; I[Export Succeeds]\n    I --&gt; J[Sync Client Does Not Log Error]\n    J --&gt; K[Sync Client Does Not Retry Operation]\n    K --&gt; L[Background Timer Task Every Hour]\n    L --&gt; M[Check for Resolved Conflicts]\n    M --&gt; N[Remove Attributes from Quarantine]\n    C -- No --&gt; H\n</code></pre>","tags":["Microsoft Entra Attribute Duplicate Attribute Resiliency","Microsoft Entra Connec"]},{"location":"blog/2024/10/03/terraform-import-block/","title":"terraform import block","text":"<p>Sometimes you need to import existing infrastructure into Terraform. This is useful when you have existing resources that you want to manage with Terraform, or when you want to migrate from another tool to Terraform.</p> <p>Other times, you may need to import resources that were created outside of Terraform, such as manually created resources or resources created by another tool. For example: </p> <p>\"Error: unexpected status 409 (409 Conflict) with error: RoleDefinitionWithSameNameExists: A custom role with the same name already exists in this directory. Use a different name\"</p> <p>In my case, I had to import a custom role that was created outside of Terraform. Here's how I did it:</p> <ol> <li>Create a new Terraform configuration file for the resource you want to import. In my case, I created a new file called <code>custom_role.tf</code> with the following content:</li> </ol> <pre><code>resource \"azurerm_role_definition\" \"custom_role\" {\n  name        = \"CustomRole\"\n  scope       = \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000\"\n  permissions {\n    actions     = [\n      \"Microsoft.Storage/storageAccounts/listKeys/action\",\n      \"Microsoft.Storage/storageAccounts/read\"\n    ]\n\n    data_actions = []\n\n    not_data_actions = []\n  }\n  assignable_scopes = [\n    \"/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000\"\n  ]\n}\n</code></pre> <ol> <li>Add a import block to the configuration file with the resource type and name you want to import. In my case, I added the following block to the <code>custom_role.tf</code> file:</li> </ol> <pre><code>import {\n  to = azurerm_role_definition.custom_role\n  id = \"/providers/Microsoft.Authorization/roleDefinitions/11111111-1111-1111-1111-111111111111|/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000\"\n\n}\n</code></pre> <ol> <li>Run the <code>terraform</code>plan` command to see the changes that Terraform will make to the resource. In my case, the output looked like this:</li> </ol> <pre><code>.\n.\n.\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  ~ update in-place\n.\n.\n.\n</code></pre> <ol> <li>Run the <code>terraform apply</code> command to import the resource into Terraform. In my case, the output looked like this after a long 9 minutes:</li> </ol> <pre><code>...\nApply complete! Resources: 1 imported, 0 added, 1 changed, 0 destroyed.\n</code></pre> <ol> <li>Verify that the resource was imported successfully by running the <code>terraform show</code> command. In my case, the output looked like this:</li> </ol> <pre><code>terraform show\n</code></pre> <p>You can use the <code>terraform import</code> command to import existing infrastructure into Terraform too but I prefer to use the <code>import</code> block because it's more readable and easier to manage.</p> <p>With terraform import the command would look like this:</p> <pre><code>terraform import azurerm_role_definition.custom_role \"/providers/Microsoft.Authorization/roleDefinitions/11111111-1111-1111-1111-111111111111|/providers/Microsoft.Management/managementGroups/00000000-0000-0000-0000-000000000000\"\n</code></pre>","tags":["terraform"]},{"location":"blog/2024/10/03/terraform-import-block/#conclusion","title":"Conclusion","text":"<p>That's it! You've successfully imported an existing resource into Terraform. Now you can manage it with Terraform just like any other resource.</p> <p>Happy coding! \ud83d\ude80</p>","tags":["terraform"]},{"location":"blog/2024/10/04/how-to-check-if-a-role-permission-is-good-or-bad-in-azure-rbac/","title":"How to check if a role permission is good or bad in Azure RBAC","text":"<p>Do you need to check if a role permission is good or bad or just don't know what actions a provider has in Azure RBAC?</p> <p>Get-AzProviderOperation * is your friend and you can always export everything to csv:</p> <pre><code>Get-AzProviderOperation | select Operation , OperationName , ProviderNamespace , ResourceName , Description , IsDataAction | Export-csv AzProviderOperation.csv\n</code></pre> <p>This command will give you a list of all the operations that you can perform on Azure resources, including the operation name, provider namespace, resource name, description, and whether it is a data action or not. You can use this information to check if a role permission is good or bad, or to find out what actions a provider has in Azure RBAC.</p>","tags":["Azure RBAC"]},{"location":"blog/2024/10/04/how-to-check-if-a-role-permission-is-good-or-bad-in-azure-rbac/#script-to-check-if-a-role-permission-is-good-or-bad-on-tf-files","title":"Script to check if a role permission is good or bad on tf files","text":"<p>You can use the following script to check if a role permission is good or bad on tf files:</p> <pre><code>&lt;#\n.SYNOPSIS\nScript to check if a role permission is good or bad in Azure RBAC using Terraform files.\n\n.DESCRIPTION\nThis script downloads Azure provider operations to a CSV file, reads the CSV file, extracts text from Terraform (.tf and .tfvars) files, and compares the extracted text with the CSV data to find mismatches.\n\n.PARAMETER csvFilePath\nThe path to the CSV file where Azure provider operations will be downloaded.\n\n.PARAMETER tfFolderPath\nThe path to the folder containing Terraform (.tf and .tfvars) files.\n\n.PARAMETER DebugMode\nSwitch to enable debug mode for detailed output.\n\n.EXAMPLE\n.\\Check-RBAC.ps1 -csvFilePath \".\\petete.csv\" -tfFolderPath \".\\\"\n\n.EXAMPLE\n.\\Check-RBAC.ps1 -csvFilePath \".\\petete.csv\" -tfFolderPath \".\\\" -DebugMode\n\n.NOTES\nFor more information, refer to the following resources:\n- Azure RBAC Documentation: https://docs.microsoft.com/en-us/azure/role-based-access-control/\n- Get-AzProviderOperation Cmdlet: https://docs.microsoft.com/en-us/powershell/module/az.resources/get-azprovideroperation\n- Export-Csv Cmdlet: https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/export-csv\n#&gt;\n\nparam(\n    [string]$csvFilePath = \".\\petete.csv\",\n    [string]$tfFolderPath = \".\\\",\n    [switch]$DebugMode\n)\n\n# Download petete.csv using Get-AzProviderOperation\nfunction Download-CSV {\n    param(\n        [string]$filename,\n        [switch]$DebugMode\n    )\n    if ($DebugMode) { Write-Host \"Downloading petete.csv using Get-AzProviderOperation\" }\n    Get-AzProviderOperation | select Operation, OperationName, ProviderNamespace, ResourceName, Description, IsDataAction | Export-Csv -Path $filename -NoTypeInformation\n    if ($DebugMode) { Write-Host \"CSV file downloaded: $filename\" }\n}\n\n# Function to read the CSV file\nfunction Read-CSV {\n    param(\n        [string]$filename,\n        [switch]$DebugMode\n    )\n    if ($DebugMode) { Write-Host \"Reading CSV file: $filename\" }\n    $csv = Import-Csv -Path $filename\n    $csvData = $csv | ForEach-Object {\n        [PSCustomObject]@{\n            Provider = $_.Operation.Split('/')[0].Trim()\n            Operation = $_.Operation\n            OperationName = $_.OperationName\n            ProviderNamespace = $_.ProviderNamespace\n            ResourceName = $_.ResourceName\n            Description = $_.Description\n            IsDataAction = $_.IsDataAction\n        }\n    }\n    if ($DebugMode) { Write-Host \"Data read from CSV:\"; $csvData | Format-Table -AutoSize }\n    return $csvData\n}\n\n# Function to extract text from the Terraform files\nfunction Extract-Text-From-TF {\n    param(\n        [string]$folderPath,\n        [switch]$DebugMode\n    )\n    if ($DebugMode) { Write-Host \"Reading TF and TFVARS files in folder: $folderPath\" }\n    $tfTexts = @()\n    $files = Get-ChildItem -Path $folderPath -Filter *.tf,*.tfvars\n    foreach ($file in $files) {\n        $content = Get-Content -Path $file.FullName\n        $tfTexts += $content | Select-String -Pattern '\"Microsoft\\.[^\"]*\"' -AllMatches | ForEach-Object { $_.Matches.Value.Trim('\"').Trim() }\n        $tfTexts += $content | Select-String -Pattern '\"\\*\"' -AllMatches | ForEach-Object { $_.Matches.Value.Trim('\"').Trim() }\n        $tfTexts += $content | Select-String -Pattern '^\\s*\\*/' -AllMatches | ForEach-Object { $_.Matches.Value.Trim() }\n    }\n    if ($DebugMode) { Write-Host \"Texts extracted from TF and TFVARS files:\"; $tfTexts | Format-Table -AutoSize }\n    return $tfTexts\n}\n\n# Function to compare extracted text with CSV data\nfunction Compare-Text-With-CSV {\n    param(\n        [array]$csvData,\n        [array]$tfTexts,\n        [switch]$DebugMode\n    )\n    $mismatches = @()\n    foreach ($tfText in $tfTexts) {\n        if ($tfText -eq \"*\" -or $tfText -match '^\\*/') {\n            continue\n        }\n        $tfTextPattern = $tfText -replace '\\*', '.*'\n        if (-not ($csvData | Where-Object { $_.Operation -match \"^$tfTextPattern$\" })) {\n            $mismatches += $tfText\n        }\n    }\n    if ($DebugMode) { Write-Host \"Mismatches found:\"; $mismatches | Format-Table -AutoSize }\n    return $mismatches\n}\n\n# Main script execution\nDownload-CSV -filename $csvFilePath -DebugMode:$DebugMode\n$csvData = Read-CSV -filename $csvFilePath -DebugMode:$DebugMode\n$tfTexts = Extract-Text-From-TF -folderPath $tfFolderPath -DebugMode:$DebugMode\n$mismatches = Compare-Text-With-CSV -csvData $csvData -tfTexts $tfTexts -DebugMode:$DebugMode\n\nif ($mismatches.Count -eq 0) {\n    Write-Host \"All extracted texts match the CSV data.\"\n} else {\n    Write-Host \"Mismatches found:\"\n    $mismatches | Format-Table -AutoSize\n}\n</code></pre> <p>This script downloads Azure provider operations to a CSV file, reads the CSV file, extracts text from Terraform files, and compares the extracted text with the CSV data to find mismatches. You can use this script to check if a role permission is good or bad in Azure RBAC using Terraform files.</p> <p>I hope this post has given you a good introduction to how you can check if a role permission is good or bad in Azure RBAC and how you can use Terraform files to automate this process. </p> <p>Happy coding! \ud83d\ude80</p>","tags":["Azure RBAC"]},{"location":"blog/2024/10/16/how-to-check-if-a-private-endpoint-is-connected-to-a-external-private-link-service-in-azure/","title":"How to check if a private endpoint is connected to a external private link service in Azure","text":"<p>Do you need to check if a private endpoint is connected to an external private link service in Azure or just don't know how to do it?</p> <p>Check this blog post to learn how to do it: Find cross-tenant private endpoint connections in Azure</p> <p>This is a copy of the script used in the blog post in case it disappears: </p> scan-private-endpoints-with-manual-connections.ps1<pre><code>$ErrorActionPreference = \"Stop\"\n\nclass SubscriptionInformation {\n    [string] $SubscriptionID\n    [string] $Name\n    [string] $TenantID\n}\n\nclass TenantInformation {\n    [string] $TenantID\n    [string] $DisplayName\n    [string] $DomainName\n}\n\nclass PrivateEndpointData {\n    [string] $ID\n    [string] $Name\n    [string] $Type\n    [string] $Location\n    [string] $ResourceGroup\n    [string] $SubscriptionName\n    [string] $SubscriptionID\n    [string] $TenantID\n    [string] $TenantDisplayName\n    [string] $TenantDomainName\n    [string] $TargetResourceId\n    [string] $TargetSubscriptionName\n    [string] $TargetSubscriptionID\n    [string] $TargetTenantID\n    [string] $TargetTenantDisplayName\n    [string] $TargetTenantDomainName\n    [string] $Description\n    [string] $Status\n    [string] $External\n}\n\n$installedModule = Get-Module -Name \"Az.ResourceGraph\" -ListAvailable\nif ($null -eq $installedModule) {\n    Install-Module \"Az.ResourceGraph\" -Scope CurrentUser\n}\nelse {\n    Import-Module \"Az.ResourceGraph\"\n}\n\n$kqlQuery = @\"\nresourcecontainers | where type == 'microsoft.resources/subscriptions'\n| project  subscriptionId, name, tenantId\n\"@\n\n$batchSize = 1000\n$skipResult = 0\n\n$subscriptions = @{}\n\nwhile ($true) {\n\n    if ($skipResult -gt 0) {\n        $graphResult = Search-AzGraph -Query $kqlQuery -First $batchSize -SkipToken $graphResult.SkipToken -UseTenantScope\n    }\n    else {\n        $graphResult = Search-AzGraph -Query $kqlQuery -First $batchSize -UseTenantScope\n    }\n\n    foreach ($row in $graphResult.data) {\n        $s = [SubscriptionInformation]::new()\n        $s.SubscriptionID = $row.subscriptionId\n        $s.Name = $row.name\n        $s.TenantID = $row.tenantId\n\n        $subscriptions.Add($s.SubscriptionID, $s) | Out-Null\n    }\n\n    if ($graphResult.data.Count -lt $batchSize) {\n        break;\n    }\n    $skipResult += $skipResult + $batchSize\n}\n\n\"Found $($subscriptions.Count) subscriptions\"\n\nfunction Get-SubscriptionInformation($SubscriptionID) {\n    if ($subscriptions.ContainsKey($SubscriptionID)) {\n        return $subscriptions[$SubscriptionID]\n    } \n\n    Write-Warning \"Using fallback subscription information for '$SubscriptionID'\"\n    $s = [SubscriptionInformation]::new()\n    $s.SubscriptionID = $SubscriptionID\n    $s.Name = \"&lt;unknown&gt;\"\n    $s.TenantID = [Guid]::Empty.Guid\n    return $s\n}\n\n$tenantCache = @{}\n$subscriptionToTenantCache = @{}\n\nfunction Get-TenantInformation($TenantID) {\n    $domain = $null\n    if ($tenantCache.ContainsKey($TenantID)) {\n        $domain = $tenantCache[$TenantID]\n    } \n    else {\n        try {\n            $tenantResponse = Invoke-AzRestMethod -Uri \"https://graph.microsoft.com/v1.0/tenantRelationships/findTenantInformationByTenantId(tenantId='$TenantID')\"\n            $tenantInformation = ($tenantResponse.Content | ConvertFrom-Json)\n\n            $ti = [TenantInformation]::new()\n            $ti.TenantID = $TenantID\n            $ti.DisplayName = $tenantInformation.displayName\n            $ti.DomainName = $tenantInformation.defaultDomainName\n\n            $domain = $ti\n        }\n        catch {\n            Write-Warning \"Failed to get domain information for '$TenantID'\"\n        }\n\n        if ([string]::IsNullOrEmpty($domain)) {\n            Write-Warning \"Using fallback domain information for '$TenantID'\"\n            $ti = [TenantInformation]::new()\n            $ti.TenantID = $TenantID\n            $ti.DisplayName = \"&lt;unknown&gt;\"\n            $ti.DomainName = \"&lt;unknown&gt;\"\n\n            $domain = $ti\n        }\n\n        $tenantCache.Add($TenantID, $domain) | Out-Null\n    }\n\n    return $domain\n}\n\nfunction Get-TenantFromSubscription($SubscriptionID) {\n    $tenant = $null\n    if ($subscriptionToTenantCache.ContainsKey($SubscriptionID)) {\n        $tenant = $subscriptionToTenantCache[$SubscriptionID]\n    }\n    elseif ($subscriptions.ContainsKey($SubscriptionID)) {\n        $tenant = $subscriptions[$SubscriptionID].TenantID\n        $subscriptionToTenantCache.Add($SubscriptionID, $tenant) | Out-Null\n    }\n    else {\n        try {\n\n            $subscriptionResponse = Invoke-AzRestMethod -Path \"/subscriptions/$($SubscriptionID)?api-version=2022-12-01\"\n            $startIndex = $subscriptionResponse.Headers.WwwAuthenticate.Parameter.IndexOf(\"https://login.windows.net/\")\n            $tenantID = $subscriptionResponse.Headers.WwwAuthenticate.Parameter.Substring($startIndex + \"https://login.windows.net/\".Length, 36)\n\n            $tenant = $tenantID\n        }\n        catch {\n            Write-Warning \"Failed to get tenant from subscription '$SubscriptionID'\"\n        }\n\n        if ([string]::IsNullOrEmpty($tenant)) {\n            Write-Warning \"Using fallback tenant information for '$SubscriptionID'\"\n\n            $tenant = [Guid]::Empty.Guid\n        }\n\n        $subscriptionToTenantCache.Add($SubscriptionID, $tenant) | Out-Null\n    }\n\n    return $tenant\n}\n\n$kqlQuery = @\"\nresources\n| where type == \"microsoft.network/privateendpoints\"\n| where isnotnull(properties) and properties contains \"manualPrivateLinkServiceConnections\"\n| where array_length(properties.manualPrivateLinkServiceConnections) &gt; 0\n| mv-expand properties.manualPrivateLinkServiceConnections\n| extend status = properties_manualPrivateLinkServiceConnections.properties.privateLinkServiceConnectionState.status\n| extend description = coalesce(properties_manualPrivateLinkServiceConnections.properties.privateLinkServiceConnectionState.description, \"\")\n| extend privateLinkServiceId = properties_manualPrivateLinkServiceConnections.properties.privateLinkServiceId\n| extend privateLinkServiceSubscriptionId = tostring(split(privateLinkServiceId, \"/\")[2])\n| project id, name, location, type, resourceGroup, subscriptionId, tenantId, privateLinkServiceId, privateLinkServiceSubscriptionId, status, description\n\"@\n\n$batchSize = 1000\n$skipResult = 0\n\n$privateEndpoints = New-Object System.Collections.ArrayList\n\nwhile ($true) {\n\n    if ($skipResult -gt 0) {\n        $graphResult = Search-AzGraph -Query $kqlQuery -First $batchSize -SkipToken $graphResult.SkipToken -UseTenantScope\n    }\n    else {\n        $graphResult = Search-AzGraph -Query $kqlQuery -First $batchSize -UseTenantScope\n    }\n\n    foreach ($row in $graphResult.data) {\n\n        $si1 = Get-SubscriptionInformation -SubscriptionID $row.SubscriptionID\n        $ti1 = Get-TenantInformation -TenantID $row.TenantID\n\n        $si2 = Get-SubscriptionInformation -SubscriptionID $row.PrivateLinkServiceSubscriptionId\n        $tenant2 = Get-TenantFromSubscription -SubscriptionID $si2.SubscriptionID\n        $ti2 = Get-TenantInformation -TenantID $tenant2\n\n        $peData = [PrivateEndpointData]::new()\n        $peData.ID = $row.ID\n        $peData.Name = $row.Name\n        $peData.Type = $row.Type\n        $peData.Location = $row.Location\n        $peData.ResourceGroup = $row.ResourceGroup\n\n        $peData.SubscriptionName = $si1.Name\n        $peData.SubscriptionID = $si1.SubscriptionID\n        $peData.TenantID = $ti1.TenantID\n        $peData.TenantDisplayName = $ti1.DisplayName\n        $peData.TenantDomainName = $ti1.DomainName\n\n        $peData.TargetResourceId = $row.PrivateLinkServiceId\n        $peData.TargetSubscriptionName = $si2.Name\n        $peData.TargetSubscriptionID = $si2.SubscriptionID\n        $peData.TargetTenantID = $ti2.TenantID\n        $peData.TargetTenantDisplayName = $ti2.DisplayName\n        $peData.TargetTenantDomainName = $ti2.DomainName\n\n        $peData.Description = $row.Description\n        $peData.Status = $row.Status\n\n        if ($ti2.DomainName -eq \"MSAzureCloud.onmicrosoft.com\") {\n            $peData.External = \"Managed by Microsoft\"\n        }\n        elseif ($si2.TenantID -eq [Guid]::Empty.Guid) {\n            $peData.External = \"Yes\"\n        }\n        else {\n            $peData.External = \"No\"\n        }\n\n        $privateEndpoints.Add($peData) | Out-Null\n    }\n\n    if ($graphResult.data.Count -lt $batchSize) {\n        break;\n    }\n    $skipResult += $skipResult + $batchSize\n}\n\n$privateEndpoints | Format-Table\n$privateEndpoints | Export-CSV \"private-endpoints.csv\" -Delimiter ';' -Force\n\n\"Found $($privateEndpoints.Count) private endpoints with manual connections\"\n\nif ($privateEndpoints.Count -ne 0) {\n    Start-Process \"private-endpoints.csv\"\n}\n</code></pre>","tags":["Azure Private Link"]},{"location":"blog/2024/10/16/how-to-check-if-a-private-endpoint-is-connected-to-a-external-private-link-service-in-azure/#conclusion","title":"Conclusion","text":"<p>Now you know how to check if a private endpoint is connected to an external private link service in Azure.</p> <p>That's all folks!</p>","tags":["Azure Private Link"]},{"location":"blog/2024/11/05/custom-azure-policy-for-kubernetes/","title":"Custom Azure Policy for Kubernetes","text":"<p>Azure Policy is a service in Azure that you can use to create, assign, and manage policies that enforce different rules and effects over your resources. These policies can help you stay compliant with your corporate standards and service-level agreements. In this article, we will discuss how to create a custom Azure Policy for Kubernetes.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/05/custom-azure-policy-for-kubernetes/#how-azure-policy-works-in-kubernetes","title":"How Azure Policy works in kubernetes","text":"<p>Azure Policy for Kubernetes is an extension of Azure Policy that allows you to enforce policies on your Kubernetes clusters. You can use Azure Policy to define policies that apply to your Kubernetes resources, such as pods, deployments, and services. These policies can help you ensure that your Kubernetes clusters are compliant with your organization's standards and best practices.</p> <p>Azure Policy for Kubernetes uses Gatekeeper, an open-source policy controller for Kubernetes, to enforce policies on your clusters. Gatekeeper uses the Open Policy Agent (OPA) policy language to define policies and evaluate them against your Kubernetes resources. You can use Gatekeeper to create custom policies that enforce specific rules and effects on your clusters.</p> <pre><code>graph TD\n    A[Azure Policy] --&gt;|Enforce policies| B[\"add-on azure-policy(Gatekeeper)\"]\n    B --&gt;|Evaluate policies| C[Kubernetes resources]\n</code></pre> <p>Azure Policy for Kubernetes supports the following cluster environments:</p> <ul> <li>Azure Kubernetes Service (AKS), through Azure Policy's Add-on for AKS</li> <li>Azure Arc enabled Kubernetes, through Azure Policy's Extension for Arc</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/11/05/custom-azure-policy-for-kubernetes/#prepare-your-environment","title":"Prepare your environment","text":"<p>Before you can create custom Azure Policy for Kubernetes, you need to set up your environment. You will need an Azure Kubernetes Service (AKS) cluster with the Azure Policy add-on enabled. You will also need the Azure CLI and the Azure Policy extension for Visual Studio Code.</p> <p>To set up your environment, follow these steps:</p> <ol> <li> <p>Create a resource group</p> <pre><code>az group create --name myResourceGroup --location spaincentral\n</code></pre> </li> <li> <p>Create an Azure Kubernetes Service (AKS) cluster with default settings and one node:</p> <pre><code>az aks create --resource-group myResourceGroup --name myAKSCluster --node-count 1\n</code></pre> </li> <li> <p>Enable Azure Policies for the cluster:</p> <pre><code>az aks enable-addons --resource-group myResourceGroup --name myAKSCluster --addons azure-policy\n</code></pre> </li> <li> <p>Check the status of the add-on:</p> <pre><code>az aks show --resource-group myResourceGroup --name myAKSCluster --query addonProfiles.azurepolicy.enabled\n</code></pre> </li> <li> <p>Check the status of gatekeeper:</p> <pre><code># Install kubectl and kubelogin\naz aks install-cli --install-location .local/bin/kubectl --kubelogin-install-location .local/bin/kubelogin\n# Get the credentials for the AKS cluster\naz aks get-credentials --resource-group myResourceGroup --name myAKSCluster --overwrite-existing\n# azure-policy pod is installed in kube-system namespace\nkubectl get pods -n kube-system\n# gatekeeper pod is installed in gatekeeper-system namespace\nkubectl get pods -n gatekeeper-system\n</code></pre> </li> <li> <p>Install vscode and the Azure Policy extension</p> <pre><code>code --install-extension ms-azuretools.vscode-azurepolicy\n</code></pre> </li> </ol> <p>Once you have set up your environment, you can create custom Azure Policy for Kubernetes.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/05/custom-azure-policy-for-kubernetes/#how-to-create-a-custom-azure-policy-for-kubernetes","title":"How to create a custom Azure Policy for Kubernetes","text":"<p>To create a custom Azure Policy for Kubernetes, you need to define a policy in the Open Policy Agent (OPA) policy language and apply it to your Kubernetes cluster. You can define policies that enforce specific rules and effects on your Kubernetes resources, such as pods, deployments, and services.</p> <p>Info</p> <p>It`s recommended to review Constraint Templates in How to use Gatekeeper</p> <p>To create a custom Azure Policy for Kubernetes, follow these steps:</p> <ol> <li> <p>Define a constraint template for the policy, I will use an existing constraint template from the Gatekeeper library that requires Ingress resources to be HTTPS only:</p> gatekeeper-library/library/general/httpsonly/template.yaml<pre><code>apiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n    name: k8shttpsonly\n    annotations:\n        metadata.gatekeeper.sh/title: \"HTTPS Only\"\n        metadata.gatekeeper.sh/version: 1.0.2\n        description: &gt;-\n        Requires Ingress resources to be HTTPS only.  Ingress resources must\n        include the `kubernetes.io/ingress.allow-http` annotation, set to `false`.\n        By default a valid TLS {} configuration is required, this can be made\n        optional by setting the `tlsOptional` parameter to `true`.\n\n        https://kubernetes.io/docs/concepts/services-networking/ingress/#tls\nspec:\ncrd:\n    spec:\n    names:\n        kind: K8sHttpsOnly\n    validation:\n        # Schema for the `parameters` field\n        openAPIV3Schema:\n        type: object\n        description: &gt;-\n            Requires Ingress resources to be HTTPS only.  Ingress resources must\n            include the `kubernetes.io/ingress.allow-http` annotation, set to\n            `false`. By default a valid TLS {} configuration is required, this\n            can be made optional by setting the `tlsOptional` parameter to\n            `true`.\n        properties:\n            tlsOptional:\n            type: boolean\n            description: \"When set to `true` the TLS {} is optional, defaults \n            to false.\"\ntargets:\n    - target: admission.k8s.gatekeeper.sh\n    rego: |\n        package k8shttpsonly\n\n        violation[{\"msg\": msg}] {\n        input.review.object.kind == \"Ingress\"\n        regex.match(\"^(extensions|networking.k8s.io)/\", input.review.object.apiVersion)\n        ingress := input.review.object\n        not https_complete(ingress)\n        not tls_is_optional\n        msg := sprintf(\"Ingress should be https. tls configuration and allow-http=false annotation are required for %v\", [ingress.metadata.name])\n        }\n\n        violation[{\"msg\": msg}] {\n        input.review.object.kind == \"Ingress\"\n        regex.match(\"^(extensions|networking.k8s.io)/\", input.review.object.apiVersion)\n        ingress := input.review.object\n        not annotation_complete(ingress)\n        tls_is_optional\n        msg := sprintf(\"Ingress should be https. The allow-http=false annotation is required for %v\", [ingress.metadata.name])\n        }\n\n        https_complete(ingress) = true {\n        ingress.spec[\"tls\"]\n        count(ingress.spec.tls) &gt; 0\n        ingress.metadata.annotations[\"kubernetes.io/ingress.allow-http\"] == \"false\"\n        }\n\n        annotation_complete(ingress) = true {\n        ingress.metadata.annotations[\"kubernetes.io/ingress.allow-http\"] == \"false\"\n        }\n\n        tls_is_optional {\n        parameters := object.get(input, \"parameters\", {})\n        object.get(parameters, \"tlsOptional\", false) == true\n        }\n</code></pre> </li> </ol> <p>This constrains requires Ingress resources to be HTTPS only</p> <ol> <li> <p>Create an Azure Policy for this constraint template</p> <ol> <li>Open the restriction template created earlier in Visual Studio Code.</li> <li>Click on Azure Policy icon in the Activity Bar.</li> <li>Click on View &gt; Command Palette.</li> <li>Search for the command \"Azure Policy for Kubernetes: Create Policy Definition from Constraint Template or Mutation\", select base64, this command will create a policy definition from the constraint template. Untitled.json<pre><code>{\n\"properties\": {\n    \"policyType\": \"Custom\",\n    \"mode\": \"Microsoft.Kubernetes.Data\",\n    \"displayName\": \"/* EDIT HERE */\",\n    \"description\": \"/* EDIT HERE */\",\n    \"policyRule\": {\n    \"if\": {\n        \"field\": \"type\",\n        \"in\": [\n        \"Microsoft.ContainerService/managedClusters\"\n        ]\n    },\n    \"then\": {\n        \"effect\": \"[parameters('effect')]\",\n        \"details\": {\n        \"templateInfo\": {\n            \"sourceType\": \"Base64Encoded\",\n            \"content\": \"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\"\n        },\n        \"apiGroups\": [\n            \"/* EDIT HERE */\"\n        ],\n        \"kinds\": [\n            \"/* EDIT HERE */\"\n        ],\n        \"namespaces\": \"[parameters('namespaces')]\",\n        \"excludedNamespaces\": \"[parameters('excludedNamespaces')]\",\n        \"labelSelector\": \"[parameters('labelSelector')]\",\n        \"values\": {\n            \"tlsOptional\": \"[parameters('tlsOptional')]\"\n        }\n        }\n    }\n    },\n    \"parameters\": {\n    \"effect\": {\n        \"type\": \"String\",\n        \"metadata\": {\n        \"displayName\": \"Effect\",\n        \"description\": \"'audit' allows a non-compliant resource to be created or updated, but flags it as non-compliant. 'deny' blocks the non-compliant resource creation or update. 'disabled' turns off the policy.\"\n        },\n        \"allowedValues\": [\n        \"audit\",\n        \"deny\",\n        \"disabled\"\n        ],\n        \"defaultValue\": \"audit\"\n    },\n    \"excludedNamespaces\": {\n        \"type\": \"Array\",\n        \"metadata\": {\n        \"displayName\": \"Namespace exclusions\",\n        \"description\": \"List of Kubernetes namespaces to exclude from policy evaluation.\"\n        },\n        \"defaultValue\": [\n        \"kube-system\",\n        \"gatekeeper-system\",\n        \"azure-arc\"\n        ]\n    },\n    \"namespaces\": {\n        \"type\": \"Array\",\n        \"metadata\": {\n        \"displayName\": \"Namespace inclusions\",\n        \"description\": \"List of Kubernetes namespaces to only include in policy evaluation. An empty list means the policy is applied to all resources in all namespaces.\"\n        },\n        \"defaultValue\": []\n    },\n    \"labelSelector\": {\n        \"type\": \"Object\",\n        \"metadata\": {\n        \"displayName\": \"Kubernetes label selector\",\n        \"description\": \"Label query to select Kubernetes resources for policy evaluation. An empty label selector matches all Kubernetes resources.\"\n        },\n        \"defaultValue\": {},\n        \"schema\": {\n        \"description\": \"A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all resources.\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"matchLabels\": {\n            \"description\": \"matchLabels is a map of {key,value} pairs.\",\n            \"type\": \"object\",\n            \"additionalProperties\": {\n                \"type\": \"string\"\n            },\n            \"minProperties\": 1\n            },\n            \"matchExpressions\": {\n            \"description\": \"matchExpressions is a list of values, a key, and an operator.\",\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                \"key\": {\n                    \"description\": \"key is the label key that the selector applies to.\",\n                    \"type\": \"string\"\n                },\n                \"operator\": {\n                    \"description\": \"operator represents a key's relationship to a set of values.\",\n                    \"type\": \"string\",\n                    \"enum\": [\n                    \"In\",\n                    \"NotIn\",\n                    \"Exists\",\n                    \"DoesNotExist\"\n                    ]\n                },\n                \"values\": {\n                    \"description\": \"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty.\",\n                    \"type\": \"array\",\n                    \"items\": {\n                    \"type\": \"string\"\n                    }\n                }\n                },\n                \"required\": [\n                \"key\",\n                \"operator\"\n                ],\n                \"additionalProperties\": false\n            },\n            \"minItems\": 1\n            }\n        },\n        \"additionalProperties\": false\n        }\n    },\n    \"tlsOptional\": {\n        \"type\": \"Boolean\",\n        \"metadata\": {\n        \"displayName\": \"/* EDIT HERE */\",\n        \"description\": \"/* EDIT HERE */\"\n        }\n    }\n    }\n}\n}\n</code></pre></li> <li>Fill the fields with \"/ EDIT HERE /\" in the policy definition JSON file with the appropriate values, such as the display name, description, API groups, and kinds. For example, in this case you must configure apiGroups:  [\"extensions\", \"networking.k8s.io\"] and kinds: [\"Ingress\"]</li> <li>Save the policy definition JSON file.</li> </ol> </li> </ol> <p>This is the complete policy:</p> <p><code>json title=\"https-only.json\"     {     \"properties\": {         \"policyType\": \"Custom\",         \"mode\": \"Microsoft.Kubernetes.Data\",         \"displayName\": \"Require HTTPS for Ingress resources\",         \"description\": \"This policy requires Ingress resources to be HTTPS only. Ingress resources must include the `kubernetes.io/ingress.allow-http` annotation, set to `false`. By default a valid TLS configuration is required, this can be made optional by setting the `tlsOptional` parameter to `true`.\",         \"policyRule\": {         \"if\": {             \"field\": \"type\",             \"in\": [             \"Microsoft.ContainerService/managedClusters\"             ]         },         \"then\": {             \"effect\": \"[parameters('effect')]\",             \"details\": {             \"templateInfo\": {                 \"sourceType\": \"Base64Encoded\",                 \"content\": \"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\"             },             \"apiGroups\": [                 \"extensions\",                 \"networking.k8s.io\"             ],             \"kinds\": [                 \"Ingress\"             ],             \"namespaces\": \"[parameters('namespaces')]\",             \"excludedNamespaces\": \"[parameters('excludedNamespaces')]\",             \"labelSelector\": \"[parameters('labelSelector')]\",             \"values\": {                 \"tlsOptional\": \"[parameters('tlsOptional')]\"             }             }         }         },         \"parameters\": {         \"effect\": {             \"type\": \"String\",             \"metadata\": {             \"displayName\": \"Effect\",             \"description\": \"'audit' allows a non-compliant resource to be created or updated, but flags it as non-compliant. 'deny' blocks the non-compliant resource creation or update. 'disabled' turns off the policy.\"             },             \"allowedValues\": [             \"audit\",             \"deny\",             \"disabled\"             ],             \"defaultValue\": \"audit\"         },         \"excludedNamespaces\": {             \"type\": \"Array\",             \"metadata\": {             \"displayName\": \"Namespace exclusions\",             \"description\": \"List of Kubernetes namespaces to exclude from policy evaluation.\"             },             \"defaultValue\": [             \"kube-system\",             \"gatekeeper-system\",             \"azure-arc\"             ]         },         \"namespaces\": {             \"type\": \"Array\",             \"metadata\": {             \"displayName\": \"Namespace inclusions\",             \"description\": \"List of Kubernetes namespaces to only include in policy evaluation. An empty list means the policy is applied to all resources in all namespaces.\"             },             \"defaultValue\": []         },         \"labelSelector\": {             \"type\": \"Object\",             \"metadata\": {             \"displayName\": \"Kubernetes label selector\",             \"description\": \"Label query to select Kubernetes resources for policy evaluation. An empty label selector matches all Kubernetes resources.\"             },             \"defaultValue\": {},             \"schema\": {             \"description\": \"A label selector is a label query over a set of resources. The result of matchLabels and matchExpressions are ANDed. An empty label selector matches all resources.\",             \"type\": \"object\",             \"properties\": {                 \"matchLabels\": {                 \"description\": \"matchLabels is a map of {key,value} pairs.\",                 \"type\": \"object\",                 \"additionalProperties\": {                     \"type\": \"string\"                 },                 \"minProperties\": 1                 },                 \"matchExpressions\": {                 \"description\": \"matchExpressions is a list of values, a key, and an operator.\",                 \"type\": \"array\",                 \"items\": {                     \"type\": \"object\",                     \"properties\": {                     \"key\": {                         \"description\": \"key is the label key that the selector applies to.\",                         \"type\": \"string\"                     },                     \"operator\": {                         \"description\": \"operator represents a key's relationship to a set of values.\",                         \"type\": \"string\",                         \"enum\": [                         \"In\",                         \"NotIn\",                         \"Exists\",                         \"DoesNotExist\"                         ]                     },                     \"values\": {                         \"description\": \"values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty.\",                         \"type\": \"array\",                         \"items\": {                         \"type\": \"string\"                         }                     }                     },                     \"required\": [                     \"key\",                     \"operator\"                     ],                     \"additionalProperties\": false                 },                 \"minItems\": 1                 }             },             \"additionalProperties\": false             }         },         \"tlsOptional\": {             \"type\": \"Boolean\",             \"metadata\": {             \"displayName\": \"TLS Optional\",             \"description\": \"Set to true to make TLS optional\"             }         }         }     }     }</code></p> <p>Now you have created a custom Azure Policy for Kubernetes that enforces the HTTPS only constraint on your Kubernetes cluster. You can apply this policy to your cluster to ensure that all Ingress resources are HTTPS only creating a policy definition and assigning it to the management group, subscription or resource group where the AKS cluster is located.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/05/custom-azure-policy-for-kubernetes/#conclusion","title":"Conclusion","text":"<p>In this article, we discussed how to create a custom Azure Policy for Kubernetes. We showed you how to define a policy in the Open Policy Agent (OPA) policy language and apply it to your Kubernetes cluster. We also showed you how to create a constraint template for the policy and create an Azure Policy for the constraint template. By following these steps, you can create custom policies that enforce specific rules and effects on your Kubernetes resources.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/05/custom-azure-policy-for-kubernetes/#references","title":"References","text":"<ul> <li>Understand Azure Policy for kubernetes clusters</li> <li>Gatekeeper Library</li> <li>Azure Policy extension for Visual Studio Code</li> <li>How to use Gatekeeper</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/11/06/trigger-an-on-demand-azure-policy-compliance-evaluation-scan/","title":"Trigger an on-demand Azure Policy compliance evaluation scan","text":"<p>Azure Policy is a service in Azure that you can use to create, assign, and manage policies that enforce different rules and effects over your resources. These policies can help you stay compliant with your corporate standards and service-level agreements. In this article, we will discuss how to trigger a scan with Azure Policy.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/06/trigger-an-on-demand-azure-policy-compliance-evaluation-scan/#what-is-a-scan-in-azure-policy","title":"What is a scan in Azure Policy","text":"<p>A scan in Azure Policy is a process that evaluates your resources against a set of policies to determine if they are compliant. When you trigger a scan, Azure Policy evaluates your resources and generates a compliance report that shows the results of the evaluation. The compliance report includes information about the policies that were evaluated, the resources that were scanned, and the compliance status of each resource.</p> <p>You can trigger a scan in Azure Policy using the Azure CLI, PowerShell, or the Azure portal. When you trigger a scan, you can specify the scope of the scan, the policies to evaluate, and other parameters that control the behavior of the scan.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/06/trigger-an-on-demand-azure-policy-compliance-evaluation-scan/#trigger-a-scan-with-the-azure-cli","title":"Trigger a scan with the Azure CLI","text":"<p>To trigger a scan with the Azure CLI, you can use the <code>az policy state trigger-scan</code> command. This command triggers a policy compliance evaluation for a scope</p> <p>How to trigger a scan with the Azure CLI for active subscription:</p> <pre><code>az policy state trigger-scan \n</code></pre> <p>How to trigger a scan with the Azure CLI for a specific resource group:</p> <pre><code>az policy state trigger-scan --resource-group myResourceGroup\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/06/trigger-an-on-demand-azure-policy-compliance-evaluation-scan/#trigger-a-scan-with-powershell","title":"Trigger a scan with PowerShell","text":"<p>To trigger a scan with PowerShell, you can use the <code>Start-AzPolicyComplianceScan</code> cmdlet. This cmdlet triggers a policy compliance evaluation for a scope.</p> <p>How to trigger a scan with PowerShell for active subscription:</p> <pre><code>Start-AzPolicyComplianceScan\n</code></pre> <pre><code>$job = Start-AzPolicyComplianceScan -AsJob\n</code></pre> <p>How to trigger a scan with PowerShell for a specific resource group:</p> <pre><code>Start-AzPolicyComplianceScan -ResourceGroupName 'MyRG'\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/06/trigger-an-on-demand-azure-policy-compliance-evaluation-scan/#conclusion","title":"Conclusion","text":"<p>In this article, we discussed how to trigger a scan with Azure Policy. We covered how to trigger a scan using the Azure CLI and PowerShell. By triggering a scan, you can evaluate your resources against a set of policies to determine if they are compliant. This can help you ensure that your resources are compliant with your organization's standards and best practices.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/06/trigger-an-on-demand-azure-policy-compliance-evaluation-scan/#references","title":"References","text":"<ul> <li>On-demand evaluation scan </li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/","title":"How to create a local environment to write policies for Kubernetes with minikube and gatekeeper","text":"","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#minikube-in-wsl2","title":"minikube in wsl2","text":"","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#enable-systemd-in-wsl2","title":"Enable systemd in WSL2","text":"<pre><code>sudo nano /etc/wsl.conf\n</code></pre> <p>Add the following:</p> <pre><code>[boot]\nsystemd=true\n</code></pre> <p>Restart WSL2 in command:</p> <pre><code>wsl --shutdown\nwsl\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#install-docker","title":"Install docker","text":"<p>Install docker using repository</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#minikube","title":"Minikube","text":"","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#install-minikube","title":"Install minikube","text":"<pre><code># Download the latest Minikube\ncurl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\n\n# Make it executable\nchmod +x ./minikube\n\n# Move it to your user's executable PATH\nsudo mv ./minikube /usr/local/bin/\n\n#Set the driver version to Docker\nminikube config set driver docker\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#test-minikube","title":"Test minikube","text":"<pre><code># Enable completion\nsource &lt;(minikube completion bash)\n# Start minikube\nminikube start\n# Check the status\nminikube status\n# set context\nkubectl config use-context minikube\n# get pods\nkubectl get pods --all-namespaces\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#install-opa-gatekeeper","title":"Install OPA Gatekeeper","text":"<pre><code># Install OPA Gatekeeper\n# check version in https://open-policy-agent.github.io/gatekeeper/website/docs/install#deploying-a-release-using-prebuilt-image\nkubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/v3.17.1/deploy/gatekeeper.yaml\n\n# wait and check the status\nsleep 60\nkubectl get pods -n gatekeeper-system\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#test-constraints","title":"Test constraints","text":"<p>First, we need to create a constraint template and a constraint.</p> <pre><code># Create a constraint template\nkubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/v3.17.1/demo/basic/templates/k8srequiredlabels_template.yaml\n\n# Create a constraint\nkubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/v3.17.1/demo/basic/constraints/k8srequiredlabels_constraint.yaml\n</code></pre> <p>Now, we can test the constraint.</p> <p><pre><code># Create a deployment without the required label\nkubectl create namespace petete \n</code></pre> We must see an error message like this:</p> <pre><code>Error from server (Forbidden): admission webhook \"validation.gatekeeper.sh\" denied the request: [ns-must-have-gk] you must provide labels: {\"gatekeeper\"}\n</code></pre> <p><pre><code># Create a deployment with the required label\ncat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: petete\n  labels:\n    gatekeeper: \"true\"\nEOF\nkubectl get namespaces petete\n</code></pre> We must see a message like this:</p> <pre><code>NAME     STATUS   AGE\npetete   Active   3s\n</code></pre>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#conclusion","title":"Conclusion","text":"<p>We have created a local environment to write policies for Kubernetes with minikube and gatekeeper. We have tested the environment with a simple constraint. Now we can write our own policies and test them in our local environment.</p>","tags":["Azure Policy"]},{"location":"blog/2024/11/19/how-to-create-a-local-environment-to-write-policies-for-kubernetes-with-minikube-and-gatekeeper/#references","title":"References","text":"<ul> <li>Minikube</li> <li>OPA Gatekeeper</li> <li>How to use Gatekeeper</li> <li>WSL2</li> <li>Docker</li> </ul>","tags":["Azure Policy"]},{"location":"blog/2024/11/20/develop-my-firts-policy-for-kubernetes-with-minikube-and-gatekeeper/","title":"Develop my firts policy for Kubernetes with minikube and gatekeeper","text":"<p>Now that we have our development environment, we can start developing our first policy for Kubernetes with minikube and gatekeeper.</p> <p>First at all, we need some visual code editor to write our policy. I recommend using Visual Studio Code, but you can use any other editor. Exists a plugin for Visual Studio Code that helps you to write policies for gatekeeper. You can install it from the marketplace: Open Policy Agent.</p> <p>Once you have your editor ready, you can start writing your policy. In this example, we will create a policy that denies the creation of pods with the image <code>nginx:latest</code>.</p> <p>For that we need two files:</p> <ul> <li><code>constraint.yaml</code>: This file defines the constraint that we want to apply.</li> <li><code>constraint_template.yaml</code>: This file defines the template that we will use to create the constraint.</li> </ul> <p>Let's start with the <code>constraint_template.yaml</code> file:</p> constraint_template.yaml<pre><code>apiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: k8sdenypodswithnginxlatest\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sDenyPodsWithNginxLatest\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8sdenypodswithnginxlatest\n\n        violation[{\"msg\": msg}] {\n          input.review.object.spec.containers[_].image == \"nginx:latest\"\n          msg := \"Containers cannot use the nginx:latest image\"\n        }\n</code></pre> <p>Now, let's create the <code>constraint.yaml</code> file:</p> constraint.yaml<pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sDenyPodsWithNginxLatest\nmetadata:\n  name: deny-pods-with-nginx-latest\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n  parameters:\n    msg: \"Containers cannot use the nginx:latest image\"\n</code></pre> <p>Now, we can apply the files to our cluster:</p> <pre><code># Create the constraint template\nkubectl apply -f constraint_template.yaml\n\n# Create the constraint\nkubectl apply -f constraint.yaml\n</code></pre> <p>Now, we can test the constraint. Let's create a pod with the image <code>nginx:latest</code>:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx:latest\nEOF\n</code></pre> <p>We must see an error message like this:</p> <pre><code>Error from server (Forbidden): error when creating \"STDIN\": admission webhook \"validation.gatekeeper.sh\" denied the request: [k8sdenypodswithnginxlatest] Containers cannot use the nginx:latest image\n</code></pre> <p>Now, let's create a pod with a different image:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.25.5\nEOF\n</code></pre> <p>We must see a message like this:</p> <pre><code>pod/nginx-pod created\n</code></pre> <p>For cleaning up, you can delete pod,the constraint and the constraint template:</p> <pre><code># Delete the pod\nkubectl delete pod nginx-pod\n# Delete the constraint\nkubectl delete -f constraint.yaml\n\n# Delete the constraint template\nkubectl delete -f constraint_template.yaml\n</code></pre> <p>And that's it! We have developed our first policy for Kubernetes with minikube and gatekeeper. Now you can start developing more complex policies and test them in your cluster.</p> <p>Happy coding!</p>","tags":["Azure Policy"]},{"location":"blog/2024/12/12/ejecutar-terraform-con-archivos-de-variables/","title":"Ejecutar Terraform con archivos de variables","text":"<p>Script para ejecutar Terraform con archivos de variables:</p> terraform_with_var_files.sh<pre><code>function terraform_with_var_files() {\n  local dir=\"$1\"\n  local action=\"$2\"\n  local auto=\"$3\"\n\n  if [[ ! -d \"$dir\" ]]; then\n    echo \"El directorio especificado no existe.\"\n    return 1\n  fi\n\n  if [[ \"$action\" != \"plan\" &amp;&amp; \"$action\" != \"apply\" &amp;&amp; \"$action\" != \"destroy\" ]]; then\n    echo \"Acci\u00f3n no v\u00e1lida. Usa 'plan', 'apply' o 'destroy'.\"\n    return 1\n  fi\n\n  local var_files=()\n  for file in \"$dir\"/*.tfvars; do\n    if [[ -f \"$file\" ]]; then\n      var_files+=(\"--var-file $file\")\n    fi\n  done\n\n  if [[ ${#var_files[@]} -eq 0 ]]; then\n    echo \"No se encontraron archivos .tfvars en el directorio especificado.\"\n    return 1\n  fi\n\n  echo \"Validando la configuraci\u00f3n de Terraform...\"\n  (cd \"$dir\" &amp;&amp; terraform validate)\n  if [[ $? -ne 0 ]]; then\n    echo \"La validaci\u00f3n de Terraform fall\u00f3.\"\n    return 1\n  fi\n\n  local command=\"terraform $action ${var_files[@]}\"\n\n  if [[ \"$auto\" == \"auto\" &amp;&amp; ( \"$action\" == \"apply\" || \"$action\" == \"destroy\" ) ]]; then\n    command=\"$command -auto-approve\"\n  fi\n\n  echo \"Ejecutando: $command\"\n  eval \"$command\"\n}\n\n# Uso de la funci\u00f3n\n# terraform_with_var_files \"/ruta/al/directorio\" \"plan\"\n# terraform_with_var_files \"/ruta/al/directorio\" \"apply\" \"auto\"\n# terraform_with_var_files \"/ruta/al/directorio\" \"destroy\" \"auto\"\n</code></pre> <p>Para cargar la funci\u00f3n en tu terminal, copia y pega el script en tu archivo <code>.bashrc</code>, <code>.zshrc</code> o el que toque y recarga tu terminal.</p> <p>Espero que os sea de utilidad. \u00a1Saludos!</p>","tags":["Terraform"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/","title":"How to sign Git commits in Visual Studio Code in Windows Subsystem for Linux (WSL)","text":"<p>In this post, we will see how to sign Git commits in Visual Studio Code.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#prerequisites","title":"Prerequisites","text":"<ul> <li>Visual Studio Code</li> <li>Git</li> <li>gpg</li> <li>gpg-agent</li> <li>gpgconf</li> <li>pinentry-gtk-2</li> <li>Windows Subsystem for Linux (WSL) with Ubuntu 20.04</li> </ul>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#steps","title":"Steps","text":"","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#1-install-gpg","title":"1. Install GPG","text":"<p>First, you need to install GPG ans agents. You can do this by running the following command:</p> <pre><code>sudo apt install gpg gpg-agent gpgconf pinentry-gtk2 -y\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#2-generate-a-gpg-key","title":"2. Generate a GPG key","text":"<p>To generate a GPG key, run the following command:</p> <pre><code>gpg --full-generate-key\n</code></pre> <p>You will be asked to enter your name, email, and passphrase. After that, the key will be generated.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#3-list-your-gpg-keys","title":"3. List your GPG keys","text":"<p>To list your GPG keys, run the following command:</p> <pre><code>gpg --list-secret-keys --keyid-format LONG\n</code></pre> <p>You will see a list of your GPG keys. Copy the key ID of the key you want to use.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#4-configure-git-to-use-your-gpg-key","title":"4. Configure Git to use your GPG key","text":"<p>To configure Git to use your GPG key, run the following command:</p> <pre><code>git config --global user.signingkey YOUR_KEY_ID\n</code></pre> <p>Replace <code>YOUR_KEY_ID</code> with the key ID you copied in the previous step.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#5-configure-git-to-sign-commits-by-default","title":"5. Configure Git to sign commits by default","text":"<p>To configure Git to sign commits by default, run the following command:</p> <pre><code>git config --global commit.gpgsign true\ngit config --global gpg.program (which gpg)\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#6-export-the-gpg-key","title":"6. EXport the GPG key","text":"<p>To export the GPG key, run the following command:</p> <pre><code>gpg --armor --export YOUR_KEY_ID\n</code></pre> <p>Replace <code>YOUR_KEY_ID</code> with the key ID you copied in the previous step.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#7-import-to-github","title":"7. Import to github","text":"<p>Go to your github account and add the exported GPG key in GPG keys section, create a new GPG key and paste the exported key.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#configure-visual-studio-code-to-use-gpg","title":"Configure Visual Studio Code to use GPG","text":"","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#1-configure-gpg-agent","title":"1. Configure gpg-agent","text":"<p>To configure gpg-agent, run the following command:</p> <pre><code>echo \"default-cache-ttl\" &gt;&gt; ~/.gnupg/gpg-agent.conf\necho \"pinentry-program /usr/bin/pinentry-gtk-2\" &gt;&gt; ~/.gnupg/gpg-agent.conf\necho \"allow-preset-passphrase\" &gt;&gt; ~/.gnupg/gpg-agent.conf\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#2-restart-the-gpg-agent","title":"2. Restart the gpg-agent","text":"<p>To restart the gpg-agent, run the following command:</p> <pre><code>gpgconf --kill gpg-agent\ngpgconf --launch gpg-agent\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#3-sign-a-commit","title":"3. Sign a commit","text":"<p>To sign a commit, run the following command:</p> <pre><code>git commit -S -m \"Your commit message\"\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#4-verify-the-signature","title":"4. Verify the signature","text":"<p>To verify the signature of a commit, run the following command:</p> <pre><code>git verify-commit HEAD\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#5-configure-visual-studio-code-to-use-gpg","title":"5. Configure Visual Studio Code to use GPG","text":"<p>To configure Visual Studio Code to use GPG, open the settings by pressing <code>Ctrl + ,</code> and search for <code>git.enableCommitSigning</code>. Set the value to <code>true</code>.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#6-sign-a-commit","title":"6. Sign a commit","text":"<p>Make a commit in Visual Studio Code, and you will see a prompt asking you introduce your GPG passphrase. Enter your passphrase, and the commit will be signed.</p> <p>That's it! Now you know how to sign Git commits in Visual Studio Code.</p>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#some-tips","title":"Some tips","text":"","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#for-all-repositories","title":"For all repositories","text":"<ul> <li>Establish your email in git configuration:</li> </ul> <pre><code>git config --global user.email \"petete@something.es\"\n</code></pre> <ul> <li>Establish your name in git configuration:</li> </ul> <pre><code>git config --global user.name \"Petete\"\n</code></pre> <ul> <li>Establish your GPG key in git configuration:</li> </ul> <pre><code>git config --global user.signingkey YOUR_KEY_ID\n</code></pre> <ul> <li>Establish your GPG program in git configuration:</li> </ul> <pre><code>git config --global gpg.program (which gpg)\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#for-a-specific-repository","title":"For a specific repository","text":"<ul> <li>Establish your email in git configuration:</li> </ul> <pre><code>git config user.email \"petete@something.es\"\n</code></pre> <ul> <li>Establish your name in git configuration:</li> </ul> <pre><code>git config user.name \"Petete\"\n</code></pre> <ul> <li>Establish your GPG key in git configuration:</li> </ul> <pre><code>git config user.signingkey YOUR_KEY_ID\n</code></pre> <ul> <li>Establish your GPG program in git configuration:</li> </ul> <pre><code>git config gpg.program (which gpg)\n</code></pre>","tags":["Git"]},{"location":"blog/2024/12/21/how-to-sign-git-commits-in-visual-studio-code-in-windows-subsystem-for-linux-wsl/#conclusion","title":"Conclusion","text":"<p>In this post, we saw how to sign Git commits in Visual Studio Code. This is useful if you want to verify the authenticity of your commits. I hope you found this post helpful. If you have any questions or comments, please let me know. Thank you for reading!</p>","tags":["Git"]},{"location":"blog/2024/12/","title":"2024/12","text":""},{"location":"blog/2024/11/","title":"2024/11","text":""},{"location":"blog/2024/10/","title":"2024/10","text":""},{"location":"blog/2024/09/","title":"2024/09","text":""},{"location":"blog/2024/06/","title":"2024/06","text":""},{"location":"blog/2024/05/","title":"2024/05","text":""},{"location":"blog/2024/04/","title":"2024/04","text":""},{"location":"blog/2024/03/","title":"2024/03","text":""},{"location":"blog/2024/02/","title":"2024/02","text":""},{"location":"blog/2023/12/","title":"2023/12","text":""},{"location":"blog/2023/11/","title":"2023/11","text":""},{"location":"blog/2023/10/","title":"2023/10","text":""},{"location":"blog/category/visual-studio-code/","title":"Visual Studio Code","text":""},{"location":"blog/category/hashicorp/","title":"HashiCorp","text":""},{"location":"blog/category/azure-services/","title":"Azure Services","text":""},{"location":"blog/category/devops/","title":"DevOps","text":""},{"location":"blog/category/microsoft-entra/","title":"Microsoft Entra","text":""},{"location":"blog/category/security/","title":"Security","text":""},{"location":"blog/category/microsoft-entra-id/","title":"Microsoft Entra ID","text":""},{"location":"blog/category/microsoft-entra-external-id/","title":"Microsoft Entra External ID","text":""},{"location":"blog/category/azure/","title":"Azure","text":""},{"location":"blog/category/power-bi/","title":"Power BI","text":""},{"location":"blog/category/finops/","title":"FinOps","text":""},{"location":"blog/category/m365/","title":"M365","text":""},{"location":"blog/category/snowflake/","title":"Snowflake","text":""},{"location":"blog/category/tools/","title":"Tools","text":""},{"location":"blog/category/learning/","title":"Learning","text":""},{"location":"blog/category/microsoft-365/","title":"Microsoft 365","text":""},{"location":"blog/category/windows/","title":"Windows","text":""},{"location":"blog/category/azure-updates/","title":"Azure Updates","text":""},{"location":"blog/category/azure-frameworks/","title":"Azure Frameworks","text":""},{"location":"blog/category/development/","title":"Development","text":""},{"location":"blog/category/english/","title":"English","text":""},{"location":"blog/category/hello_world/","title":"Hello_World","text":""},{"location":"blog/page/2/","title":"Blog","text":""},{"location":"blog/page/3/","title":"Blog","text":""},{"location":"blog/page/4/","title":"Blog","text":""},{"location":"blog/page/5/","title":"Blog","text":""},{"location":"blog/page/6/","title":"Blog","text":""},{"location":"blog/page/7/","title":"Blog","text":""},{"location":"blog/page/8/","title":"Blog","text":""},{"location":"blog/2024/04/page/2/","title":"2024/04","text":""},{"location":"blog/2024/04/page/3/","title":"2024/04","text":""},{"location":"blog/category/azure-services/page/2/","title":"Azure Services","text":""},{"location":"blog/category/azure-services/page/3/","title":"Azure Services","text":""},{"location":"blog/category/azure-services/page/4/","title":"Azure Services","text":""},{"location":"blog/category/devops/page/2/","title":"DevOps","text":""},{"location":"blog/tags/","title":"Posts by Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"blog/tags/#attribute-based-access-control","title":"Attribute-Based Access Control","text":"<ul> <li>Azure role assignment conditions</li> </ul>"},{"location":"blog/tags/#azure-arc","title":"Azure ARC","text":"<ul> <li>Azure ARC</li> <li>How to use Azue ARC-enabled servers with managed identity to access to Azure Storage Account</li> </ul>"},{"location":"blog/tags/#azure-communication-services","title":"Azure Communication Services","text":"<ul> <li>Azure Communication Services</li> </ul>"},{"location":"blog/tags/#azure-container-apps","title":"Azure Container Apps","text":"<ul> <li>Comparing Container Apps with other Azure container options</li> </ul>"},{"location":"blog/tags/#azure-container-registry","title":"Azure Container Registry","text":"<ul> <li>Azure Container Registry: Artifact Cache</li> </ul>"},{"location":"blog/tags/#azure-cost-management","title":"Azure Cost Management","text":"<ul> <li>FinOps for Azure: Optimizing Your Cloud Spend</li> </ul>"},{"location":"blog/tags/#azure-functions","title":"Azure Functions","text":"<ul> <li>Azure Functions</li> </ul>"},{"location":"blog/tags/#azure-managed-disks","title":"Azure Managed Disks","text":"<ul> <li>Restrict managed disks from being imported or exported</li> </ul>"},{"location":"blog/tags/#azure-network","title":"Azure Network","text":"<ul> <li>Azure Network, Hub-and-Spoke Topology</li> </ul>"},{"location":"blog/tags/#azure-policy","title":"Azure Policy","text":"<ul> <li>Azure Policy</li> <li>Azure Policy, defintion schema</li> <li>Writing Your First Policy in Azure with Portal</li> <li>Writing Your First Initiative with Portal</li> <li>Manage Azure Policy GitHub Action</li> <li>Enterprise Azure Policy as Code (EPAC)</li> <li>Azure Policy Management Best Practices</li> <li>Using Enterprise Azure Policy as Code (EPAC)</li> <li>Azure Policy useful queries</li> <li>Custom Azure Policy for Kubernetes</li> <li>Trigger an on-demand Azure Policy compliance evaluation scan</li> <li>How to create a local environment to write policies for Kubernetes with minikube and gatekeeper</li> <li>Develop my firts policy for Kubernetes with minikube and gatekeeper</li> </ul>"},{"location":"blog/tags/#azure-private-link","title":"Azure Private Link","text":"<ul> <li>Reduce your attack surface in Snowflake when using from Azure</li> <li>How to check if a private endpoint is connected to a external private link service in Azure</li> </ul>"},{"location":"blog/tags/#azure-rbac","title":"Azure RBAC","text":"<ul> <li>Azure role assignment conditions</li> <li>How to check if a role permission is good or bad in Azure RBAC</li> </ul>"},{"location":"blog/tags/#azure-storage-account","title":"Azure Storage Account","text":"<ul> <li>Data threat modeling in Azure storage accounts</li> </ul>"},{"location":"blog/tags/#azure-tags","title":"Azure Tags","text":"<ul> <li>Tagging best practices in Azure</li> </ul>"},{"location":"blog/tags/#azure-well-architected-framework","title":"Azure Well-Architected Framework","text":"<ul> <li>Azure Well-Architected Framework (WAF) mind maps</li> </ul>"},{"location":"blog/tags/#azure-role-assignment-conditions","title":"Azure role assignment conditions","text":"<ul> <li>Azure role assignment conditions</li> </ul>"},{"location":"blog/tags/#azure-tags_1","title":"Azure tags","text":"<ul> <li>FinOps for Azure: Optimizing Your Cloud Spend</li> </ul>"},{"location":"blog/tags/#b2b","title":"B2B","text":"<ul> <li>Differences between B2B Direct Connect and B2B Collaboration in Microsoft Entra</li> </ul>"},{"location":"blog/tags/#b2b-collaboration","title":"B2B Collaboration","text":"<ul> <li>Differences between B2B Direct Connect and B2B Collaboration in Microsoft Entra</li> </ul>"},{"location":"blog/tags/#b2b-direct-connect","title":"B2B Direct Connect","text":"<ul> <li>Differences between B2B Direct Connect and B2B Collaboration in Microsoft Entra</li> </ul>"},{"location":"blog/tags/#cvss","title":"CVSS","text":"<ul> <li>Security Score System</li> </ul>"},{"location":"blog/tags/#certifications","title":"Certifications","text":"<ul> <li>Microsoft Azure Certifications</li> </ul>"},{"location":"blog/tags/#conditional-access-policies","title":"Conditional access policies","text":"<ul> <li>Microsoft Entra ID Protection</li> </ul>"},{"location":"blog/tags/#epac","title":"EPAC","text":"<ul> <li>Enterprise Azure Policy as Code (EPAC)</li> <li>Using Enterprise Azure Policy as Code (EPAC)</li> </ul>"},{"location":"blog/tags/#english","title":"English","text":"<ul> <li>Azure Services</li> </ul>"},{"location":"blog/tags/#external-id-b2b","title":"External ID B2B","text":"<ul> <li>Differences between B2B Direct Connect and B2B Collaboration in Microsoft Entra</li> </ul>"},{"location":"blog/tags/#general","title":"General","text":"<ul> <li>Azure Services</li> </ul>"},{"location":"blog/tags/#git","title":"Git","text":"<ul> <li>How to sign Git commits in Visual Studio Code in Windows Subsystem for Linux (WSL)</li> </ul>"},{"location":"blog/tags/#hub-and-spoke","title":"Hub and Spoke","text":"<ul> <li>Azure Network, Hub-and-Spoke Topology</li> </ul>"},{"location":"blog/tags/#id-protection","title":"ID Protection","text":"<ul> <li>Microsoft Entra ID Protection</li> </ul>"},{"location":"blog/tags/#iac","title":"IaC","text":"<ul> <li>What you need to think about when starting an IaC project ?</li> <li>Starting my IaC project with terraform</li> <li>Nested Structures with Optional Attributes and Dynamic Blocks</li> </ul>"},{"location":"blog/tags/#identity-protection-reports","title":"Identity protection reports","text":"<ul> <li>Microsoft Entra ID Protection</li> </ul>"},{"location":"blog/tags/#kql","title":"KQL","text":"<ul> <li>Kusto Query Language (KQL) for Azure Resource Graph</li> </ul>"},{"location":"blog/tags/#managed-identity","title":"Managed Identity","text":"<ul> <li>When to use service principals</li> </ul>"},{"location":"blog/tags/#management-groups","title":"Management Groups","text":"<ul> <li>Management Groups</li> <li>Moving Management Groups and Subscriptions</li> <li>How to create a Management Group diagram with draw.io</li> </ul>"},{"location":"blog/tags/#microsoft-defender-for-cloud","title":"Microsoft Defender for Cloud","text":"<ul> <li>Cambio de nombres de los niveles de servicio de Microsoft Defender para Cloud</li> </ul>"},{"location":"blog/tags/#microsoft-defender-for-storage","title":"Microsoft Defender for Storage","text":"<ul> <li>Microsoft Defender for Storage</li> </ul>"},{"location":"blog/tags/#microsoft-entra-attribute-duplicate-attribute-resiliency","title":"Microsoft Entra Attribute Duplicate Attribute Resiliency","text":"<ul> <li>Microsoft Entra Attribute Duplicate Attribute Resiliency</li> </ul>"},{"location":"blog/tags/#microsoft-entra-conditional-access","title":"Microsoft Entra Conditional Access","text":"<ul> <li>Microsoft Entra Conditional Access</li> </ul>"},{"location":"blog/tags/#microsoft-entra-connec","title":"Microsoft Entra Connec","text":"<ul> <li>Microsoft Entra Attribute Duplicate Attribute Resiliency</li> </ul>"},{"location":"blog/tags/#microsoft-entra-id-privileged-identity-management","title":"Microsoft Entra ID Privileged Identity Management","text":"<ul> <li>Microsoft Entra ID Privileged Identity Management</li> </ul>"},{"location":"blog/tags/#multi-factor-authentication","title":"Multi-factor authentication","text":"<ul> <li>Microsoft Entra ID Protection</li> </ul>"},{"location":"blog/tags/#onedrive-for-business","title":"OneDrive for Business","text":"<ul> <li>Depurar logs de OneDrive para detectar problemas de sincronizaci\u00f3n</li> </ul>"},{"location":"blog/tags/#open-policy-agent","title":"Open Policy Agent","text":"<ul> <li>Implementing policy as code with Open Policy Agent</li> </ul>"},{"location":"blog/tags/#opentofu","title":"OpenTofu","text":"<ul> <li>Starting my IaC project with terraform</li> <li>Nested Structures with Optional Attributes and Dynamic Blocks</li> </ul>"},{"location":"blog/tags/#pam","title":"PAM","text":"<ul> <li>Privileged Access Management (PAM) Strategy with Microsoft Entra ID and some Azure Services</li> </ul>"},{"location":"blog/tags/#risk-based-policies","title":"Risk-based policies","text":"<ul> <li>Microsoft Entra ID Protection</li> </ul>"},{"location":"blog/tags/#role-based-access-control","title":"Role-Based Access Control","text":"<ul> <li>Azure Role-Based Access Control (RBAC)</li> <li>How to create assigment Reports for Azure RBAC</li> </ul>"},{"location":"blog/tags/#security","title":"Security","text":"<ul> <li>Privileged Access Management (PAM) Strategy with Microsoft Entra ID and some Azure Services</li> </ul>"},{"location":"blog/tags/#service-principal","title":"Service Principal","text":"<ul> <li>When to use service principals</li> </ul>"},{"location":"blog/tags/#teams","title":"Teams","text":"<ul> <li>Configure your Teams meetings options to improve your collaboration experience</li> </ul>"},{"location":"blog/tags/#terraform","title":"Terraform","text":"<ul> <li>Starting my IaC project with terraform</li> <li>Terraform: Configuration Language</li> <li>Terraform: Set your local environment developer</li> <li>Nested Structures with Optional Attributes and Dynamic Blocks</li> <li>Ejecutar Terraform con archivos de variables</li> </ul>"},{"location":"blog/tags/#trunk","title":"Trunk","text":"<ul> <li>Trunk</li> </ul>"},{"location":"blog/tags/#virtual-network-vnet-data-gateway","title":"Virtual network (VNet) data gateway","text":"<ul> <li>Securely connect Power BI to data sources with a VNet data gateway</li> </ul>"},{"location":"blog/tags/#windows-subsystem-for-linux-2","title":"Windows Subsystem for Linux 2","text":"<ul> <li>Instalar WSL2 en Windows 11 con chocolatey</li> </ul>"},{"location":"blog/tags/#csharp","title":"csharp","text":"<ul> <li>Starting to develop in c#</li> </ul>"},{"location":"blog/tags/#drawio","title":"draw.io","text":"<ul> <li>How to create a Management Group diagram with draw.io</li> </ul>"},{"location":"blog/tags/#git_1","title":"git","text":"<ul> <li>Repository Strategy: Monorepo vs Multi-repo</li> <li>Repository Strategy: Fork vs Branch</li> <li>Repository Strategy: Branching Strategy</li> <li>Repository Strategy: How to test Branching Strategy in local repository</li> </ul>"},{"location":"blog/tags/#markmap","title":"markmap","text":"<ul> <li>markmap</li> </ul>"},{"location":"blog/tags/#mkdocs","title":"mkdocs","text":"<ul> <li>Create a blog with MkDocs,mkdocs-material, mkdocs-rss-plugin and GitHub Pages</li> <li>Enhance your mkdocks.yml</li> </ul>"},{"location":"blog/tags/#terraform_1","title":"terraform","text":"<ul> <li>terraform import block</li> </ul>"},{"location":"blog/tags/#vscode","title":"vscode","text":"<ul> <li>Trunk</li> </ul>"}]}